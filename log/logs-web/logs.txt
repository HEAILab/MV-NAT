[2023-05-04 22:00:09,244-rk0-train.py#371] Version Information: 
commit : 
  log  : 

[2023-05-04 22:00:09,245-rk0-train.py#372] config 
{
    "META_ARC": "udatcar_r50_l234",
    "CUDA": true,
    "TRAIN": {
        "EXEMPLAR_SIZE": 127,
        "SEARCH_SIZE": 255,
        "OUTPUT_SIZE": 25,
        "RESUME": "",
        "RESUME_2": "",
        "RESUME_D": "",
        "RESUME_D_2": "",
        "PRETRAINED": "/home/user/V4R/LHY/MDAT/UDAT/CAR/tools/snapshot/udatcar_model.pth",
        "PRETRAINED_2": "",
        "LOG_DIR": "/home/user/V4R/LHY/MDAT/UDAT/CAR/log/logs-web",
        "SNAPSHOT_DIR": "/home/user/V4R/LHY/MDAT/UDAT/CAR/snapshot-web",
        "EPOCH": 25,
        "START_EPOCH": 0,
        "BATCH_SIZE": 32,
        "NUM_WORKERS": 8,
        "MOMENTUM": 0.9,
        "WEIGHT_DECAY": 0.0001,
        "CLS_WEIGHT": 1.0,
        "LOC_WEIGHT": 3.0,
        "CEN_WEIGHT": 1.0,
        "PRINT_FREQ": 20,
        "LOG_GRADS": false,
        "GRAD_CLIP": 10.0,
        "BASE_LR": 0.0015,
        "BASE_LR_d": 0.005,
        "LR": {
            "TYPE": "log",
            "KWARGS": {
                "start_lr": 0.0015,
                "end_lr": 0.00015
            }
        },
        "LR_WARMUP": {
            "WARMUP": true,
            "TYPE": "step",
            "EPOCH": 5,
            "KWARGS": {
                "start_lr": 0.0003,
                "end_lr": 0.0015,
                "step": 1
            }
        },
        "NUM_CLASSES": 2,
        "NUM_CONVS": 4,
        "PRIOR_PROB": 0.01,
        "LOSS_ALPHA": 0.25,
        "LOSS_GAMMA": 2.0
    },
    "DATASET": {
        "TEMPLATE": {
            "SHIFT": 4,
            "SCALE": 0.05,
            "BLUR": 0.0,
            "FLIP": 0.0,
            "COLOR": 1.0
        },
        "SEARCH": {
            "SHIFT": 64,
            "SCALE": 0.18,
            "BLUR": 0.2,
            "FLIP": 0.0,
            "COLOR": 1.0
        },
        "NEG": 0.0,
        "GRAY": 0.0,
        "SOURCE": [
            "WEB_mid",
            "WEB_ver"
        ],
        "TARGET": [
            "NAT"
        ],
        "VID": {
            "ROOT": "/data1/Train_dataset/vid/crop511",
            "ANNO": "/data1/Train_dataset/vid/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "WEB_mid": {
            "ROOT": "/data2/Train_dataset/WEB3-UAV/train_middle_view/crop_511",
            "ANNO": "/data2/Train_dataset/WEB3-UAV/train_middle_view/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "WEB_ver": {
            "ROOT": "/data2/Train_dataset/WEB3-UAV/train_verticle_view/crop_511",
            "ANNO": "/data2/Train_dataset/WEB3-UAV/train_verticle_view/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "YOUTUBEBB": {
            "ROOT": "train_dataset/yt_bb/crop511",
            "ANNO": "train_dataset/yt_bb/train.json",
            "FRAME_RANGE": 3,
            "NUM_USE": -1
        },
        "COCO": {
            "ROOT": "train_dataset/coco/crop511",
            "ANNO": "train_dataset/coco/train2017.json",
            "FRAME_RANGE": 1,
            "NUM_USE": -1
        },
        "DET": {
            "ROOT": "train_dataset/det/crop511",
            "ANNO": "train_dataset/det/train.json",
            "FRAME_RANGE": 1,
            "NUM_USE": -1
        },
        "GOT": {
            "ROOT": "/data1/Train_dataset/got10k/crop511",
            "ANNO": "/data1/Train_dataset/got10k/train.json",
            "FRAME_RANGE": 50,
            "NUM_USE": -1
        },
        "LaSOT": {
            "ROOT": "train_dataset/lasot/crop511",
            "ANNO": "train_dataset/lasot/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": 100000
        },
        "UAV123": {
            "ROOT": "/data1/Test_dataset/UAV123/crop_511",
            "ANNO": "/data1/Test_dataset/UAV123/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "UAVDT": {
            "ROOT": "/data1/Train_dataset/UAVDT/crop_511",
            "ANNO": "/data1/Train_dataset/UAVDT/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "Track112": {
            "ROOT": "/data1/Test_dataset/UAVTrack112/crop_511",
            "ANNO": "/data1/Test_dataset/UAVTrack112/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "DarkTrack": {
            "ROOT": "/home/mist/v4r/train_dataset/random_train/random_crop511",
            "ANNO": "/home/mist/v4r/train_dataset/random_train/train_random.json",
            "FRAME_RANGE": 50,
            "NUM_USE": 10000
        },
        "NAT": {
            "ROOT": "/data1/Train_dataset/NAT2021-train/random_train/random_crop511",
            "ANNO": "/data1/Train_dataset/NAT2021-train/random_train/train_random.json",
            "FRAME_RANGE": 50,
            "NUM_USE": 10000
        },
        "VIDEOS_PER_EPOCH": 20000,
        "NAMES": [
            "WEB_mid",
            "WEB_ver"
        ]
    },
    "BACKBONE": {
        "TYPE": "resnet50",
        "KWARGS": {
            "used_layers": [
                2,
                3,
                4
            ]
        },
        "PRETRAINED": "",
        "TRAIN_LAYERS": [
            "layer2",
            "layer3",
            "layer4"
        ],
        "LAYERS_LR": 0.1,
        "TRAIN_EPOCH": 0
    },
    "ADJUST": {
        "ADJUST": true,
        "KWARGS": {
            "in_channels": [
                512,
                1024,
                2048
            ],
            "out_channels": [
                256,
                256,
                256
            ]
        },
        "TYPE": "AdjustAllLayer"
    },
    "ALIGN": {
        "ALIGN": true,
        "KWARGS": {
            "channels": 256
        },
        "TYPE": "Adjust_Transformer"
    },
    "CAR": {
        "TYPE": "MultiCAR",
        "KWARGS": {}
    },
    "TRACK": {
        "TYPE": "SiamCARTracker",
        "PENALTY_K": 0.04,
        "WINDOW_INFLUENCE": 0.44,
        "LR": 0.33,
        "EXEMPLAR_SIZE": 127,
        "INSTANCE_SIZE": 255,
        "CONTEXT_AMOUNT": 0.5,
        "STRIDE": 8,
        "SCORE_SIZE": 25,
        "hanming": true,
        "NUM_K": 2,
        "NUM_N": 1,
        "REGION_S": 0.1,
        "REGION_L": 0.44
    },
    "HP_SEARCH": {
        "UAV123": [
            0.39,
            0.04,
            0.37
        ],
        "NAT": [
            0.39,
            0.04,
            0.37
        ],
        "NAT_L": [
            0.39,
            0.04,
            0.37
        ],
        "UAVDark70": [
            0.32,
            0.04,
            0.36
        ]
    }
}
[2023-05-04 22:00:19,175-rk0-train.py# 66] build train dataset
[2023-05-04 22:00:19,176-rk0-dataset.py# 40] loading NAT
[2023-05-04 22:00:20,448-rk0-dataset.py# 65] NAT loaded
[2023-05-04 22:00:20,449-rk0-dataset.py# 96] NAT start-index 0 select [10000/1399] path_format {}.{}.{}.jpg
[2023-05-04 22:00:20,467-rk0-dataset.py#203] shuffle done!
[2023-05-04 22:00:20,468-rk0-dataset.py#204] dataset length 500000
[2023-05-04 22:00:20,469-rk0-train.py# 69] build dataset done
[2023-05-04 22:00:20,470-rk0-train.py# 66] build train dataset
[2023-05-04 22:00:20,470-rk0-dataset.py# 40] loading WEB_mid
[2023-05-04 22:00:23,136-rk0-dataset.py# 65] WEB_mid loaded
[2023-05-04 22:00:23,136-rk0-dataset.py# 96] WEB_mid start-index 0 select [1666/1666] path_format {}.{}.{}.jpg
[2023-05-04 22:00:23,137-rk0-dataset.py# 40] loading WEB_ver
[2023-05-04 22:00:25,615-rk0-dataset.py# 65] WEB_ver loaded
[2023-05-04 22:00:25,615-rk0-dataset.py# 96] WEB_ver start-index 1666 select [1092/1092] path_format {}.{}.{}.jpg
[2023-05-04 22:00:25,642-rk0-dataset.py#203] shuffle done!
[2023-05-04 22:00:25,642-rk0-dataset.py#204] dataset length 500000
[2023-05-04 22:00:25,646-rk0-train.py# 69] build dataset done
[2023-05-04 22:00:25,728-rk0-model_load.py# 48] load pretrained model from /home/user/V4R/LHY/MDAT/UDAT/CAR/tools/snapshot/udatcar_model.pth
[2023-05-04 22:00:26,196-rk0-model_load.py# 42] remove prefix 'module.'
[2023-05-04 22:00:26,200-rk0-model_load.py# 26] [Warning] missing keys: ['align.transformer.encoder.layers.0.self_attn2.in_proj_weight', 'align.transformer.encoder.layers.0.self_attn2.out_proj.weight', 'align.transformer.encoder.layers.0.norm3.weight', 'align.transformer.encoder.layers.0.self_attn2.out_proj.bias', 'align.transformer.encoder.layers.0.self_attn2.in_proj_bias', 'align.conv1.0.bias', 'align.transformer.encoder.layers.0.norm3.bias', 'align.conv1.0.weight']
[2023-05-04 22:00:26,200-rk0-model_load.py# 27] missing keys:8
[2023-05-04 22:00:26,200-rk0-model_load.py# 33] used keys:401
[2023-05-04 22:00:26,224-rk0-train.py#427] (WarmUPScheduler) lr spaces: 
[0.0003     0.00041392 0.0005711  0.00078796 0.00108717 0.0015
 0.0013288  0.00117714 0.00104279 0.00092377 0.00081834 0.00072494
 0.0006422  0.0005689  0.00050397 0.00044645 0.0003955  0.00035036
 0.00031037 0.00027495 0.00024357 0.00021577 0.00019114 0.00016933
 0.00015   ]
[2023-05-04 22:00:26,225-rk0-train.py#428] model prepare done
[2023-05-04 22:00:26,229-rk0-train.py#198] model
.[31mbackbone[0m (ResNet)
         .[31mconv1[0m (Conv2d)
               - [31mweight[0m
         .[31mbn1[0m (BatchNorm2d)
             - [31mweight[0m
             - [31mbias[0m
         .[31mrelu[0m (ReLU)
         .[31mmaxpool[0m (MaxPool2d)
         .[31mlayer1[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer2[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m3[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer3[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m3[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m4[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m5[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer4[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
.[31mneck[0m (AdjustAllLayer)
     .[31mdownsample2[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
     .[31mdownsample3[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
     .[31mdownsample4[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
.[31malign[0m (Adjust_Transformer)
      .[31mrow_embed[0m (Embedding)
                - [31mweight[0m
      .[31mcol_embed[0m (Embedding)
                - [31mweight[0m
      .[31mconv1[0m (Sequential)
            .[31m0[0m (ConvTranspose2d)
              - [31mweight[0m
              - [31mbias[0m
      .[31mtransformer[0m (Transformer)
                  .[31mencoder[0m (TransformerEncoder)
                          .[31mlayers[0m (ModuleList)
                                 .[31m0[0m (TransformerEncoderLayer)
                                   .[31mself_attn[0m (MultiheadAttention)
                                             - [31min_proj_weight[0m
                                             - [31min_proj_bias[0m
                                             .[31mout_proj[0m (NonDynamicallyQuantizableLinear)
                                                      - [31mweight[0m
                                                      - [31mbias[0m
                                   .[31mself_attn2[0m (MultiheadAttention)
                                              - [31min_proj_weight[0m
                                              - [31min_proj_bias[0m
                                              .[31mout_proj[0m (NonDynamicallyQuantizableLinear)
                                                       - [31mweight[0m
                                                       - [31mbias[0m
                                   .[31mcross_attn[0m (Cattention)
                                              - [31mgamma[0m
                                              .[31mconv1[0m (Sequential)
                                                    .[31m0[0m (ConvTranspose2d)
                                                      - [31mweight[0m
                                                      - [31mbias[0m
                                              .[31mavg_pool[0m (AdaptiveAvgPool2d)
                                              .[31mlinear1[0m (Conv2d)
                                                      - [31mweight[0m
                                              .[31mlinear2[0m (Conv2d)
                                                      - [31mweight[0m
                                              .[31mactivation[0m (ReLU)
                                              .[31mdropout[0m (Dropout)
                                   .[31mlinear1[0m (Linear)
                                           - [31mweight[0m
                                           - [31mbias[0m
                                   .[31mdropout[0m (Dropout)
                                   .[31mlinear2[0m (Linear)
                                           - [31mweight[0m
                                           - [31mbias[0m
                                   .[31mnorm0[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm1[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm2[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm3[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mdropout1[0m (Dropout)
                                   .[31mdropout2[0m (Dropout)
                          .[31mnorm[0m (LayerNorm)
                               - [31mweight[0m
                               - [31mbias[0m
                  .[31mdecoder[0m (TransformerDecoder)
                          .[31mlayers[0m (ModuleList)
                          .[31mnorm[0m (LayerNorm)
                               - [31mweight[0m
                               - [31mbias[0m
.[31mcar_head[0m (CARHead)
         .[31mcls_tower[0m (Sequential)
                   .[31m0[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m1[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m2[0m (ReLU)
                   .[31m3[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m4[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m5[0m (ReLU)
                   .[31m6[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m7[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m8[0m (ReLU)
                   .[31m9[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m10[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                   .[31m11[0m (ReLU)
         .[31mbbox_tower[0m (Sequential)
                    .[31m0[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m1[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m2[0m (ReLU)
                    .[31m3[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m4[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m5[0m (ReLU)
                    .[31m6[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m7[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m8[0m (ReLU)
                    .[31m9[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m10[0m (GroupNorm)
                       - [31mweight[0m
                       - [31mbias[0m
                    .[31m11[0m (ReLU)
         .[31mcls_logits[0m (Conv2d)
                    - [31mweight[0m
                    - [31mbias[0m
         .[31mbbox_pred[0m (Conv2d)
                   - [31mweight[0m
                   - [31mbias[0m
         .[31mcenterness[0m (Conv2d)
                    - [31mweight[0m
                    - [31mbias[0m
.[31mdown[0m (ConvTranspose2d)
     - [31mweight[0m
     - [31mbias[0m
[2023-05-04 22:00:41,814-rk0-train.py#371] Version Information: 
commit : 
  log  : 

[2023-05-04 22:00:41,815-rk0-train.py#372] config 
{
    "META_ARC": "udatcar_r50_l234",
    "CUDA": true,
    "TRAIN": {
        "EXEMPLAR_SIZE": 127,
        "SEARCH_SIZE": 255,
        "OUTPUT_SIZE": 25,
        "RESUME": "",
        "RESUME_2": "",
        "RESUME_D": "",
        "RESUME_D_2": "",
        "PRETRAINED": "/home/user/V4R/LHY/MDAT/UDAT/CAR/tools/snapshot/udatcar_model.pth",
        "PRETRAINED_2": "",
        "LOG_DIR": "/home/user/V4R/LHY/MDAT/UDAT/CAR/log/logs-web",
        "SNAPSHOT_DIR": "/home/user/V4R/LHY/MDAT/UDAT/CAR/snapshot-web",
        "EPOCH": 25,
        "START_EPOCH": 0,
        "BATCH_SIZE": 32,
        "NUM_WORKERS": 8,
        "MOMENTUM": 0.9,
        "WEIGHT_DECAY": 0.0001,
        "CLS_WEIGHT": 1.0,
        "LOC_WEIGHT": 3.0,
        "CEN_WEIGHT": 1.0,
        "PRINT_FREQ": 20,
        "LOG_GRADS": false,
        "GRAD_CLIP": 10.0,
        "BASE_LR": 0.0015,
        "BASE_LR_d": 0.005,
        "LR": {
            "TYPE": "log",
            "KWARGS": {
                "start_lr": 0.0015,
                "end_lr": 0.00015
            }
        },
        "LR_WARMUP": {
            "WARMUP": true,
            "TYPE": "step",
            "EPOCH": 5,
            "KWARGS": {
                "start_lr": 0.0003,
                "end_lr": 0.0015,
                "step": 1
            }
        },
        "NUM_CLASSES": 2,
        "NUM_CONVS": 4,
        "PRIOR_PROB": 0.01,
        "LOSS_ALPHA": 0.25,
        "LOSS_GAMMA": 2.0
    },
    "DATASET": {
        "TEMPLATE": {
            "SHIFT": 4,
            "SCALE": 0.05,
            "BLUR": 0.0,
            "FLIP": 0.0,
            "COLOR": 1.0
        },
        "SEARCH": {
            "SHIFT": 64,
            "SCALE": 0.18,
            "BLUR": 0.2,
            "FLIP": 0.0,
            "COLOR": 1.0
        },
        "NEG": 0.0,
        "GRAY": 0.0,
        "SOURCE": [
            "WEB_mid",
            "WEB_ver"
        ],
        "TARGET": [
            "NAT"
        ],
        "VID": {
            "ROOT": "/data1/Train_dataset/vid/crop511",
            "ANNO": "/data1/Train_dataset/vid/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "WEB_mid": {
            "ROOT": "/data2/Train_dataset/WEB3-UAV/train_middle_view/crop_511",
            "ANNO": "/data2/Train_dataset/WEB3-UAV/train_middle_view/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "WEB_ver": {
            "ROOT": "/data2/Train_dataset/WEB3-UAV/train_verticle_view/crop_511",
            "ANNO": "/data2/Train_dataset/WEB3-UAV/train_verticle_view/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "YOUTUBEBB": {
            "ROOT": "train_dataset/yt_bb/crop511",
            "ANNO": "train_dataset/yt_bb/train.json",
            "FRAME_RANGE": 3,
            "NUM_USE": -1
        },
        "COCO": {
            "ROOT": "train_dataset/coco/crop511",
            "ANNO": "train_dataset/coco/train2017.json",
            "FRAME_RANGE": 1,
            "NUM_USE": -1
        },
        "DET": {
            "ROOT": "train_dataset/det/crop511",
            "ANNO": "train_dataset/det/train.json",
            "FRAME_RANGE": 1,
            "NUM_USE": -1
        },
        "GOT": {
            "ROOT": "/data1/Train_dataset/got10k/crop511",
            "ANNO": "/data1/Train_dataset/got10k/train.json",
            "FRAME_RANGE": 50,
            "NUM_USE": -1
        },
        "LaSOT": {
            "ROOT": "train_dataset/lasot/crop511",
            "ANNO": "train_dataset/lasot/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": 100000
        },
        "UAV123": {
            "ROOT": "/data1/Test_dataset/UAV123/crop_511",
            "ANNO": "/data1/Test_dataset/UAV123/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "UAVDT": {
            "ROOT": "/data1/Train_dataset/UAVDT/crop_511",
            "ANNO": "/data1/Train_dataset/UAVDT/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "Track112": {
            "ROOT": "/data1/Test_dataset/UAVTrack112/crop_511",
            "ANNO": "/data1/Test_dataset/UAVTrack112/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "DarkTrack": {
            "ROOT": "/home/mist/v4r/train_dataset/random_train/random_crop511",
            "ANNO": "/home/mist/v4r/train_dataset/random_train/train_random.json",
            "FRAME_RANGE": 50,
            "NUM_USE": 10000
        },
        "NAT": {
            "ROOT": "/data1/Train_dataset/NAT2021-train/random_train/random_crop511",
            "ANNO": "/data1/Train_dataset/NAT2021-train/random_train/train_random.json",
            "FRAME_RANGE": 50,
            "NUM_USE": 10000
        },
        "VIDEOS_PER_EPOCH": 20000,
        "NAMES": [
            "WEB_mid",
            "WEB_ver"
        ]
    },
    "BACKBONE": {
        "TYPE": "resnet50",
        "KWARGS": {
            "used_layers": [
                2,
                3,
                4
            ]
        },
        "PRETRAINED": "",
        "TRAIN_LAYERS": [
            "layer2",
            "layer3",
            "layer4"
        ],
        "LAYERS_LR": 0.1,
        "TRAIN_EPOCH": 0
    },
    "ADJUST": {
        "ADJUST": true,
        "KWARGS": {
            "in_channels": [
                512,
                1024,
                2048
            ],
            "out_channels": [
                256,
                256,
                256
            ]
        },
        "TYPE": "AdjustAllLayer"
    },
    "ALIGN": {
        "ALIGN": true,
        "KWARGS": {
            "channels": 256
        },
        "TYPE": "Adjust_Transformer"
    },
    "CAR": {
        "TYPE": "MultiCAR",
        "KWARGS": {}
    },
    "TRACK": {
        "TYPE": "SiamCARTracker",
        "PENALTY_K": 0.04,
        "WINDOW_INFLUENCE": 0.44,
        "LR": 0.33,
        "EXEMPLAR_SIZE": 127,
        "INSTANCE_SIZE": 255,
        "CONTEXT_AMOUNT": 0.5,
        "STRIDE": 8,
        "SCORE_SIZE": 25,
        "hanming": true,
        "NUM_K": 2,
        "NUM_N": 1,
        "REGION_S": 0.1,
        "REGION_L": 0.44
    },
    "HP_SEARCH": {
        "UAV123": [
            0.39,
            0.04,
            0.37
        ],
        "NAT": [
            0.39,
            0.04,
            0.37
        ],
        "NAT_L": [
            0.39,
            0.04,
            0.37
        ],
        "UAVDark70": [
            0.32,
            0.04,
            0.36
        ]
    }
}
[2023-05-04 22:00:46,436-rk0-train.py# 66] build train dataset
[2023-05-04 22:00:46,436-rk0-dataset.py# 40] loading NAT
[2023-05-04 22:00:47,020-rk0-dataset.py# 65] NAT loaded
[2023-05-04 22:00:47,020-rk0-dataset.py# 96] NAT start-index 0 select [10000/1399] path_format {}.{}.{}.jpg
[2023-05-04 22:00:47,041-rk0-dataset.py#203] shuffle done!
[2023-05-04 22:00:47,041-rk0-dataset.py#204] dataset length 500000
[2023-05-04 22:00:47,044-rk0-train.py# 69] build dataset done
[2023-05-04 22:00:47,044-rk0-train.py# 66] build train dataset
[2023-05-04 22:00:47,045-rk0-dataset.py# 40] loading WEB_mid
[2023-05-04 22:00:49,267-rk0-dataset.py# 65] WEB_mid loaded
[2023-05-04 22:00:49,267-rk0-dataset.py# 96] WEB_mid start-index 0 select [1666/1666] path_format {}.{}.{}.jpg
[2023-05-04 22:00:49,267-rk0-dataset.py# 40] loading WEB_ver
[2023-05-04 22:00:51,079-rk0-dataset.py# 65] WEB_ver loaded
[2023-05-04 22:00:51,079-rk0-dataset.py# 96] WEB_ver start-index 1666 select [1092/1092] path_format {}.{}.{}.jpg
[2023-05-04 22:00:51,102-rk0-dataset.py#203] shuffle done!
[2023-05-04 22:00:51,102-rk0-dataset.py#204] dataset length 500000
[2023-05-04 22:00:51,105-rk0-train.py# 69] build dataset done
[2023-05-04 22:00:51,159-rk0-model_load.py# 48] load pretrained model from /home/user/V4R/LHY/MDAT/UDAT/CAR/tools/snapshot/udatcar_model.pth
[2023-05-04 22:00:51,600-rk0-model_load.py# 42] remove prefix 'module.'
[2023-05-04 22:00:51,603-rk0-model_load.py# 26] [Warning] missing keys: ['align.transformer.encoder.layers.0.self_attn2.out_proj.weight', 'align.transformer.encoder.layers.0.self_attn2.out_proj.bias', 'align.transformer.encoder.layers.0.self_attn2.in_proj_weight', 'align.transformer.encoder.layers.0.norm3.bias', 'align.transformer.encoder.layers.0.norm3.weight', 'align.conv1.0.bias', 'align.conv1.0.weight', 'align.transformer.encoder.layers.0.self_attn2.in_proj_bias']
[2023-05-04 22:00:51,603-rk0-model_load.py# 27] missing keys:8
[2023-05-04 22:00:51,603-rk0-model_load.py# 33] used keys:401
[2023-05-04 22:00:51,620-rk0-train.py#427] (WarmUPScheduler) lr spaces: 
[0.0003     0.00041392 0.0005711  0.00078796 0.00108717 0.0015
 0.0013288  0.00117714 0.00104279 0.00092377 0.00081834 0.00072494
 0.0006422  0.0005689  0.00050397 0.00044645 0.0003955  0.00035036
 0.00031037 0.00027495 0.00024357 0.00021577 0.00019114 0.00016933
 0.00015   ]
[2023-05-04 22:00:51,621-rk0-train.py#428] model prepare done
[2023-05-04 22:00:51,625-rk0-train.py#198] model
.[31mbackbone[0m (ResNet)
         .[31mconv1[0m (Conv2d)
               - [31mweight[0m
         .[31mbn1[0m (BatchNorm2d)
             - [31mweight[0m
             - [31mbias[0m
         .[31mrelu[0m (ReLU)
         .[31mmaxpool[0m (MaxPool2d)
         .[31mlayer1[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer2[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m3[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer3[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m3[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m4[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m5[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer4[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
.[31mneck[0m (AdjustAllLayer)
     .[31mdownsample2[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
     .[31mdownsample3[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
     .[31mdownsample4[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
.[31malign[0m (Adjust_Transformer)
      .[31mrow_embed[0m (Embedding)
                - [31mweight[0m
      .[31mcol_embed[0m (Embedding)
                - [31mweight[0m
      .[31mconv1[0m (Sequential)
            .[31m0[0m (ConvTranspose2d)
              - [31mweight[0m
              - [31mbias[0m
      .[31mtransformer[0m (Transformer)
                  .[31mencoder[0m (TransformerEncoder)
                          .[31mlayers[0m (ModuleList)
                                 .[31m0[0m (TransformerEncoderLayer)
                                   .[31mself_attn[0m (MultiheadAttention)
                                             - [31min_proj_weight[0m
                                             - [31min_proj_bias[0m
                                             .[31mout_proj[0m (NonDynamicallyQuantizableLinear)
                                                      - [31mweight[0m
                                                      - [31mbias[0m
                                   .[31mself_attn2[0m (MultiheadAttention)
                                              - [31min_proj_weight[0m
                                              - [31min_proj_bias[0m
                                              .[31mout_proj[0m (NonDynamicallyQuantizableLinear)
                                                       - [31mweight[0m
                                                       - [31mbias[0m
                                   .[31mcross_attn[0m (Cattention)
                                              - [31mgamma[0m
                                              .[31mconv1[0m (Sequential)
                                                    .[31m0[0m (ConvTranspose2d)
                                                      - [31mweight[0m
                                                      - [31mbias[0m
                                              .[31mavg_pool[0m (AdaptiveAvgPool2d)
                                              .[31mlinear1[0m (Conv2d)
                                                      - [31mweight[0m
                                              .[31mlinear2[0m (Conv2d)
                                                      - [31mweight[0m
                                              .[31mactivation[0m (ReLU)
                                              .[31mdropout[0m (Dropout)
                                   .[31mlinear1[0m (Linear)
                                           - [31mweight[0m
                                           - [31mbias[0m
                                   .[31mdropout[0m (Dropout)
                                   .[31mlinear2[0m (Linear)
                                           - [31mweight[0m
                                           - [31mbias[0m
                                   .[31mnorm0[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm1[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm2[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm3[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mdropout1[0m (Dropout)
                                   .[31mdropout2[0m (Dropout)
                          .[31mnorm[0m (LayerNorm)
                               - [31mweight[0m
                               - [31mbias[0m
                  .[31mdecoder[0m (TransformerDecoder)
                          .[31mlayers[0m (ModuleList)
                          .[31mnorm[0m (LayerNorm)
                               - [31mweight[0m
                               - [31mbias[0m
.[31mcar_head[0m (CARHead)
         .[31mcls_tower[0m (Sequential)
                   .[31m0[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m1[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m2[0m (ReLU)
                   .[31m3[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m4[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m5[0m (ReLU)
                   .[31m6[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m7[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m8[0m (ReLU)
                   .[31m9[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m10[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                   .[31m11[0m (ReLU)
         .[31mbbox_tower[0m (Sequential)
                    .[31m0[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m1[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m2[0m (ReLU)
                    .[31m3[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m4[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m5[0m (ReLU)
                    .[31m6[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m7[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m8[0m (ReLU)
                    .[31m9[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m10[0m (GroupNorm)
                       - [31mweight[0m
                       - [31mbias[0m
                    .[31m11[0m (ReLU)
         .[31mcls_logits[0m (Conv2d)
                    - [31mweight[0m
                    - [31mbias[0m
         .[31mbbox_pred[0m (Conv2d)
                   - [31mweight[0m
                   - [31mbias[0m
         .[31mcenterness[0m (Conv2d)
                    - [31mweight[0m
                    - [31mbias[0m
.[31mdown[0m (ConvTranspose2d)
     - [31mweight[0m
     - [31mbias[0m
[2023-05-04 22:04:25,299-rk0-train.py#371] Version Information: 
commit : 
  log  : 

[2023-05-04 22:04:25,300-rk0-train.py#372] config 
{
    "META_ARC": "udatcar_r50_l234",
    "CUDA": true,
    "TRAIN": {
        "EXEMPLAR_SIZE": 127,
        "SEARCH_SIZE": 255,
        "OUTPUT_SIZE": 25,
        "RESUME": "",
        "RESUME_2": "",
        "RESUME_D": "",
        "RESUME_D_2": "",
        "PRETRAINED": "/home/user/V4R/LHY/MDAT/UDAT/CAR/tools/snapshot/udatcar_model.pth",
        "PRETRAINED_2": "",
        "LOG_DIR": "/home/user/V4R/LHY/MDAT/UDAT/CAR/log/logs-web",
        "SNAPSHOT_DIR": "/home/user/V4R/LHY/MDAT/UDAT/CAR/snapshot-web",
        "EPOCH": 25,
        "START_EPOCH": 0,
        "BATCH_SIZE": 32,
        "NUM_WORKERS": 8,
        "MOMENTUM": 0.9,
        "WEIGHT_DECAY": 0.0001,
        "CLS_WEIGHT": 1.0,
        "LOC_WEIGHT": 3.0,
        "CEN_WEIGHT": 1.0,
        "PRINT_FREQ": 20,
        "LOG_GRADS": false,
        "GRAD_CLIP": 10.0,
        "BASE_LR": 0.0015,
        "BASE_LR_d": 0.005,
        "LR": {
            "TYPE": "log",
            "KWARGS": {
                "start_lr": 0.0015,
                "end_lr": 0.00015
            }
        },
        "LR_WARMUP": {
            "WARMUP": true,
            "TYPE": "step",
            "EPOCH": 5,
            "KWARGS": {
                "start_lr": 0.0003,
                "end_lr": 0.0015,
                "step": 1
            }
        },
        "NUM_CLASSES": 2,
        "NUM_CONVS": 4,
        "PRIOR_PROB": 0.01,
        "LOSS_ALPHA": 0.25,
        "LOSS_GAMMA": 2.0
    },
    "DATASET": {
        "TEMPLATE": {
            "SHIFT": 4,
            "SCALE": 0.05,
            "BLUR": 0.0,
            "FLIP": 0.0,
            "COLOR": 1.0
        },
        "SEARCH": {
            "SHIFT": 64,
            "SCALE": 0.18,
            "BLUR": 0.2,
            "FLIP": 0.0,
            "COLOR": 1.0
        },
        "NEG": 0.0,
        "GRAY": 0.0,
        "SOURCE": [
            "WEB_mid",
            "WEB_ver"
        ],
        "TARGET": [
            "NAT"
        ],
        "VID": {
            "ROOT": "/data1/Train_dataset/vid/crop511",
            "ANNO": "/data1/Train_dataset/vid/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "WEB_mid": {
            "ROOT": "/data2/Train_dataset/WEB3-UAV/train_middle_view/crop_511",
            "ANNO": "/data2/Train_dataset/WEB3-UAV/train_middle_view/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "WEB_ver": {
            "ROOT": "/data2/Train_dataset/WEB3-UAV/train_verticle_view/crop_511",
            "ANNO": "/data2/Train_dataset/WEB3-UAV/train_verticle_view/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "YOUTUBEBB": {
            "ROOT": "train_dataset/yt_bb/crop511",
            "ANNO": "train_dataset/yt_bb/train.json",
            "FRAME_RANGE": 3,
            "NUM_USE": -1
        },
        "COCO": {
            "ROOT": "train_dataset/coco/crop511",
            "ANNO": "train_dataset/coco/train2017.json",
            "FRAME_RANGE": 1,
            "NUM_USE": -1
        },
        "DET": {
            "ROOT": "train_dataset/det/crop511",
            "ANNO": "train_dataset/det/train.json",
            "FRAME_RANGE": 1,
            "NUM_USE": -1
        },
        "GOT": {
            "ROOT": "/data1/Train_dataset/got10k/crop511",
            "ANNO": "/data1/Train_dataset/got10k/train.json",
            "FRAME_RANGE": 50,
            "NUM_USE": -1
        },
        "LaSOT": {
            "ROOT": "train_dataset/lasot/crop511",
            "ANNO": "train_dataset/lasot/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": 100000
        },
        "UAV123": {
            "ROOT": "/data1/Test_dataset/UAV123/crop_511",
            "ANNO": "/data1/Test_dataset/UAV123/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "UAVDT": {
            "ROOT": "/data1/Train_dataset/UAVDT/crop_511",
            "ANNO": "/data1/Train_dataset/UAVDT/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "Track112": {
            "ROOT": "/data1/Test_dataset/UAVTrack112/crop_511",
            "ANNO": "/data1/Test_dataset/UAVTrack112/train.json",
            "FRAME_RANGE": 100,
            "NUM_USE": -1
        },
        "DarkTrack": {
            "ROOT": "/home/mist/v4r/train_dataset/random_train/random_crop511",
            "ANNO": "/home/mist/v4r/train_dataset/random_train/train_random.json",
            "FRAME_RANGE": 50,
            "NUM_USE": 10000
        },
        "NAT": {
            "ROOT": "/data1/Train_dataset/NAT2021-train/random_train/random_crop511",
            "ANNO": "/data1/Train_dataset/NAT2021-train/random_train/train_random.json",
            "FRAME_RANGE": 50,
            "NUM_USE": 10000
        },
        "VIDEOS_PER_EPOCH": 20000,
        "NAMES": [
            "WEB_mid",
            "WEB_ver"
        ]
    },
    "BACKBONE": {
        "TYPE": "resnet50",
        "KWARGS": {
            "used_layers": [
                2,
                3,
                4
            ]
        },
        "PRETRAINED": "",
        "TRAIN_LAYERS": [
            "layer2",
            "layer3",
            "layer4"
        ],
        "LAYERS_LR": 0.1,
        "TRAIN_EPOCH": 0
    },
    "ADJUST": {
        "ADJUST": true,
        "KWARGS": {
            "in_channels": [
                512,
                1024,
                2048
            ],
            "out_channels": [
                256,
                256,
                256
            ]
        },
        "TYPE": "AdjustAllLayer"
    },
    "ALIGN": {
        "ALIGN": true,
        "KWARGS": {
            "channels": 256
        },
        "TYPE": "Adjust_Transformer"
    },
    "CAR": {
        "TYPE": "MultiCAR",
        "KWARGS": {}
    },
    "TRACK": {
        "TYPE": "SiamCARTracker",
        "PENALTY_K": 0.04,
        "WINDOW_INFLUENCE": 0.44,
        "LR": 0.33,
        "EXEMPLAR_SIZE": 127,
        "INSTANCE_SIZE": 255,
        "CONTEXT_AMOUNT": 0.5,
        "STRIDE": 8,
        "SCORE_SIZE": 25,
        "hanming": true,
        "NUM_K": 2,
        "NUM_N": 1,
        "REGION_S": 0.1,
        "REGION_L": 0.44
    },
    "HP_SEARCH": {
        "UAV123": [
            0.39,
            0.04,
            0.37
        ],
        "NAT": [
            0.39,
            0.04,
            0.37
        ],
        "NAT_L": [
            0.39,
            0.04,
            0.37
        ],
        "UAVDark70": [
            0.32,
            0.04,
            0.36
        ]
    }
}
[2023-05-04 22:04:39,835-rk0-train.py# 66] build train dataset
[2023-05-04 22:04:39,836-rk0-dataset.py# 40] loading NAT
[2023-05-04 22:04:40,507-rk0-dataset.py# 65] NAT loaded
[2023-05-04 22:04:40,508-rk0-dataset.py# 96] NAT start-index 0 select [10000/1399] path_format {}.{}.{}.jpg
[2023-05-04 22:04:40,529-rk0-dataset.py#203] shuffle done!
[2023-05-04 22:04:40,529-rk0-dataset.py#204] dataset length 500000
[2023-05-04 22:04:40,533-rk0-train.py# 69] build dataset done
[2023-05-04 22:04:40,533-rk0-train.py# 66] build train dataset
[2023-05-04 22:04:40,533-rk0-dataset.py# 40] loading WEB_mid
[2023-05-04 22:04:43,183-rk0-dataset.py# 65] WEB_mid loaded
[2023-05-04 22:04:43,183-rk0-dataset.py# 96] WEB_mid start-index 0 select [1666/1666] path_format {}.{}.{}.jpg
[2023-05-04 22:04:43,183-rk0-dataset.py# 40] loading WEB_ver
[2023-05-04 22:04:45,332-rk0-dataset.py# 65] WEB_ver loaded
[2023-05-04 22:04:45,333-rk0-dataset.py# 96] WEB_ver start-index 1666 select [1092/1092] path_format {}.{}.{}.jpg
[2023-05-04 22:04:45,366-rk0-dataset.py#203] shuffle done!
[2023-05-04 22:04:45,366-rk0-dataset.py#204] dataset length 500000
[2023-05-04 22:04:45,371-rk0-train.py# 69] build dataset done
[2023-05-04 22:04:45,504-rk0-model_load.py# 48] load pretrained model from /home/user/V4R/LHY/MDAT/UDAT/CAR/tools/snapshot/udatcar_model.pth
[2023-05-04 22:04:45,980-rk0-model_load.py# 42] remove prefix 'module.'
[2023-05-04 22:04:45,983-rk0-model_load.py# 26] [Warning] missing keys: ['align.transformer.encoder.layers.0.self_attn2.in_proj_weight', 'align.transformer.encoder.layers.0.norm3.weight', 'align.conv1.0.bias', 'align.transformer.encoder.layers.0.norm3.bias', 'align.transformer.encoder.layers.0.self_attn2.out_proj.weight', 'align.transformer.encoder.layers.0.self_attn2.in_proj_bias', 'align.transformer.encoder.layers.0.self_attn2.out_proj.bias', 'align.conv1.0.weight']
[2023-05-04 22:04:45,983-rk0-model_load.py# 27] missing keys:8
[2023-05-04 22:04:45,983-rk0-model_load.py# 33] used keys:401
[2023-05-04 22:04:46,002-rk0-train.py#427] (WarmUPScheduler) lr spaces: 
[0.0003     0.00041392 0.0005711  0.00078796 0.00108717 0.0015
 0.0013288  0.00117714 0.00104279 0.00092377 0.00081834 0.00072494
 0.0006422  0.0005689  0.00050397 0.00044645 0.0003955  0.00035036
 0.00031037 0.00027495 0.00024357 0.00021577 0.00019114 0.00016933
 0.00015   ]
[2023-05-04 22:04:46,003-rk0-train.py#428] model prepare done
[2023-05-04 22:04:46,007-rk0-train.py#198] model
.[31mbackbone[0m (ResNet)
         .[31mconv1[0m (Conv2d)
               - [31mweight[0m
         .[31mbn1[0m (BatchNorm2d)
             - [31mweight[0m
             - [31mbias[0m
         .[31mrelu[0m (ReLU)
         .[31mmaxpool[0m (MaxPool2d)
         .[31mlayer1[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer2[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m3[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer3[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m3[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m4[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m5[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
         .[31mlayer4[0m (Sequential)
                .[31m0[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                  .[31mdownsample[0m (Sequential)
                             .[31m0[0m (Conv2d)
                               - [31mweight[0m
                             .[31m1[0m (BatchNorm2d)
                               - [31mweight[0m
                               - [31mbias[0m
                .[31m1[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
                .[31m2[0m (Bottleneck)
                  .[31mconv1[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn1[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv2[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn2[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mconv3[0m (Conv2d)
                        - [31mweight[0m
                  .[31mbn3[0m (BatchNorm2d)
                      - [31mweight[0m
                      - [31mbias[0m
                  .[31mrelu[0m (ReLU)
.[31mneck[0m (AdjustAllLayer)
     .[31mdownsample2[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
     .[31mdownsample3[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
     .[31mdownsample4[0m (AdjustLayer)
                 .[31mdownsample[0m (Sequential)
                            .[31m0[0m (Conv2d)
                              - [31mweight[0m
                            .[31m1[0m (BatchNorm2d)
                              - [31mweight[0m
                              - [31mbias[0m
.[31malign[0m (Adjust_Transformer)
      .[31mrow_embed[0m (Embedding)
                - [31mweight[0m
      .[31mcol_embed[0m (Embedding)
                - [31mweight[0m
      .[31mconv1[0m (Sequential)
            .[31m0[0m (ConvTranspose2d)
              - [31mweight[0m
              - [31mbias[0m
      .[31mtransformer[0m (Transformer)
                  .[31mencoder[0m (TransformerEncoder)
                          .[31mlayers[0m (ModuleList)
                                 .[31m0[0m (TransformerEncoderLayer)
                                   .[31mself_attn[0m (MultiheadAttention)
                                             - [31min_proj_weight[0m
                                             - [31min_proj_bias[0m
                                             .[31mout_proj[0m (NonDynamicallyQuantizableLinear)
                                                      - [31mweight[0m
                                                      - [31mbias[0m
                                   .[31mself_attn2[0m (MultiheadAttention)
                                              - [31min_proj_weight[0m
                                              - [31min_proj_bias[0m
                                              .[31mout_proj[0m (NonDynamicallyQuantizableLinear)
                                                       - [31mweight[0m
                                                       - [31mbias[0m
                                   .[31mcross_attn[0m (Cattention)
                                              - [31mgamma[0m
                                              .[31mconv1[0m (Sequential)
                                                    .[31m0[0m (ConvTranspose2d)
                                                      - [31mweight[0m
                                                      - [31mbias[0m
                                              .[31mavg_pool[0m (AdaptiveAvgPool2d)
                                              .[31mlinear1[0m (Conv2d)
                                                      - [31mweight[0m
                                              .[31mlinear2[0m (Conv2d)
                                                      - [31mweight[0m
                                              .[31mactivation[0m (ReLU)
                                              .[31mdropout[0m (Dropout)
                                   .[31mlinear1[0m (Linear)
                                           - [31mweight[0m
                                           - [31mbias[0m
                                   .[31mdropout[0m (Dropout)
                                   .[31mlinear2[0m (Linear)
                                           - [31mweight[0m
                                           - [31mbias[0m
                                   .[31mnorm0[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm1[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm2[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mnorm3[0m (LayerNorm)
                                         - [31mweight[0m
                                         - [31mbias[0m
                                   .[31mdropout1[0m (Dropout)
                                   .[31mdropout2[0m (Dropout)
                          .[31mnorm[0m (LayerNorm)
                               - [31mweight[0m
                               - [31mbias[0m
                  .[31mdecoder[0m (TransformerDecoder)
                          .[31mlayers[0m (ModuleList)
                          .[31mnorm[0m (LayerNorm)
                               - [31mweight[0m
                               - [31mbias[0m
.[31mcar_head[0m (CARHead)
         .[31mcls_tower[0m (Sequential)
                   .[31m0[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m1[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m2[0m (ReLU)
                   .[31m3[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m4[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m5[0m (ReLU)
                   .[31m6[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m7[0m (GroupNorm)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m8[0m (ReLU)
                   .[31m9[0m (Conv2d)
                     - [31mweight[0m
                     - [31mbias[0m
                   .[31m10[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                   .[31m11[0m (ReLU)
         .[31mbbox_tower[0m (Sequential)
                    .[31m0[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m1[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m2[0m (ReLU)
                    .[31m3[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m4[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m5[0m (ReLU)
                    .[31m6[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m7[0m (GroupNorm)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m8[0m (ReLU)
                    .[31m9[0m (Conv2d)
                      - [31mweight[0m
                      - [31mbias[0m
                    .[31m10[0m (GroupNorm)
                       - [31mweight[0m
                       - [31mbias[0m
                    .[31m11[0m (ReLU)
         .[31mcls_logits[0m (Conv2d)
                    - [31mweight[0m
                    - [31mbias[0m
         .[31mbbox_pred[0m (Conv2d)
                   - [31mweight[0m
                   - [31mbias[0m
         .[31mcenterness[0m (Conv2d)
                    - [31mweight[0m
                    - [31mbias[0m
.[31mdown[0m (ConvTranspose2d)
     - [31mweight[0m
     - [31mbias[0m
[2023-05-04 22:05:45,925-rk0-train.py#348] Epoch: [1][20/625] lr: 0.000300
	batch_time: 2.062751 (2.994712)	data_time: 0.001342 (0.127622)
	loss_fool: 0.042684 (0.342236)	loss_train_adv: 0.100579 (0.724466)
	cen_loss: 0.603505 (0.617814)	cls_loss: 0.051402 (0.070349)
	loc_loss: 0.232285 (0.230760)	total_loss: 1.351762 (1.380443)

[2023-05-04 22:05:45,926-rk0-log_helper.py#102] Progress: 20 / 15625 [0%], Speed: 2.995 s/iter, ETA 0:12:58 (D:H:M)

[2023-05-04 22:06:27,487-rk0-train.py#348] Epoch: [1][40/625] lr: 0.000300
	batch_time: 2.068231 (2.535826)	data_time: 0.000581 (0.064166)
	loss_fool: 0.032075 (0.195667)	loss_train_adv: 0.103959 (0.415402)
	cen_loss: 0.617190 (0.617802)	cls_loss: 0.055063 (0.067275)
	loc_loss: 0.232851 (0.228373)	total_loss: 1.370808 (1.370196)

[2023-05-04 22:06:27,487-rk0-log_helper.py#102] Progress: 40 / 15625 [0%], Speed: 2.536 s/iter, ETA 0:10:58 (D:H:M)

[2023-05-04 22:07:09,080-rk0-train.py#348] Epoch: [1][60/625] lr: 0.000300
	batch_time: 2.086221 (2.383381)	data_time: 0.000415 (0.043047)
	loss_fool: 0.057460 (0.147476)	loss_train_adv: 0.100498 (0.310527)
	cen_loss: 0.616309 (0.617339)	cls_loss: 0.037931 (0.064472)
	loc_loss: 0.178692 (0.223003)	total_loss: 1.190315 (1.350819)

[2023-05-04 22:07:09,080-rk0-log_helper.py#102] Progress: 60 / 15625 [0%], Speed: 2.383 s/iter, ETA 0:10:18 (D:H:M)

[2023-05-04 22:07:51,332-rk0-train.py#348] Epoch: [1][80/625] lr: 0.000300
	batch_time: 2.078914 (2.315390)	data_time: 0.000479 (0.032453)
	loss_fool: 0.051979 (0.123046)	loss_train_adv: 0.100018 (0.257917)
	cen_loss: 0.619653 (0.617036)	cls_loss: 0.062937 (0.064661)
	loc_loss: 0.219633 (0.221058)	total_loss: 1.341489 (1.344869)

[2023-05-04 22:07:51,333-rk0-log_helper.py#102] Progress: 80 / 15625 [0%], Speed: 2.315 s/iter, ETA 0:09:59 (D:H:M)

[2023-05-04 22:08:33,128-rk0-train.py#348] Epoch: [1][100/625] lr: 0.000300
	batch_time: 2.089428 (2.269988)	data_time: 0.001500 (0.026124)
	loss_fool: 0.051051 (0.108457)	loss_train_adv: 0.099968 (0.226331)
	cen_loss: 0.619753 (0.616780)	cls_loss: 0.067281 (0.064421)
	loc_loss: 0.248197 (0.221994)	total_loss: 1.431625 (1.347181)

[2023-05-04 22:08:33,129-rk0-log_helper.py#102] Progress: 100 / 15625 [0%], Speed: 2.270 s/iter, ETA 0:09:47 (D:H:M)

[2023-05-04 22:09:15,086-rk0-train.py#348] Epoch: [1][120/625] lr: 0.000300
	batch_time: 2.107424 (2.090329)	data_time: 0.000769 (0.000737)
	loss_fool: 0.049716 (0.050010)	loss_train_adv: 0.099936 (0.101428)
	cen_loss: 0.613832 (0.616536)	cls_loss: 0.052888 (0.063357)
	loc_loss: 0.212401 (0.218576)	total_loss: 1.303923 (1.335622)

[2023-05-04 22:09:15,086-rk0-log_helper.py#102] Progress: 120 / 15625 [0%], Speed: 2.090 s/iter, ETA 0:09:00 (D:H:M)

[2023-05-04 22:09:56,906-rk0-train.py#348] Epoch: [1][140/625] lr: 0.000300
	batch_time: 2.089402 (2.092881)	data_time: 0.001240 (0.000719)
	loss_fool: 0.050125 (0.050200)	loss_train_adv: 0.099899 (0.100145)
	cen_loss: 0.611353 (0.616437)	cls_loss: 0.046057 (0.064030)
	loc_loss: 0.200333 (0.216518)	total_loss: 1.258408 (1.330021)

[2023-05-04 22:09:56,907-rk0-log_helper.py#102] Progress: 140 / 15625 [0%], Speed: 2.093 s/iter, ETA 0:09:00 (D:H:M)

[2023-05-04 22:10:38,661-rk0-train.py#348] Epoch: [1][160/625] lr: 0.000300
	batch_time: 2.077522 (2.094476)	data_time: 0.001240 (0.000695)
	loss_fool: 0.050085 (0.049991)	loss_train_adv: 0.099853 (0.099965)
	cen_loss: 0.604043 (0.616341)	cls_loss: 0.057083 (0.066045)
	loc_loss: 0.198130 (0.216433)	total_loss: 1.255516 (1.331686)

[2023-05-04 22:10:38,662-rk0-log_helper.py#102] Progress: 160 / 15625 [1%], Speed: 2.094 s/iter, ETA 0:08:59 (D:H:M)

[2023-05-04 22:11:20,450-rk0-train.py#348] Epoch: [1][180/625] lr: 0.000300
	batch_time: 2.115361 (2.089817)	data_time: 0.000446 (0.000691)
	loss_fool: 0.050194 (0.050064)	loss_train_adv: 0.099589 (0.099899)
	cen_loss: 0.605184 (0.616374)	cls_loss: 0.045987 (0.065370)
	loc_loss: 0.244466 (0.216769)	total_loss: 1.384569 (1.332052)

[2023-05-04 22:11:20,450-rk0-log_helper.py#102] Progress: 180 / 15625 [1%], Speed: 2.090 s/iter, ETA 0:08:57 (D:H:M)

[2023-05-04 22:12:02,295-rk0-train.py#348] Epoch: [1][200/625] lr: 0.000300
	batch_time: 2.095850 (2.090317)	data_time: 0.000988 (0.000690)
	loss_fool: 0.064586 (0.050317)	loss_train_adv: 0.100338 (0.099664)
	cen_loss: 0.612852 (0.616275)	cls_loss: 0.057125 (0.064589)
	loc_loss: 0.192779 (0.212729)	total_loss: 1.248312 (1.319050)

[2023-05-04 22:12:02,296-rk0-log_helper.py#102] Progress: 200 / 15625 [1%], Speed: 2.090 s/iter, ETA 0:08:57 (D:H:M)

[2023-05-04 22:12:44,130-rk0-train.py#348] Epoch: [1][220/625] lr: 0.000300
	batch_time: 2.087081 (2.089119)	data_time: 0.000586 (0.000668)
	loss_fool: 0.091266 (0.051878)	loss_train_adv: 0.107730 (0.101011)
	cen_loss: 0.606890 (0.616196)	cls_loss: 0.044708 (0.063955)
	loc_loss: 0.187421 (0.212026)	total_loss: 1.213861 (1.316228)

[2023-05-04 22:12:44,131-rk0-log_helper.py#102] Progress: 220 / 15625 [1%], Speed: 2.089 s/iter, ETA 0:08:56 (D:H:M)

[2023-05-04 22:13:25,864-rk0-train.py#348] Epoch: [1][240/625] lr: 0.000300
	batch_time: 2.064986 (2.088252)	data_time: 0.000489 (0.000685)
	loss_fool: 0.046561 (0.052858)	loss_train_adv: 0.088442 (0.099727)
	cen_loss: 0.623773 (0.616192)	cls_loss: 0.058622 (0.061609)
	loc_loss: 0.212136 (0.211001)	total_loss: 1.318802 (1.310803)

[2023-05-04 22:13:25,864-rk0-log_helper.py#102] Progress: 240 / 15625 [1%], Speed: 2.088 s/iter, ETA 0:08:55 (D:H:M)

[2023-05-04 22:14:08,657-rk0-train.py#348] Epoch: [1][260/625] lr: 0.000300
	batch_time: 2.078502 (2.098595)	data_time: 0.001219 (0.000741)
	loss_fool: 0.056320 (0.058723)	loss_train_adv: 0.080290 (0.097267)
	cen_loss: 0.614047 (0.616342)	cls_loss: 0.039853 (0.059088)
	loc_loss: 0.188399 (0.211896)	total_loss: 1.219097 (1.311119)

[2023-05-04 22:14:08,659-rk0-log_helper.py#102] Progress: 260 / 15625 [1%], Speed: 2.099 s/iter, ETA 0:08:57 (D:H:M)

[2023-05-04 22:14:50,892-rk0-train.py#348] Epoch: [1][280/625] lr: 0.000300
	batch_time: 2.070094 (2.103051)	data_time: 0.000545 (0.000734)
	loss_fool: 0.104932 (0.067556)	loss_train_adv: 0.059661 (0.091578)
	cen_loss: 0.619471 (0.616304)	cls_loss: 0.052676 (0.057915)
	loc_loss: 0.221685 (0.209508)	total_loss: 1.337202 (1.302743)

[2023-05-04 22:14:50,893-rk0-log_helper.py#102] Progress: 280 / 15625 [1%], Speed: 2.103 s/iter, ETA 0:08:57 (D:H:M)

[2023-05-04 22:15:32,603-rk0-train.py#348] Epoch: [1][300/625] lr: 0.000300
	batch_time: 2.094193 (2.101739)	data_time: 0.000442 (0.000672)
	loss_fool: 0.073103 (0.078757)	loss_train_adv: 0.056860 (0.085714)
	cen_loss: 0.607123 (0.616111)	cls_loss: 0.047870 (0.057226)
	loc_loss: 0.196499 (0.208593)	total_loss: 1.244491 (1.299116)

[2023-05-04 22:15:32,604-rk0-log_helper.py#102] Progress: 300 / 15625 [1%], Speed: 2.102 s/iter, ETA 0:08:56 (D:H:M)

[2023-05-04 22:16:14,416-rk0-train.py#348] Epoch: [1][320/625] lr: 0.000300
	batch_time: 2.095595 (2.101487)	data_time: 0.000452 (0.000701)
	loss_fool: 0.169301 (0.091956)	loss_train_adv: 0.063356 (0.075851)
	cen_loss: 0.613471 (0.616022)	cls_loss: 0.078099 (0.057237)
	loc_loss: 0.203531 (0.209228)	total_loss: 1.302163 (1.300942)

[2023-05-04 22:16:14,418-rk0-log_helper.py#102] Progress: 320 / 15625 [2%], Speed: 2.101 s/iter, ETA 0:08:56 (D:H:M)

[2023-05-04 22:16:56,244-rk0-train.py#348] Epoch: [1][340/625] lr: 0.000300
	batch_time: 2.091270 (2.102408)	data_time: 0.000717 (0.000671)
	loss_fool: 0.102689 (0.102623)	loss_train_adv: 0.056002 (0.069621)
	cen_loss: 0.609947 (0.615981)	cls_loss: 0.047817 (0.059589)
	loc_loss: 0.206170 (0.209313)	total_loss: 1.276274 (1.303508)

[2023-05-04 22:16:56,244-rk0-log_helper.py#102] Progress: 340 / 15625 [2%], Speed: 2.102 s/iter, ETA 0:08:55 (D:H:M)

[2023-05-04 22:17:38,124-rk0-train.py#348] Epoch: [1][360/625] lr: 0.000300
	batch_time: 2.083036 (2.093328)	data_time: 0.000523 (0.000599)
	loss_fool: 0.129866 (0.112316)	loss_train_adv: 0.048169 (0.062825)
	cen_loss: 0.618502 (0.615951)	cls_loss: 0.102625 (0.061237)
	loc_loss: 0.254696 (0.209253)	total_loss: 1.485215 (1.304948)

[2023-05-04 22:17:38,125-rk0-log_helper.py#102] Progress: 360 / 15625 [2%], Speed: 2.093 s/iter, ETA 0:08:52 (D:H:M)

[2023-05-04 22:18:19,938-rk0-train.py#348] Epoch: [1][380/625] lr: 0.000300
	batch_time: 2.098707 (2.089122)	data_time: 0.000665 (0.000597)
	loss_fool: 0.064339 (0.120079)	loss_train_adv: 0.064514 (0.057778)
	cen_loss: 0.614030 (0.615846)	cls_loss: 0.080326 (0.062111)
	loc_loss: 0.261039 (0.209692)	total_loss: 1.477473 (1.307031)

[2023-05-04 22:18:19,939-rk0-log_helper.py#102] Progress: 380 / 15625 [2%], Speed: 2.089 s/iter, ETA 0:08:50 (D:H:M)

[2023-05-04 22:19:01,778-rk0-train.py#348] Epoch: [1][400/625] lr: 0.000300
	batch_time: 2.090597 (2.090405)	data_time: 0.000493 (0.000638)
	loss_fool: 0.088566 (0.124414)	loss_train_adv: 0.048069 (0.053666)
	cen_loss: 0.613642 (0.616240)	cls_loss: 0.046330 (0.062041)
	loc_loss: 0.208387 (0.212960)	total_loss: 1.285133 (1.317162)

[2023-05-04 22:19:01,779-rk0-log_helper.py#102] Progress: 400 / 15625 [2%], Speed: 2.090 s/iter, ETA 0:08:50 (D:H:M)

[2023-05-04 22:19:43,648-rk0-train.py#348] Epoch: [1][420/625] lr: 0.000300
	batch_time: 2.079970 (2.091017)	data_time: 0.000427 (0.000639)
	loss_fool: 0.089930 (0.127045)	loss_train_adv: 0.052908 (0.051072)
	cen_loss: 0.612045 (0.616290)	cls_loss: 0.093820 (0.060171)
	loc_loss: 0.226169 (0.211010)	total_loss: 1.384373 (1.309490)

[2023-05-04 22:19:43,649-rk0-log_helper.py#102] Progress: 420 / 15625 [2%], Speed: 2.091 s/iter, ETA 0:08:49 (D:H:M)

[2023-05-04 22:20:25,461-rk0-train.py#348] Epoch: [1][440/625] lr: 0.000300
	batch_time: 2.093475 (2.090893)	data_time: 0.000478 (0.000698)
	loss_fool: 0.168001 (0.134241)	loss_train_adv: 0.035049 (0.046986)
	cen_loss: 0.620777 (0.616280)	cls_loss: 0.057005 (0.059150)
	loc_loss: 0.224992 (0.209730)	total_loss: 1.352757 (1.304621)

[2023-05-04 22:20:25,463-rk0-log_helper.py#102] Progress: 440 / 15625 [2%], Speed: 2.091 s/iter, ETA 0:08:49 (D:H:M)

[2023-05-04 22:21:07,279-rk0-train.py#348] Epoch: [1][460/625] lr: 0.000300
	batch_time: 2.091131 (2.090249)	data_time: 0.000566 (0.000697)
	loss_fool: 0.212584 (0.138251)	loss_train_adv: 0.056654 (0.044630)
	cen_loss: 0.616768 (0.616211)	cls_loss: 0.070964 (0.057802)
	loc_loss: 0.203865 (0.206326)	total_loss: 1.299328 (1.292991)

[2023-05-04 22:21:07,281-rk0-log_helper.py#102] Progress: 460 / 15625 [2%], Speed: 2.090 s/iter, ETA 0:08:48 (D:H:M)

[2023-05-04 22:21:49,525-rk0-train.py#348] Epoch: [1][480/625] lr: 0.000300
	batch_time: 2.083426 (2.094572)	data_time: 0.000600 (0.000709)
	loss_fool: 0.126915 (0.139418)	loss_train_adv: 0.022820 (0.044068)
	cen_loss: 0.621675 (0.616217)	cls_loss: 0.057683 (0.058694)
	loc_loss: 0.184535 (0.205153)	total_loss: 1.232962 (1.290371)

[2023-05-04 22:21:49,526-rk0-log_helper.py#102] Progress: 480 / 15625 [3%], Speed: 2.095 s/iter, ETA 0:08:48 (D:H:M)

[2023-05-04 22:22:31,309-rk0-train.py#348] Epoch: [1][500/625] lr: 0.000300
	batch_time: 2.084800 (2.093995)	data_time: 0.000468 (0.000709)
	loss_fool: 0.179820 (0.143162)	loss_train_adv: 0.042618 (0.042508)
	cen_loss: 0.620376 (0.616179)	cls_loss: 0.077925 (0.060772)
	loc_loss: 0.214025 (0.203831)	total_loss: 1.340376 (1.288442)

[2023-05-04 22:22:31,310-rk0-log_helper.py#102] Progress: 500 / 15625 [3%], Speed: 2.094 s/iter, ETA 0:08:47 (D:H:M)

[2023-05-04 22:23:13,180-rk0-train.py#348] Epoch: [1][520/625] lr: 0.000300
	batch_time: 2.086780 (2.093994)	data_time: 0.000437 (0.000704)
	loss_fool: 0.154265 (0.145131)	loss_train_adv: 0.039936 (0.040960)
	cen_loss: 0.628747 (0.616176)	cls_loss: 0.058464 (0.061915)
	loc_loss: 0.216991 (0.204174)	total_loss: 1.338184 (1.290614)

[2023-05-04 22:23:13,181-rk0-log_helper.py#102] Progress: 520 / 15625 [3%], Speed: 2.094 s/iter, ETA 0:08:47 (D:H:M)

[2023-05-04 22:23:55,044-rk0-train.py#348] Epoch: [1][540/625] lr: 0.000300
	batch_time: 2.099661 (2.094513)	data_time: 0.000482 (0.000649)
	loss_fool: 0.167303 (0.141721)	loss_train_adv: 0.034809 (0.043897)
	cen_loss: 0.618830 (0.615890)	cls_loss: 0.071659 (0.061979)
	loc_loss: 0.216319 (0.204272)	total_loss: 1.339447 (1.290685)

[2023-05-04 22:23:55,045-rk0-log_helper.py#102] Progress: 540 / 15625 [3%], Speed: 2.095 s/iter, ETA 0:08:46 (D:H:M)

[2023-05-04 22:24:36,844-rk0-train.py#348] Epoch: [1][560/625] lr: 0.000300
	batch_time: 2.084029 (2.094353)	data_time: 0.000616 (0.000671)
	loss_fool: 0.145185 (0.141940)	loss_train_adv: 0.026395 (0.042693)
	cen_loss: 0.617993 (0.615777)	cls_loss: 0.054132 (0.061887)
	loc_loss: 0.217385 (0.204942)	total_loss: 1.324279 (1.292489)

[2023-05-04 22:24:36,845-rk0-log_helper.py#102] Progress: 560 / 15625 [3%], Speed: 2.094 s/iter, ETA 0:08:45 (D:H:M)

[2023-05-04 22:25:18,682-rk0-train.py#348] Epoch: [1][580/625] lr: 0.000300
	batch_time: 2.074896 (2.090262)	data_time: 0.000486 (0.000679)
	loss_fool: 0.180226 (0.144394)	loss_train_adv: 0.027100 (0.041207)
	cen_loss: 0.621017 (0.615912)	cls_loss: 0.080439 (0.061250)
	loc_loss: 0.185960 (0.204784)	total_loss: 1.259337 (1.291514)

[2023-05-04 22:25:18,682-rk0-log_helper.py#102] Progress: 580 / 15625 [3%], Speed: 2.090 s/iter, ETA 0:08:44 (D:H:M)

[2023-05-04 22:26:00,600-rk0-train.py#348] Epoch: [1][600/625] lr: 0.000300
	batch_time: 2.113783 (2.091600)	data_time: 0.000769 (0.000679)
	loss_fool: 0.161810 (0.145065)	loss_train_adv: 0.038063 (0.040319)
	cen_loss: 0.616204 (0.615792)	cls_loss: 0.032148 (0.061189)
	loc_loss: 0.166860 (0.204477)	total_loss: 1.148930 (1.290411)

[2023-05-04 22:26:00,601-rk0-log_helper.py#102] Progress: 600 / 15625 [3%], Speed: 2.092 s/iter, ETA 0:08:43 (D:H:M)

[2023-05-04 22:26:42,399-rk0-train.py#348] Epoch: [1][620/625] lr: 0.000300
	batch_time: 2.079384 (2.090892)	data_time: 0.000698 (0.000661)
	loss_fool: 0.212244 (0.145493)	loss_train_adv: 0.049553 (0.040821)
	cen_loss: 0.611908 (0.615501)	cls_loss: 0.042685 (0.060675)
	loc_loss: 0.170691 (0.202896)	total_loss: 1.166664 (1.284865)

[2023-05-04 22:26:42,399-rk0-log_helper.py#102] Progress: 620 / 15625 [3%], Speed: 2.091 s/iter, ETA 0:08:42 (D:H:M)

[2023-05-04 22:26:53,669-rk0-train.py#235] epoch: 2
[2023-05-04 22:26:53,670-rk0-train.py#240] epoch 2 lr 4.139188984383643e-05
[2023-05-04 22:26:53,670-rk0-train.py#240] epoch 2 lr 0.00041391889843836433
[2023-05-04 22:26:53,671-rk0-train.py#240] epoch 2 lr 0.0013797296614612145
[2023-05-04 22:26:53,671-rk0-train.py#240] epoch 2 lr 0.00041391889843836433
[2023-05-04 22:26:53,672-rk0-train.py#240] epoch 2 lr 0.00041391889843836433
[2023-05-04 22:27:25,009-rk0-train.py#348] Epoch: [2][15/625] lr: 0.000414
	batch_time: 2.067918 (2.098352)	data_time: 0.000359 (0.009063)
	loss_fool: 0.155613 (0.150438)	loss_train_adv: 0.029014 (0.036632)
	cen_loss: 0.607801 (0.615277)	cls_loss: 0.036680 (0.060625)
	loc_loss: 0.193484 (0.202473)	total_loss: 1.224934 (1.283321)

[2023-05-04 22:27:25,010-rk0-log_helper.py#102] Progress: 640 / 15625 [4%], Speed: 2.098 s/iter, ETA 0:08:44 (D:H:M)

[2023-05-04 22:28:06,608-rk0-train.py#348] Epoch: [2][35/625] lr: 0.000414
	batch_time: 2.077875 (2.096345)	data_time: 0.000158 (0.009029)
	loss_fool: 0.120302 (0.151917)	loss_train_adv: 0.030552 (0.035374)
	cen_loss: 0.616383 (0.615458)	cls_loss: 0.070195 (0.061030)
	loc_loss: 0.251776 (0.204299)	total_loss: 1.441906 (1.289384)

[2023-05-04 22:28:06,609-rk0-log_helper.py#102] Progress: 660 / 15625 [4%], Speed: 2.096 s/iter, ETA 0:08:42 (D:H:M)

[2023-05-04 22:28:48,766-rk0-train.py#348] Epoch: [2][55/625] lr: 0.000414
	batch_time: 2.113424 (2.099552)	data_time: 0.000618 (0.008995)
	loss_fool: 0.171560 (0.153989)	loss_train_adv: 0.023060 (0.033772)
	cen_loss: 0.611415 (0.614967)	cls_loss: 0.037487 (0.060343)
	loc_loss: 0.214841 (0.206690)	total_loss: 1.293425 (1.295381)

[2023-05-04 22:28:48,767-rk0-log_helper.py#102] Progress: 680 / 15625 [4%], Speed: 2.100 s/iter, ETA 0:08:42 (D:H:M)

[2023-05-04 22:29:30,654-rk0-train.py#348] Epoch: [2][75/625] lr: 0.000414
	batch_time: 2.106492 (2.099265)	data_time: 0.002048 (0.008968)
	loss_fool: 0.243901 (0.156898)	loss_train_adv: 0.039278 (0.032148)
	cen_loss: 0.618545 (0.614928)	cls_loss: 0.069760 (0.058663)
	loc_loss: 0.221515 (0.205156)	total_loss: 1.352850 (1.289059)

[2023-05-04 22:29:30,655-rk0-log_helper.py#102] Progress: 700 / 15625 [4%], Speed: 2.099 s/iter, ETA 0:08:42 (D:H:M)

[2023-05-04 22:30:12,357-rk0-train.py#348] Epoch: [2][95/625] lr: 0.000414
	batch_time: 2.084029 (2.098312)	data_time: 0.000695 (0.008940)
	loss_fool: 0.199049 (0.158793)	loss_train_adv: 0.022042 (0.030218)
	cen_loss: 0.613424 (0.615287)	cls_loss: 0.065383 (0.060210)
	loc_loss: 0.200665 (0.206321)	total_loss: 1.280802 (1.294460)

[2023-05-04 22:30:12,357-rk0-log_helper.py#102] Progress: 720 / 15625 [4%], Speed: 2.098 s/iter, ETA 0:08:41 (D:H:M)

[2023-05-04 22:30:54,162-rk0-train.py#348] Epoch: [2][115/625] lr: 0.000414
	batch_time: 2.092885 (2.090240)	data_time: 0.000744 (0.000539)
	loss_fool: 0.186380 (0.160074)	loss_train_adv: 0.032667 (0.029170)
	cen_loss: 0.616723 (0.615592)	cls_loss: 0.070520 (0.060828)
	loc_loss: 0.213580 (0.207158)	total_loss: 1.327982 (1.297895)

[2023-05-04 22:30:54,163-rk0-log_helper.py#102] Progress: 740 / 15625 [4%], Speed: 2.090 s/iter, ETA 0:08:38 (D:H:M)

[2023-05-04 22:31:35,832-rk0-train.py#348] Epoch: [2][135/625] lr: 0.000414
	batch_time: 2.076931 (2.090944)	data_time: 0.000436 (0.000525)
	loss_fool: 0.161021 (0.161518)	loss_train_adv: 0.019643 (0.028829)
	cen_loss: 0.621210 (0.615038)	cls_loss: 0.095519 (0.060073)
	loc_loss: 0.214724 (0.203912)	total_loss: 1.360901 (1.286848)

[2023-05-04 22:31:35,832-rk0-log_helper.py#102] Progress: 760 / 15625 [4%], Speed: 2.091 s/iter, ETA 0:08:38 (D:H:M)

[2023-05-04 22:32:17,483-rk0-train.py#348] Epoch: [2][155/625] lr: 0.000414
	batch_time: 2.080222 (2.085912)	data_time: 0.000667 (0.000515)
	loss_fool: 0.191232 (0.161272)	loss_train_adv: 0.023037 (0.029149)
	cen_loss: 0.615441 (0.615766)	cls_loss: 0.069576 (0.061639)
	loc_loss: 0.199993 (0.203860)	total_loss: 1.284995 (1.288985)

[2023-05-04 22:32:17,484-rk0-log_helper.py#102] Progress: 780 / 15625 [4%], Speed: 2.086 s/iter, ETA 0:08:36 (D:H:M)

[2023-05-04 22:32:59,143-rk0-train.py#348] Epoch: [2][175/625] lr: 0.000414
	batch_time: 2.117853 (2.083652)	data_time: 0.000742 (0.000508)
	loss_fool: 0.173098 (0.161884)	loss_train_adv: 0.029611 (0.027860)
	cen_loss: 0.618160 (0.615570)	cls_loss: 0.063908 (0.062153)
	loc_loss: 0.198115 (0.203962)	total_loss: 1.276412 (1.289609)

[2023-05-04 22:32:59,145-rk0-log_helper.py#102] Progress: 800 / 15625 [5%], Speed: 2.084 s/iter, ETA 0:08:34 (D:H:M)

[2023-05-04 22:33:41,506-rk0-train.py#348] Epoch: [2][195/625] lr: 0.000414
	batch_time: 2.102234 (2.090243)	data_time: 0.000689 (0.000516)
	loss_fool: 0.162879 (0.163082)	loss_train_adv: 0.022918 (0.026886)
	cen_loss: 0.615003 (0.615247)	cls_loss: 0.039273 (0.061792)
	loc_loss: 0.168736 (0.203868)	total_loss: 1.160484 (1.288642)

[2023-05-04 22:33:41,508-rk0-log_helper.py#102] Progress: 820 / 15625 [5%], Speed: 2.090 s/iter, ETA 0:08:35 (D:H:M)

[2023-05-04 22:34:23,244-rk0-train.py#348] Epoch: [2][215/625] lr: 0.000414
	batch_time: 2.090914 (2.089583)	data_time: 0.000167 (0.000491)
	loss_fool: 0.156132 (0.164581)	loss_train_adv: 0.026856 (0.025556)
	cen_loss: 0.614042 (0.615062)	cls_loss: 0.123406 (0.060270)
	loc_loss: 0.221127 (0.204326)	total_loss: 1.400830 (1.288310)

[2023-05-04 22:34:23,245-rk0-log_helper.py#102] Progress: 840 / 15625 [5%], Speed: 2.090 s/iter, ETA 0:08:34 (D:H:M)

[2023-05-04 22:35:05,011-rk0-train.py#348] Epoch: [2][235/625] lr: 0.000414
	batch_time: 2.080302 (2.090541)	data_time: 0.000175 (0.000484)
	loss_fool: 0.113822 (0.164534)	loss_train_adv: 0.038581 (0.025592)
	cen_loss: 0.619718 (0.615466)	cls_loss: 0.047416 (0.059955)
	loc_loss: 0.212349 (0.206683)	total_loss: 1.304179 (1.295470)

[2023-05-04 22:35:05,012-rk0-log_helper.py#102] Progress: 860 / 15625 [5%], Speed: 2.091 s/iter, ETA 0:08:34 (D:H:M)

[2023-05-04 22:35:46,745-rk0-train.py#348] Epoch: [2][255/625] lr: 0.000414
	batch_time: 2.086984 (2.091336)	data_time: 0.000520 (0.000473)
	loss_fool: 0.166306 (0.166167)	loss_train_adv: 0.021856 (0.024317)
	cen_loss: 0.623774 (0.615207)	cls_loss: 0.092320 (0.058270)
	loc_loss: 0.220187 (0.204702)	total_loss: 1.376656 (1.287582)

[2023-05-04 22:35:46,747-rk0-log_helper.py#102] Progress: 880 / 15625 [5%], Speed: 2.091 s/iter, ETA 0:08:33 (D:H:M)

[2023-05-04 22:36:28,465-rk0-train.py#348] Epoch: [2][275/625] lr: 0.000414
	batch_time: 2.087679 (2.091921)	data_time: 0.000638 (0.000466)
	loss_fool: 0.167244 (0.165952)	loss_train_adv: 0.029171 (0.024936)
	cen_loss: 0.618597 (0.615490)	cls_loss: 0.047009 (0.058013)
	loc_loss: 0.227056 (0.206310)	total_loss: 1.346775 (1.292434)

[2023-05-04 22:36:28,467-rk0-log_helper.py#102] Progress: 900 / 15625 [5%], Speed: 2.092 s/iter, ETA 0:08:33 (D:H:M)

[2023-05-04 22:37:10,153-rk0-train.py#348] Epoch: [2][295/625] lr: 0.000414
	batch_time: 2.088496 (2.085176)	data_time: 0.000461 (0.000454)
	loss_fool: 0.116669 (0.166376)	loss_train_adv: 0.026944 (0.024577)
	cen_loss: 0.617987 (0.615662)	cls_loss: 0.073140 (0.056841)
	loc_loss: 0.197331 (0.206227)	total_loss: 1.283118 (1.291186)

[2023-05-04 22:37:10,155-rk0-log_helper.py#102] Progress: 920 / 15625 [5%], Speed: 2.085 s/iter, ETA 0:08:31 (D:H:M)

[2023-05-04 22:37:52,000-rk0-train.py#348] Epoch: [2][315/625] lr: 0.000414
	batch_time: 2.086097 (2.086254)	data_time: 0.000481 (0.000439)
	loss_fool: 0.220426 (0.164495)	loss_train_adv: 0.045018 (0.026329)
	cen_loss: 0.612634 (0.615361)	cls_loss: 0.068470 (0.058375)
	loc_loss: 0.198832 (0.204317)	total_loss: 1.277598 (1.286688)

[2023-05-04 22:37:52,002-rk0-log_helper.py#102] Progress: 940 / 15625 [6%], Speed: 2.086 s/iter, ETA 0:08:30 (D:H:M)

[2023-05-04 22:38:33,807-rk0-train.py#348] Epoch: [2][335/625] lr: 0.000414
	batch_time: 2.087571 (2.086653)	data_time: 0.000610 (0.000456)
	loss_fool: 0.137383 (0.166202)	loss_train_adv: 0.029896 (0.025836)
	cen_loss: 0.616104 (0.615303)	cls_loss: 0.052700 (0.058764)
	loc_loss: 0.214169 (0.203601)	total_loss: 1.311311 (1.284871)

[2023-05-04 22:38:33,809-rk0-log_helper.py#102] Progress: 960 / 15625 [6%], Speed: 2.087 s/iter, ETA 0:08:30 (D:H:M)

[2023-05-04 22:39:15,742-rk0-train.py#348] Epoch: [2][355/625] lr: 0.000414
	batch_time: 2.084404 (2.088656)	data_time: 0.000678 (0.000473)
	loss_fool: 0.188866 (0.166192)	loss_train_adv: 0.015852 (0.025638)
	cen_loss: 0.611443 (0.614737)	cls_loss: 0.064930 (0.058005)
	loc_loss: 0.179034 (0.202747)	total_loss: 1.213474 (1.280984)

[2023-05-04 22:39:15,742-rk0-log_helper.py#102] Progress: 980 / 15625 [6%], Speed: 2.089 s/iter, ETA 0:08:29 (D:H:M)

[2023-05-04 22:39:57,549-rk0-train.py#348] Epoch: [2][375/625] lr: 0.000414
	batch_time: 2.103837 (2.089537)	data_time: 0.000157 (0.000476)
	loss_fool: 0.212108 (0.166401)	loss_train_adv: 0.035020 (0.025852)
	cen_loss: 0.616529 (0.614622)	cls_loss: 0.050475 (0.058372)
	loc_loss: 0.180920 (0.201735)	total_loss: 1.209764 (1.278198)

[2023-05-04 22:39:57,550-rk0-log_helper.py#102] Progress: 1000 / 15625 [6%], Speed: 2.090 s/iter, ETA 0:08:29 (D:H:M)

[2023-05-04 22:40:39,366-rk0-train.py#348] Epoch: [2][395/625] lr: 0.000414
	batch_time: 2.098403 (2.090820)	data_time: 0.000154 (0.000467)
	loss_fool: 0.152724 (0.163510)	loss_train_adv: 0.034991 (0.027595)
	cen_loss: 0.618249 (0.614597)	cls_loss: 0.078787 (0.059389)
	loc_loss: 0.226364 (0.201678)	total_loss: 1.376129 (1.279020)

[2023-05-04 22:40:39,368-rk0-log_helper.py#102] Progress: 1020 / 15625 [6%], Speed: 2.091 s/iter, ETA 0:08:28 (D:H:M)

[2023-05-04 22:41:21,539-rk0-train.py#348] Epoch: [2][415/625] lr: 0.000414
	batch_time: 2.078078 (2.094096)	data_time: 0.000480 (0.000462)
	loss_fool: 0.116834 (0.163621)	loss_train_adv: 0.042307 (0.027514)
	cen_loss: 0.615274 (0.614650)	cls_loss: 0.065632 (0.056934)
	loc_loss: 0.208331 (0.202772)	total_loss: 1.305897 (1.279901)

[2023-05-04 22:41:21,541-rk0-log_helper.py#102] Progress: 1040 / 15625 [6%], Speed: 2.094 s/iter, ETA 0:08:29 (D:H:M)

[2023-05-04 22:42:03,275-rk0-train.py#348] Epoch: [2][435/625] lr: 0.000414
	batch_time: 2.098481 (2.093385)	data_time: 0.000731 (0.000466)
	loss_fool: 0.088335 (0.159134)	loss_train_adv: 0.040644 (0.029479)
	cen_loss: 0.613671 (0.614432)	cls_loss: 0.050534 (0.058362)
	loc_loss: 0.196360 (0.201877)	total_loss: 1.253287 (1.278423)

[2023-05-04 22:42:03,277-rk0-log_helper.py#102] Progress: 1060 / 15625 [6%], Speed: 2.093 s/iter, ETA 0:08:28 (D:H:M)

[2023-05-04 22:42:44,954-rk0-train.py#348] Epoch: [2][455/625] lr: 0.000414
	batch_time: 2.092819 (2.090838)	data_time: 0.000192 (0.000452)
	loss_fool: 0.168839 (0.158920)	loss_train_adv: 0.023980 (0.030345)
	cen_loss: 0.616618 (0.614919)	cls_loss: 0.059291 (0.059819)
	loc_loss: 0.205848 (0.204271)	total_loss: 1.293454 (1.287552)

[2023-05-04 22:42:44,956-rk0-log_helper.py#102] Progress: 1080 / 15625 [6%], Speed: 2.091 s/iter, ETA 0:08:26 (D:H:M)

[2023-05-04 22:43:26,732-rk0-train.py#348] Epoch: [2][475/625] lr: 0.000414
	batch_time: 2.077882 (2.090530)	data_time: 0.000149 (0.000394)
	loss_fool: 0.155534 (0.158657)	loss_train_adv: 0.022158 (0.030212)
	cen_loss: 0.612767 (0.614890)	cls_loss: 0.044456 (0.058846)
	loc_loss: 0.183612 (0.202472)	total_loss: 1.208058 (1.281152)

[2023-05-04 22:43:26,733-rk0-log_helper.py#102] Progress: 1100 / 15625 [7%], Speed: 2.091 s/iter, ETA 0:08:26 (D:H:M)

[2023-05-04 22:44:08,652-rk0-train.py#348] Epoch: [2][495/625] lr: 0.000414
	batch_time: 2.111774 (2.091517)	data_time: 0.000646 (0.000420)
	loss_fool: 0.177952 (0.159040)	loss_train_adv: 0.034440 (0.030351)
	cen_loss: 0.611143 (0.614979)	cls_loss: 0.072647 (0.057881)
	loc_loss: 0.218220 (0.200552)	total_loss: 1.338450 (1.274517)

[2023-05-04 22:44:08,654-rk0-log_helper.py#102] Progress: 1120 / 15625 [7%], Speed: 2.092 s/iter, ETA 0:08:25 (D:H:M)

[2023-05-04 22:44:50,536-rk0-train.py#348] Epoch: [2][515/625] lr: 0.000414
	batch_time: 2.099372 (2.088613)	data_time: 0.000197 (0.000421)
	loss_fool: 0.168714 (0.158769)	loss_train_adv: 0.028789 (0.029775)
	cen_loss: 0.616085 (0.615067)	cls_loss: 0.055217 (0.058660)
	loc_loss: 0.191683 (0.199844)	total_loss: 1.246350 (1.273257)

[2023-05-04 22:44:50,536-rk0-log_helper.py#102] Progress: 1140 / 15625 [7%], Speed: 2.089 s/iter, ETA 0:08:24 (D:H:M)

[2023-05-04 22:45:32,333-rk0-train.py#348] Epoch: [2][535/625] lr: 0.000414
	batch_time: 2.092296 (2.089240)	data_time: 0.000165 (0.000420)
	loss_fool: 0.097759 (0.160288)	loss_train_adv: 0.042290 (0.028790)
	cen_loss: 0.611455 (0.615461)	cls_loss: 0.049000 (0.057638)
	loc_loss: 0.189718 (0.199568)	total_loss: 1.229610 (1.271804)

[2023-05-04 22:45:32,335-rk0-log_helper.py#102] Progress: 1160 / 15625 [7%], Speed: 2.089 s/iter, ETA 0:08:23 (D:H:M)

[2023-05-04 22:46:14,173-rk0-train.py#348] Epoch: [2][555/625] lr: 0.000414
	batch_time: 2.092703 (2.090825)	data_time: 0.000737 (0.000437)
	loss_fool: 0.168161 (0.160099)	loss_train_adv: 0.025384 (0.028475)
	cen_loss: 0.612055 (0.615203)	cls_loss: 0.053127 (0.056749)
	loc_loss: 0.200987 (0.197091)	total_loss: 1.268142 (1.263225)

[2023-05-04 22:46:14,173-rk0-log_helper.py#102] Progress: 1180 / 15625 [7%], Speed: 2.091 s/iter, ETA 0:08:23 (D:H:M)

[2023-05-04 22:46:56,030-rk0-train.py#348] Epoch: [2][575/625] lr: 0.000414
	batch_time: 2.097229 (2.091625)	data_time: 0.000191 (0.000501)
	loss_fool: 0.200159 (0.159224)	loss_train_adv: 0.028605 (0.028371)
	cen_loss: 0.617754 (0.614902)	cls_loss: 0.048773 (0.056355)
	loc_loss: 0.219575 (0.197708)	total_loss: 1.325253 (1.264381)

[2023-05-04 22:46:56,031-rk0-log_helper.py#102] Progress: 1200 / 15625 [7%], Speed: 2.092 s/iter, ETA 0:08:22 (D:H:M)

[2023-05-04 22:47:37,846-rk0-train.py#348] Epoch: [2][595/625] lr: 0.000414
	batch_time: 2.086962 (2.090638)	data_time: 0.000277 (0.000481)
	loss_fool: 0.185058 (0.161603)	loss_train_adv: 0.025681 (0.026587)
	cen_loss: 0.609206 (0.614679)	cls_loss: 0.044733 (0.056906)
	loc_loss: 0.173446 (0.199217)	total_loss: 1.174276 (1.269235)

[2023-05-04 22:47:37,848-rk0-log_helper.py#102] Progress: 1220 / 15625 [7%], Speed: 2.091 s/iter, ETA 0:08:21 (D:H:M)

[2023-05-04 22:48:20,285-rk0-train.py#348] Epoch: [2][615/625] lr: 0.000414
	batch_time: 2.087127 (2.096184)	data_time: 0.000134 (0.000498)
	loss_fool: 0.202017 (0.164243)	loss_train_adv: 0.027262 (0.025174)
	cen_loss: 0.609456 (0.614657)	cls_loss: 0.065367 (0.055717)
	loc_loss: 0.184549 (0.197688)	total_loss: 1.228470 (1.263437)

[2023-05-04 22:48:20,285-rk0-log_helper.py#102] Progress: 1240 / 15625 [7%], Speed: 2.096 s/iter, ETA 0:08:22 (D:H:M)

[2023-05-04 22:48:42,000-rk0-train.py#235] epoch: 3
[2023-05-04 22:48:42,000-rk0-train.py#240] epoch 3 lr 5.7109618161476344e-05
[2023-05-04 22:48:42,001-rk0-train.py#240] epoch 3 lr 0.0005710961816147635
[2023-05-04 22:48:42,001-rk0-train.py#240] epoch 3 lr 0.001903653938715878
[2023-05-04 22:48:42,002-rk0-train.py#240] epoch 3 lr 0.0005710961816147635
[2023-05-04 22:48:42,002-rk0-train.py#240] epoch 3 lr 0.0005710961816147635
[2023-05-04 22:49:02,941-rk0-train.py#348] Epoch: [3][10/625] lr: 0.000571
	batch_time: 2.079589 (2.104786)	data_time: 0.000614 (0.008407)
	loss_fool: 0.143156 (0.165605)	loss_train_adv: 0.021424 (0.024350)
	cen_loss: 0.619489 (0.614376)	cls_loss: 0.047641 (0.054737)
	loc_loss: 0.184057 (0.197719)	total_loss: 1.219301 (1.262269)

[2023-05-04 22:49:02,942-rk0-log_helper.py#102] Progress: 1260 / 15625 [8%], Speed: 2.105 s/iter, ETA 0:08:23 (D:H:M)

[2023-05-04 22:49:44,710-rk0-train.py#348] Epoch: [3][30/625] lr: 0.000571
	batch_time: 2.089051 (2.104084)	data_time: 0.000707 (0.008396)
	loss_fool: 0.173450 (0.166552)	loss_train_adv: 0.021700 (0.023738)
	cen_loss: 0.615311 (0.614467)	cls_loss: 0.050058 (0.055451)
	loc_loss: 0.198610 (0.198976)	total_loss: 1.261199 (1.266848)

[2023-05-04 22:49:44,711-rk0-log_helper.py#102] Progress: 1280 / 15625 [8%], Speed: 2.104 s/iter, ETA 0:08:23 (D:H:M)

[2023-05-04 22:50:26,481-rk0-train.py#348] Epoch: [3][50/625] lr: 0.000571
	batch_time: 2.087744 (2.103215)	data_time: 0.000586 (0.008375)
	loss_fool: 0.142380 (0.166326)	loss_train_adv: 0.019454 (0.023744)
	cen_loss: 0.613470 (0.614799)	cls_loss: 0.049060 (0.056122)
	loc_loss: 0.183970 (0.199029)	total_loss: 1.214440 (1.268009)

[2023-05-04 22:50:26,482-rk0-log_helper.py#102] Progress: 1300 / 15625 [8%], Speed: 2.103 s/iter, ETA 0:08:22 (D:H:M)

[2023-05-04 22:51:08,272-rk0-train.py#348] Epoch: [3][70/625] lr: 0.000571
	batch_time: 2.080980 (2.102958)	data_time: 0.000600 (0.008406)
	loss_fool: 0.129734 (0.167724)	loss_train_adv: 0.022771 (0.023283)
	cen_loss: 0.615289 (0.614827)	cls_loss: 0.047887 (0.056133)
	loc_loss: 0.198248 (0.198121)	total_loss: 1.257920 (1.265322)

[2023-05-04 22:51:08,273-rk0-log_helper.py#102] Progress: 1320 / 15625 [8%], Speed: 2.103 s/iter, ETA 0:08:21 (D:H:M)

[2023-05-04 22:51:49,931-rk0-train.py#348] Epoch: [3][90/625] lr: 0.000571
	batch_time: 2.090401 (2.095191)	data_time: 0.000744 (0.008422)
	loss_fool: 0.182287 (0.167488)	loss_train_adv: 0.018973 (0.023082)
	cen_loss: 0.610895 (0.615102)	cls_loss: 0.065013 (0.057093)
	loc_loss: 0.199640 (0.198385)	total_loss: 1.274828 (1.267350)

[2023-05-04 22:51:49,932-rk0-log_helper.py#102] Progress: 1340 / 15625 [8%], Speed: 2.095 s/iter, ETA 0:08:18 (D:H:M)

[2023-05-04 22:52:31,676-rk0-train.py#348] Epoch: [3][110/625] lr: 0.000571
	batch_time: 2.080609 (2.086038)	data_time: 0.000671 (0.000490)
	loss_fool: 0.174550 (0.168458)	loss_train_adv: 0.013379 (0.022310)
	cen_loss: 0.610450 (0.615153)	cls_loss: 0.048234 (0.057617)
	loc_loss: 0.183671 (0.198407)	total_loss: 1.209695 (1.267991)

[2023-05-04 22:52:31,678-rk0-log_helper.py#102] Progress: 1360 / 15625 [8%], Speed: 2.086 s/iter, ETA 0:08:15 (D:H:M)

[2023-05-04 22:53:13,372-rk0-train.py#348] Epoch: [3][130/625] lr: 0.000571
	batch_time: 2.069893 (2.085303)	data_time: 0.000692 (0.000498)
	loss_fool: 0.211140 (0.168793)	loss_train_adv: 0.021062 (0.022445)
	cen_loss: 0.617894 (0.615087)	cls_loss: 0.047660 (0.057388)
	loc_loss: 0.191448 (0.198095)	total_loss: 1.239898 (1.266760)

[2023-05-04 22:53:13,373-rk0-log_helper.py#102] Progress: 1380 / 15625 [8%], Speed: 2.085 s/iter, ETA 0:08:15 (D:H:M)

[2023-05-04 22:53:55,266-rk0-train.py#348] Epoch: [3][150/625] lr: 0.000571
	batch_time: 2.096764 (2.086532)	data_time: 0.000679 (0.000537)
	loss_fool: 0.163629 (0.170346)	loss_train_adv: 0.014375 (0.021386)
	cen_loss: 0.615986 (0.614942)	cls_loss: 0.034299 (0.058217)
	loc_loss: 0.179751 (0.198740)	total_loss: 1.189537 (1.269378)

[2023-05-04 22:53:55,267-rk0-log_helper.py#102] Progress: 1400 / 15625 [8%], Speed: 2.087 s/iter, ETA 0:08:14 (D:H:M)

[2023-05-04 22:54:37,039-rk0-train.py#348] Epoch: [3][170/625] lr: 0.000571
	batch_time: 2.077200 (2.086349)	data_time: 0.000714 (0.000549)
	loss_fool: 0.163859 (0.169461)	loss_train_adv: 0.023867 (0.021437)
	cen_loss: 0.619191 (0.615280)	cls_loss: 0.056384 (0.058764)
	loc_loss: 0.178771 (0.200551)	total_loss: 1.211886 (1.275698)

[2023-05-04 22:54:37,040-rk0-log_helper.py#102] Progress: 1420 / 15625 [9%], Speed: 2.086 s/iter, ETA 0:08:13 (D:H:M)

[2023-05-04 22:55:19,126-rk0-train.py#348] Epoch: [3][190/625] lr: 0.000571
	batch_time: 2.069700 (2.090629)	data_time: 0.000573 (0.000535)
	loss_fool: 0.153879 (0.171309)	loss_train_adv: 0.024808 (0.020834)
	cen_loss: 0.611238 (0.615054)	cls_loss: 0.047977 (0.058592)
	loc_loss: 0.196464 (0.200676)	total_loss: 1.248607 (1.275675)

[2023-05-04 22:55:19,128-rk0-log_helper.py#102] Progress: 1440 / 15625 [9%], Speed: 2.091 s/iter, ETA 0:08:14 (D:H:M)

[2023-05-04 22:56:00,857-rk0-train.py#348] Epoch: [3][210/625] lr: 0.000571
	batch_time: 2.100658 (2.090495)	data_time: 0.000717 (0.000558)
	loss_fool: 0.163353 (0.171006)	loss_train_adv: 0.026246 (0.020742)
	cen_loss: 0.620342 (0.614985)	cls_loss: 0.060189 (0.058886)
	loc_loss: 0.213943 (0.201654)	total_loss: 1.322360 (1.278831)

[2023-05-04 22:56:00,858-rk0-log_helper.py#102] Progress: 1460 / 15625 [9%], Speed: 2.090 s/iter, ETA 0:08:13 (D:H:M)

[2023-05-04 22:56:42,669-rk0-train.py#348] Epoch: [3][230/625] lr: 0.000571
	batch_time: 2.093118 (2.091694)	data_time: 0.000124 (0.000556)
	loss_fool: 0.188445 (0.170036)	loss_train_adv: 0.020369 (0.021455)
	cen_loss: 0.615218 (0.614798)	cls_loss: 0.151233 (0.058992)
	loc_loss: 0.230561 (0.200014)	total_loss: 1.458134 (1.273832)

[2023-05-04 22:56:42,670-rk0-log_helper.py#102] Progress: 1480 / 15625 [9%], Speed: 2.092 s/iter, ETA 0:08:13 (D:H:M)

[2023-05-04 22:57:24,484-rk0-train.py#348] Epoch: [3][250/625] lr: 0.000571
	batch_time: 2.096480 (2.090914)	data_time: 0.000581 (0.000549)
	loss_fool: 0.182057 (0.168912)	loss_train_adv: 0.020600 (0.022119)
	cen_loss: 0.615907 (0.614901)	cls_loss: 0.059250 (0.058051)
	loc_loss: 0.210592 (0.199449)	total_loss: 1.306934 (1.271299)

[2023-05-04 22:57:24,485-rk0-log_helper.py#102] Progress: 1500 / 15625 [9%], Speed: 2.091 s/iter, ETA 0:08:12 (D:H:M)

[2023-05-04 22:58:06,240-rk0-train.py#348] Epoch: [3][270/625] lr: 0.000571
	batch_time: 2.095077 (2.090757)	data_time: 0.000413 (0.000531)
	loss_fool: 0.196478 (0.170268)	loss_train_adv: 0.021210 (0.021407)
	cen_loss: 0.617624 (0.614533)	cls_loss: 0.043288 (0.057813)
	loc_loss: 0.189048 (0.198918)	total_loss: 1.228057 (1.269099)

[2023-05-04 22:58:06,240-rk0-log_helper.py#102] Progress: 1520 / 15625 [9%], Speed: 2.091 s/iter, ETA 0:08:11 (D:H:M)

[2023-05-04 22:58:48,020-rk0-train.py#348] Epoch: [3][290/625] lr: 0.000571
	batch_time: 2.083616 (2.087699)	data_time: 0.002085 (0.000547)
	loss_fool: 0.162637 (0.169057)	loss_train_adv: 0.015855 (0.021813)
	cen_loss: 0.609318 (0.614780)	cls_loss: 0.042865 (0.058220)
	loc_loss: 0.180777 (0.198797)	total_loss: 1.194513 (1.269392)

[2023-05-04 22:58:48,021-rk0-log_helper.py#102] Progress: 1540 / 15625 [9%], Speed: 2.088 s/iter, ETA 0:08:10 (D:H:M)

[2023-05-04 22:59:29,844-rk0-train.py#348] Epoch: [3][310/625] lr: 0.000571
	batch_time: 2.086305 (2.088656)	data_time: 0.000636 (0.000532)
	loss_fool: 0.200657 (0.170676)	loss_train_adv: 0.016045 (0.020926)
	cen_loss: 0.617278 (0.614691)	cls_loss: 0.055011 (0.058149)
	loc_loss: 0.213954 (0.198394)	total_loss: 1.314152 (1.268023)

[2023-05-04 22:59:29,845-rk0-log_helper.py#102] Progress: 1560 / 15625 [9%], Speed: 2.089 s/iter, ETA 0:08:09 (D:H:M)

[2023-05-04 23:00:12,086-rk0-train.py#348] Epoch: [3][330/625] lr: 0.000571
	batch_time: 2.072200 (2.092968)	data_time: 0.001101 (0.000554)
	loss_fool: 0.157032 (0.172269)	loss_train_adv: 0.017690 (0.019080)
	cen_loss: 0.616864 (0.614726)	cls_loss: 0.045667 (0.057268)
	loc_loss: 0.166422 (0.199297)	total_loss: 1.161796 (1.269885)

[2023-05-04 23:00:12,087-rk0-log_helper.py#102] Progress: 1580 / 15625 [10%], Speed: 2.093 s/iter, ETA 0:08:09 (D:H:M)

[2023-05-04 23:00:53,825-rk0-train.py#348] Epoch: [3][350/625] lr: 0.000571
	batch_time: 2.098655 (2.092227)	data_time: 0.000630 (0.000538)
	loss_fool: 0.140489 (0.173949)	loss_train_adv: 0.025164 (0.017997)
	cen_loss: 0.612326 (0.614453)	cls_loss: 0.063793 (0.056589)
	loc_loss: 0.212404 (0.198173)	total_loss: 1.313330 (1.265560)

[2023-05-04 23:00:53,826-rk0-log_helper.py#102] Progress: 1600 / 15625 [10%], Speed: 2.092 s/iter, ETA 0:08:09 (D:H:M)

[2023-05-04 23:01:35,555-rk0-train.py#348] Epoch: [3][370/625] lr: 0.000571
	batch_time: 2.084350 (2.091977)	data_time: 0.000395 (0.000561)
	loss_fool: 0.173300 (0.174666)	loss_train_adv: 0.016071 (0.017707)
	cen_loss: 0.616293 (0.614436)	cls_loss: 0.051702 (0.055337)
	loc_loss: 0.186982 (0.197758)	total_loss: 1.228943 (1.263047)

[2023-05-04 23:01:35,557-rk0-log_helper.py#102] Progress: 1620 / 15625 [10%], Speed: 2.092 s/iter, ETA 0:08:08 (D:H:M)

[2023-05-04 23:02:17,223-rk0-train.py#348] Epoch: [3][390/625] lr: 0.000571
	batch_time: 2.072395 (2.090851)	data_time: 0.000575 (0.000567)
	loss_fool: 0.177308 (0.176247)	loss_train_adv: 0.016360 (0.017720)
	cen_loss: 0.618416 (0.614224)	cls_loss: 0.063436 (0.056483)
	loc_loss: 0.207186 (0.198317)	total_loss: 1.303411 (1.265659)

[2023-05-04 23:02:17,224-rk0-log_helper.py#102] Progress: 1640 / 15625 [10%], Speed: 2.091 s/iter, ETA 0:08:07 (D:H:M)

[2023-05-04 23:02:58,899-rk0-train.py#348] Epoch: [3][410/625] lr: 0.000571
	batch_time: 2.103541 (2.089382)	data_time: 0.000632 (0.000579)
	loss_fool: 0.175680 (0.175706)	loss_train_adv: 0.020038 (0.017629)
	cen_loss: 0.602198 (0.613949)	cls_loss: 0.044844 (0.055800)
	loc_loss: 0.179157 (0.197561)	total_loss: 1.184514 (1.262431)

[2023-05-04 23:02:58,900-rk0-log_helper.py#102] Progress: 1660 / 15625 [10%], Speed: 2.089 s/iter, ETA 0:08:06 (D:H:M)

[2023-05-04 23:03:40,516-rk0-train.py#348] Epoch: [3][430/625] lr: 0.000571
	batch_time: 2.095307 (2.083132)	data_time: 0.000715 (0.000547)
	loss_fool: 0.126035 (0.173881)	loss_train_adv: 0.025592 (0.018742)
	cen_loss: 0.612525 (0.614062)	cls_loss: 0.043346 (0.056527)
	loc_loss: 0.189618 (0.197602)	total_loss: 1.224725 (1.263394)

[2023-05-04 23:03:40,517-rk0-log_helper.py#102] Progress: 1680 / 15625 [10%], Speed: 2.083 s/iter, ETA 0:08:04 (D:H:M)

[2023-05-04 23:04:22,226-rk0-train.py#348] Epoch: [3][450/625] lr: 0.000571
	batch_time: 2.087790 (2.082825)	data_time: 0.000819 (0.000543)
	loss_fool: 0.171896 (0.174342)	loss_train_adv: 0.021129 (0.018778)
	cen_loss: 0.613078 (0.614225)	cls_loss: 0.049448 (0.056446)
	loc_loss: 0.175254 (0.197402)	total_loss: 1.188287 (1.262876)

[2023-05-04 23:04:22,227-rk0-log_helper.py#102] Progress: 1700 / 15625 [10%], Speed: 2.083 s/iter, ETA 0:08:03 (D:H:M)

[2023-05-04 23:05:03,899-rk0-train.py#348] Epoch: [3][470/625] lr: 0.000571
	batch_time: 2.076848 (2.082263)	data_time: 0.000552 (0.000518)
	loss_fool: 0.199842 (0.174942)	loss_train_adv: 0.016741 (0.018666)
	cen_loss: 0.623685 (0.614303)	cls_loss: 0.070840 (0.056169)
	loc_loss: 0.236276 (0.197372)	total_loss: 1.403352 (1.262587)

[2023-05-04 23:05:03,900-rk0-log_helper.py#102] Progress: 1720 / 15625 [11%], Speed: 2.082 s/iter, ETA 0:08:02 (D:H:M)

[2023-05-04 23:05:45,677-rk0-train.py#348] Epoch: [3][490/625] lr: 0.000571
	batch_time: 2.096411 (2.083365)	data_time: 0.000683 (0.000514)
	loss_fool: 0.175934 (0.174580)	loss_train_adv: 0.009470 (0.017400)
	cen_loss: 0.615626 (0.614390)	cls_loss: 0.117926 (0.055592)
	loc_loss: 0.203594 (0.196243)	total_loss: 1.344334 (1.258712)

[2023-05-04 23:05:45,678-rk0-log_helper.py#102] Progress: 1740 / 15625 [11%], Speed: 2.083 s/iter, ETA 0:08:02 (D:H:M)

[2023-05-04 23:06:27,380-rk0-train.py#348] Epoch: [3][510/625] lr: 0.000571
	batch_time: 2.089468 (2.083644)	data_time: 0.000773 (0.000518)
	loss_fool: 0.181617 (0.175506)	loss_train_adv: 0.014310 (0.017362)
	cen_loss: 0.608368 (0.614593)	cls_loss: 0.035293 (0.055823)
	loc_loss: 0.184398 (0.195772)	total_loss: 1.196855 (1.257732)

[2023-05-04 23:06:27,381-rk0-log_helper.py#102] Progress: 1760 / 15625 [11%], Speed: 2.084 s/iter, ETA 0:08:01 (D:H:M)

[2023-05-04 23:07:09,039-rk0-train.py#348] Epoch: [3][530/625] lr: 0.000571
	batch_time: 2.080982 (2.084041)	data_time: 0.000469 (0.000521)
	loss_fool: 0.136385 (0.175353)	loss_train_adv: 0.019145 (0.017582)
	cen_loss: 0.608532 (0.615056)	cls_loss: 0.057032 (0.055818)
	loc_loss: 0.236826 (0.197051)	total_loss: 1.376043 (1.262026)

[2023-05-04 23:07:09,041-rk0-log_helper.py#102] Progress: 1780 / 15625 [11%], Speed: 2.084 s/iter, ETA 0:08:00 (D:H:M)

[2023-05-04 23:07:51,271-rk0-train.py#348] Epoch: [3][550/625] lr: 0.000571
	batch_time: 2.097084 (2.089281)	data_time: 0.000376 (0.000521)
	loss_fool: 0.171088 (0.175031)	loss_train_adv: 0.012635 (0.017947)
	cen_loss: 0.613818 (0.615267)	cls_loss: 0.077760 (0.056674)
	loc_loss: 0.214499 (0.197077)	total_loss: 1.335073 (1.263172)

[2023-05-04 23:07:51,271-rk0-log_helper.py#102] Progress: 1800 / 15625 [11%], Speed: 2.089 s/iter, ETA 0:08:01 (D:H:M)

[2023-05-04 23:08:32,938-rk0-train.py#348] Epoch: [3][570/625] lr: 0.000571
	batch_time: 2.068157 (2.089242)	data_time: 0.000451 (0.000508)
	loss_fool: 0.162827 (0.172927)	loss_train_adv: 0.016628 (0.018730)
	cen_loss: 0.615816 (0.615211)	cls_loss: 0.053738 (0.056784)
	loc_loss: 0.211534 (0.196280)	total_loss: 1.304157 (1.260834)

[2023-05-04 23:08:32,939-rk0-log_helper.py#102] Progress: 1820 / 15625 [11%], Speed: 2.089 s/iter, ETA 0:08:00 (D:H:M)

[2023-05-04 23:09:14,503-rk0-train.py#348] Epoch: [3][590/625] lr: 0.000571
	batch_time: 2.081177 (2.087128)	data_time: 0.000625 (0.000492)
	loss_fool: 0.121006 (0.170907)	loss_train_adv: 0.026643 (0.020886)
	cen_loss: 0.610417 (0.615000)	cls_loss: 0.037463 (0.055675)
	loc_loss: 0.169615 (0.196129)	total_loss: 1.156726 (1.259062)

[2023-05-04 23:09:14,504-rk0-log_helper.py#102] Progress: 1840 / 15625 [11%], Speed: 2.087 s/iter, ETA 0:07:59 (D:H:M)

[2023-05-04 23:09:56,190-rk0-train.py#348] Epoch: [3][610/625] lr: 0.000571
	batch_time: 2.068709 (2.086946)	data_time: 0.000552 (0.000505)
	loss_fool: 0.156666 (0.168625)	loss_train_adv: 0.025230 (0.022145)
	cen_loss: 0.608237 (0.614931)	cls_loss: 0.040776 (0.055226)
	loc_loss: 0.196785 (0.197941)	total_loss: 1.239367 (1.263980)

[2023-05-04 23:09:56,191-rk0-log_helper.py#102] Progress: 1860 / 15625 [11%], Speed: 2.087 s/iter, ETA 0:07:58 (D:H:M)

[2023-05-04 23:10:28,185-rk0-train.py#235] epoch: 4
[2023-05-04 23:10:28,185-rk0-train.py#240] epoch 4 lr 7.8795834132113e-05
[2023-05-04 23:10:28,185-rk0-train.py#240] epoch 4 lr 0.0007879583413211298
[2023-05-04 23:10:28,186-rk0-train.py#240] epoch 4 lr 0.0026265278044037663
[2023-05-04 23:10:28,186-rk0-train.py#240] epoch 4 lr 0.0007879583413211298
[2023-05-04 23:10:28,186-rk0-train.py#240] epoch 4 lr 0.0007879583413211298
[2023-05-04 23:10:38,618-rk0-train.py#348] Epoch: [4][5/625] lr: 0.000788
	batch_time: 2.072717 (2.094613)	data_time: 0.000599 (0.008210)
	loss_fool: 0.197140 (0.168885)	loss_train_adv: 0.019330 (0.022264)
	cen_loss: 0.607285 (0.614447)	cls_loss: 0.038945 (0.054377)
	loc_loss: 0.169801 (0.195708)	total_loss: 1.155634 (1.255948)

[2023-05-04 23:10:38,619-rk0-log_helper.py#102] Progress: 1880 / 15625 [12%], Speed: 2.095 s/iter, ETA 0:07:59 (D:H:M)

[2023-05-04 23:11:20,324-rk0-train.py#348] Epoch: [4][25/625] lr: 0.000788
	batch_time: 2.057544 (2.089350)	data_time: 0.000434 (0.008220)
	loss_fool: 0.185793 (0.168073)	loss_train_adv: 0.035624 (0.022912)
	cen_loss: 0.608861 (0.614088)	cls_loss: 0.045779 (0.053737)
	loc_loss: 0.187335 (0.198230)	total_loss: 1.216645 (1.262515)

[2023-05-04 23:11:20,324-rk0-log_helper.py#102] Progress: 1900 / 15625 [12%], Speed: 2.089 s/iter, ETA 0:07:57 (D:H:M)

[2023-05-04 23:12:02,073-rk0-train.py#348] Epoch: [4][45/625] lr: 0.000788
	batch_time: 2.092906 (2.090136)	data_time: 0.000711 (0.008241)
	loss_fool: 0.134959 (0.167209)	loss_train_adv: 0.019696 (0.023453)
	cen_loss: 0.605577 (0.613961)	cls_loss: 0.034963 (0.054298)
	loc_loss: 0.176252 (0.198147)	total_loss: 1.169296 (1.262701)

[2023-05-04 23:12:02,074-rk0-log_helper.py#102] Progress: 1920 / 15625 [12%], Speed: 2.090 s/iter, ETA 0:07:57 (D:H:M)

[2023-05-04 23:12:43,758-rk0-train.py#348] Epoch: [4][65/625] lr: 0.000788
	batch_time: 2.082155 (2.091315)	data_time: 0.000426 (0.008265)
	loss_fool: 0.157394 (0.168583)	loss_train_adv: 0.020146 (0.022484)
	cen_loss: 0.616308 (0.613838)	cls_loss: 0.048868 (0.054179)
	loc_loss: 0.214759 (0.197786)	total_loss: 1.309454 (1.261374)

[2023-05-04 23:12:43,760-rk0-log_helper.py#102] Progress: 1940 / 15625 [12%], Speed: 2.091 s/iter, ETA 0:07:56 (D:H:M)

[2023-05-04 23:13:25,377-rk0-train.py#348] Epoch: [4][85/625] lr: 0.000788
	batch_time: 2.081918 (2.090650)	data_time: 0.000549 (0.008239)
	loss_fool: 0.146134 (0.169759)	loss_train_adv: 0.018358 (0.021087)
	cen_loss: 0.624407 (0.614128)	cls_loss: 0.051270 (0.055121)
	loc_loss: 0.211619 (0.196567)	total_loss: 1.310533 (1.258951)

[2023-05-04 23:13:25,379-rk0-log_helper.py#102] Progress: 1960 / 15625 [12%], Speed: 2.091 s/iter, ETA 0:07:56 (D:H:M)

[2023-05-04 23:14:07,454-rk0-train.py#348] Epoch: [4][105/625] lr: 0.000788
	batch_time: 2.079799 (2.087186)	data_time: 0.000670 (0.000541)
	loss_fool: 0.183742 (0.172943)	loss_train_adv: 0.009148 (0.019186)
	cen_loss: 0.610377 (0.613892)	cls_loss: 0.045475 (0.054338)
	loc_loss: 0.175337 (0.195821)	total_loss: 1.181861 (1.255692)

[2023-05-04 23:14:07,456-rk0-log_helper.py#102] Progress: 1980 / 15625 [12%], Speed: 2.087 s/iter, ETA 0:07:54 (D:H:M)

[2023-05-04 23:14:49,142-rk0-train.py#348] Epoch: [4][125/625] lr: 0.000788
	batch_time: 2.084230 (2.087004)	data_time: 0.000612 (0.000542)
	loss_fool: 0.216693 (0.174771)	loss_train_adv: 0.014212 (0.017740)
	cen_loss: 0.617893 (0.614055)	cls_loss: 0.029559 (0.054199)
	loc_loss: 0.161109 (0.193967)	total_loss: 1.130778 (1.250154)

[2023-05-04 23:14:49,143-rk0-log_helper.py#102] Progress: 2000 / 15625 [12%], Speed: 2.087 s/iter, ETA 0:07:53 (D:H:M)

[2023-05-04 23:15:30,770-rk0-train.py#348] Epoch: [4][145/625] lr: 0.000788
	batch_time: 2.068448 (2.085800)	data_time: 0.000643 (0.000526)
	loss_fool: 0.201068 (0.177057)	loss_train_adv: 0.007077 (0.016422)
	cen_loss: 0.607143 (0.614145)	cls_loss: 0.055295 (0.055908)
	loc_loss: 0.189469 (0.194393)	total_loss: 1.230845 (1.253232)

[2023-05-04 23:15:30,770-rk0-log_helper.py#102] Progress: 2020 / 15625 [12%], Speed: 2.086 s/iter, ETA 0:07:52 (D:H:M)

[2023-05-04 23:16:12,405-rk0-train.py#348] Epoch: [4][165/625] lr: 0.000788
	batch_time: 2.084329 (2.085322)	data_time: 0.000641 (0.000504)
	loss_fool: 0.182638 (0.177866)	loss_train_adv: 0.014491 (0.015562)
	cen_loss: 0.618956 (0.614361)	cls_loss: 0.066598 (0.056410)
	loc_loss: 0.210591 (0.194076)	total_loss: 1.317327 (1.253000)

[2023-05-04 23:16:12,406-rk0-log_helper.py#102] Progress: 2040 / 15625 [13%], Speed: 2.085 s/iter, ETA 0:07:52 (D:H:M)

[2023-05-04 23:16:53,982-rk0-train.py#348] Epoch: [4][185/625] lr: 0.000788
	batch_time: 2.076076 (2.084920)	data_time: 0.000655 (0.000506)
	loss_fool: 0.207537 (0.178177)	loss_train_adv: 0.022733 (0.016155)
	cen_loss: 0.609915 (0.614219)	cls_loss: 0.040198 (0.056932)
	loc_loss: 0.182026 (0.193558)	total_loss: 1.196189 (1.251824)

[2023-05-04 23:16:53,983-rk0-log_helper.py#102] Progress: 2060 / 15625 [13%], Speed: 2.085 s/iter, ETA 0:07:51 (D:H:M)

[2023-05-04 23:17:35,541-rk0-train.py#348] Epoch: [4][205/625] lr: 0.000788
	batch_time: 2.085294 (2.079750)	data_time: 0.000399 (0.000501)
	loss_fool: 0.212985 (0.175903)	loss_train_adv: 0.017942 (0.017369)
	cen_loss: 0.622082 (0.614728)	cls_loss: 0.066131 (0.057519)
	loc_loss: 0.209045 (0.195201)	total_loss: 1.315349 (1.257849)

[2023-05-04 23:17:35,542-rk0-log_helper.py#102] Progress: 2080 / 15625 [13%], Speed: 2.080 s/iter, ETA 0:07:49 (D:H:M)

[2023-05-04 23:18:17,156-rk0-train.py#348] Epoch: [4][225/625] lr: 0.000788
	batch_time: 2.077167 (2.079012)	data_time: 0.000767 (0.000493)
	loss_fool: 0.162162 (0.175319)	loss_train_adv: 0.011540 (0.017575)
	cen_loss: 0.614931 (0.614813)	cls_loss: 0.040279 (0.057635)
	loc_loss: 0.197002 (0.195527)	total_loss: 1.246215 (1.259029)

[2023-05-04 23:18:17,157-rk0-log_helper.py#102] Progress: 2100 / 15625 [13%], Speed: 2.079 s/iter, ETA 0:07:48 (D:H:M)

[2023-05-04 23:18:58,921-rk0-train.py#348] Epoch: [4][245/625] lr: 0.000788
	batch_time: 2.086232 (2.080378)	data_time: 0.000718 (0.000517)
	loss_fool: 0.159165 (0.174490)	loss_train_adv: 0.020075 (0.017731)
	cen_loss: 0.614078 (0.614589)	cls_loss: 0.048368 (0.056453)
	loc_loss: 0.187086 (0.194905)	total_loss: 1.223704 (1.255756)

[2023-05-04 23:18:58,922-rk0-log_helper.py#102] Progress: 2120 / 15625 [13%], Speed: 2.080 s/iter, ETA 0:07:48 (D:H:M)

[2023-05-04 23:19:40,679-rk0-train.py#348] Epoch: [4][265/625] lr: 0.000788
	batch_time: 2.089275 (2.081585)	data_time: 0.000773 (0.000532)
	loss_fool: 0.177009 (0.173872)	loss_train_adv: 0.022032 (0.018590)
	cen_loss: 0.613226 (0.614740)	cls_loss: 0.051602 (0.057356)
	loc_loss: 0.216910 (0.197843)	total_loss: 1.315557 (1.265624)

[2023-05-04 23:19:40,680-rk0-log_helper.py#102] Progress: 2140 / 15625 [13%], Speed: 2.082 s/iter, ETA 0:07:47 (D:H:M)

[2023-05-04 23:20:22,391-rk0-train.py#348] Epoch: [4][285/625] lr: 0.000788
	batch_time: 2.064022 (2.082910)	data_time: 0.000408 (0.000541)
	loss_fool: 0.186419 (0.173728)	loss_train_adv: 0.032257 (0.018752)
	cen_loss: 0.623700 (0.614780)	cls_loss: 0.094018 (0.057104)
	loc_loss: 0.211164 (0.198266)	total_loss: 1.351210 (1.266681)

[2023-05-04 23:20:22,392-rk0-log_helper.py#102] Progress: 2160 / 15625 [13%], Speed: 2.083 s/iter, ETA 0:07:47 (D:H:M)

[2023-05-04 23:21:04,559-rk0-train.py#348] Epoch: [4][305/625] lr: 0.000788
	batch_time: 2.076982 (2.088980)	data_time: 0.000601 (0.000565)
	loss_fool: 0.154187 (0.174378)	loss_train_adv: 0.021448 (0.018179)
	cen_loss: 0.606527 (0.614568)	cls_loss: 0.048721 (0.058558)
	loc_loss: 0.181661 (0.198385)	total_loss: 1.200232 (1.268280)

[2023-05-04 23:21:04,559-rk0-log_helper.py#102] Progress: 2180 / 15625 [13%], Speed: 2.089 s/iter, ETA 0:07:48 (D:H:M)

[2023-05-04 23:21:46,376-rk0-train.py#348] Epoch: [4][325/625] lr: 0.000788
	batch_time: 2.090529 (2.090988)	data_time: 0.000188 (0.000564)
	loss_fool: 0.177603 (0.174760)	loss_train_adv: 0.016179 (0.017693)
	cen_loss: 0.621291 (0.615036)	cls_loss: 0.035820 (0.058372)
	loc_loss: 0.187320 (0.198475)	total_loss: 1.219071 (1.268835)

[2023-05-04 23:21:46,377-rk0-log_helper.py#102] Progress: 2200 / 15625 [14%], Speed: 2.091 s/iter, ETA 0:07:47 (D:H:M)

[2023-05-04 23:22:28,126-rk0-train.py#348] Epoch: [4][345/625] lr: 0.000788
	batch_time: 2.085918 (2.090848)	data_time: 0.000710 (0.000542)
	loss_fool: 0.148806 (0.174611)	loss_train_adv: 0.014440 (0.017914)
	cen_loss: 0.608775 (0.614993)	cls_loss: 0.044624 (0.058171)
	loc_loss: 0.195469 (0.198958)	total_loss: 1.239804 (1.270039)

[2023-05-04 23:22:28,128-rk0-log_helper.py#102] Progress: 2220 / 15625 [14%], Speed: 2.091 s/iter, ETA 0:07:47 (D:H:M)

[2023-05-04 23:23:09,803-rk0-train.py#348] Epoch: [4][365/625] lr: 0.000788
	batch_time: 2.068502 (2.090034)	data_time: 0.000586 (0.000516)
	loss_fool: 0.166732 (0.175367)	loss_train_adv: 0.010957 (0.017616)
	cen_loss: 0.613815 (0.614688)	cls_loss: 0.044694 (0.055732)
	loc_loss: 0.215849 (0.196938)	total_loss: 1.306055 (1.261236)

[2023-05-04 23:23:09,803-rk0-log_helper.py#102] Progress: 2240 / 15625 [14%], Speed: 2.090 s/iter, ETA 0:07:46 (D:H:M)

[2023-05-04 23:23:51,612-rk0-train.py#348] Epoch: [4][385/625] lr: 0.000788
	batch_time: 2.089174 (2.090988)	data_time: 0.000150 (0.000495)
	loss_fool: 0.189351 (0.176666)	loss_train_adv: 0.009550 (0.016502)
	cen_loss: 0.614020 (0.614607)	cls_loss: 0.038112 (0.056398)
	loc_loss: 0.176098 (0.196264)	total_loss: 1.180424 (1.259795)

[2023-05-04 23:23:51,614-rk0-log_helper.py#102] Progress: 2260 / 15625 [14%], Speed: 2.091 s/iter, ETA 0:07:45 (D:H:M)

[2023-05-04 23:24:33,417-rk0-train.py#348] Epoch: [4][405/625] lr: 0.000788
	batch_time: 2.076905 (2.087348)	data_time: 0.000665 (0.000474)
	loss_fool: 0.126382 (0.173965)	loss_train_adv: 0.017878 (0.018075)
	cen_loss: 0.617665 (0.614892)	cls_loss: 0.039000 (0.055471)
	loc_loss: 0.204479 (0.196257)	total_loss: 1.270103 (1.259135)

[2023-05-04 23:24:33,419-rk0-log_helper.py#102] Progress: 2280 / 15625 [14%], Speed: 2.087 s/iter, ETA 0:07:44 (D:H:M)

[2023-05-04 23:25:15,233-rk0-train.py#348] Epoch: [4][425/625] lr: 0.000788
	batch_time: 2.097975 (2.087329)	data_time: 0.000326 (0.000446)
	loss_fool: 0.208066 (0.174839)	loss_train_adv: 0.022487 (0.019767)
	cen_loss: 0.612452 (0.614217)	cls_loss: 0.042382 (0.055307)
	loc_loss: 0.205574 (0.195518)	total_loss: 1.271556 (1.256078)

[2023-05-04 23:25:15,235-rk0-log_helper.py#102] Progress: 2300 / 15625 [14%], Speed: 2.087 s/iter, ETA 0:07:43 (D:H:M)

[2023-05-04 23:25:57,005-rk0-train.py#348] Epoch: [4][445/625] lr: 0.000788
	batch_time: 2.083802 (2.087522)	data_time: 0.000395 (0.000458)
	loss_fool: 0.172818 (0.174127)	loss_train_adv: 0.021591 (0.019899)
	cen_loss: 0.614210 (0.614262)	cls_loss: 0.034854 (0.054608)
	loc_loss: 0.171713 (0.193902)	total_loss: 1.164205 (1.250576)

[2023-05-04 23:25:57,007-rk0-log_helper.py#102] Progress: 2320 / 15625 [14%], Speed: 2.088 s/iter, ETA 0:07:42 (D:H:M)

[2023-05-04 23:26:38,750-rk0-train.py#348] Epoch: [4][465/625] lr: 0.000788
	batch_time: 2.093858 (2.088191)	data_time: 0.000638 (0.000476)
	loss_fool: 0.245928 (0.174295)	loss_train_adv: 0.025440 (0.019763)
	cen_loss: 0.614891 (0.614205)	cls_loss: 0.118224 (0.055571)
	loc_loss: 0.202612 (0.193985)	total_loss: 1.340952 (1.251730)

[2023-05-04 23:26:38,751-rk0-log_helper.py#102] Progress: 2340 / 15625 [14%], Speed: 2.088 s/iter, ETA 0:07:42 (D:H:M)

[2023-05-04 23:27:20,441-rk0-train.py#348] Epoch: [4][485/625] lr: 0.000788
	batch_time: 2.067216 (2.087016)	data_time: 0.000134 (0.000481)
	loss_fool: 0.173853 (0.172957)	loss_train_adv: 0.008335 (0.019968)
	cen_loss: 0.608482 (0.613784)	cls_loss: 0.040328 (0.053312)
	loc_loss: 0.191930 (0.194603)	total_loss: 1.224598 (1.250904)

[2023-05-04 23:27:20,443-rk0-log_helper.py#102] Progress: 2360 / 15625 [15%], Speed: 2.087 s/iter, ETA 0:07:41 (D:H:M)

[2023-05-04 23:28:02,146-rk0-train.py#348] Epoch: [4][505/625] lr: 0.000788
	batch_time: 2.093797 (2.086019)	data_time: 0.000569 (0.000479)
	loss_fool: 0.179437 (0.176113)	loss_train_adv: 0.011369 (0.017844)
	cen_loss: 0.600533 (0.613261)	cls_loss: 0.042251 (0.054221)
	loc_loss: 0.187118 (0.194232)	total_loss: 1.204139 (1.250179)

[2023-05-04 23:28:02,148-rk0-log_helper.py#102] Progress: 2380 / 15625 [15%], Speed: 2.086 s/iter, ETA 0:07:40 (D:H:M)

[2023-05-04 23:28:44,612-rk0-train.py#348] Epoch: [4][525/625] lr: 0.000788
	batch_time: 2.086836 (2.092534)	data_time: 0.000585 (0.000516)
	loss_fool: 0.163558 (0.175987)	loss_train_adv: 0.016587 (0.016080)
	cen_loss: 0.616796 (0.613730)	cls_loss: 0.038701 (0.054476)
	loc_loss: 0.196586 (0.194057)	total_loss: 1.245255 (1.250378)

[2023-05-04 23:28:44,614-rk0-log_helper.py#102] Progress: 2400 / 15625 [15%], Speed: 2.093 s/iter, ETA 0:07:41 (D:H:M)

[2023-05-04 23:29:26,348-rk0-train.py#348] Epoch: [4][545/625] lr: 0.000788
	batch_time: 2.075536 (2.092163)	data_time: 0.000471 (0.000502)
	loss_fool: 0.168833 (0.178156)	loss_train_adv: 0.015197 (0.014868)
	cen_loss: 0.612276 (0.614079)	cls_loss: 0.055833 (0.055911)
	loc_loss: 0.220133 (0.196001)	total_loss: 1.328509 (1.257994)

[2023-05-04 23:29:26,349-rk0-log_helper.py#102] Progress: 2420 / 15625 [15%], Speed: 2.092 s/iter, ETA 0:07:40 (D:H:M)

[2023-05-04 23:30:08,133-rk0-train.py#348] Epoch: [4][565/625] lr: 0.000788
	batch_time: 2.094104 (2.092578)	data_time: 0.000750 (0.000504)
	loss_fool: 0.160129 (0.178908)	loss_train_adv: 0.019622 (0.014320)
	cen_loss: 0.614959 (0.614035)	cls_loss: 0.058868 (0.055644)
	loc_loss: 0.198123 (0.195943)	total_loss: 1.268196 (1.257507)

[2023-05-04 23:30:08,134-rk0-log_helper.py#102] Progress: 2440 / 15625 [15%], Speed: 2.093 s/iter, ETA 0:07:39 (D:H:M)

[2023-05-04 23:30:49,864-rk0-train.py#348] Epoch: [4][585/625] lr: 0.000788
	batch_time: 2.084049 (2.092978)	data_time: 0.000701 (0.000526)
	loss_fool: 0.151748 (0.179168)	loss_train_adv: 0.018224 (0.015028)
	cen_loss: 0.608881 (0.614253)	cls_loss: 0.041292 (0.056310)
	loc_loss: 0.185902 (0.195724)	total_loss: 1.207879 (1.257736)

[2023-05-04 23:30:49,866-rk0-log_helper.py#102] Progress: 2460 / 15625 [15%], Speed: 2.093 s/iter, ETA 0:07:39 (D:H:M)

[2023-05-04 23:31:31,680-rk0-train.py#348] Epoch: [4][605/625] lr: 0.000788
	batch_time: 2.098915 (2.094070)	data_time: 0.000589 (0.000517)
	loss_fool: 0.166109 (0.178140)	loss_train_adv: 0.014348 (0.015354)
	cen_loss: 0.609779 (0.614276)	cls_loss: 0.040473 (0.056249)
	loc_loss: 0.174797 (0.194510)	total_loss: 1.174642 (1.254055)

[2023-05-04 23:31:31,681-rk0-log_helper.py#102] Progress: 2480 / 15625 [15%], Speed: 2.094 s/iter, ETA 0:07:38 (D:H:M)

[2023-05-04 23:32:13,534-rk0-train.py#348] Epoch: [4][0/625] lr: 0.000788
	batch_time: 2.091649 (2.087937)	data_time: 0.000566 (0.000524)
	loss_fool: 0.160079 (0.178225)	loss_train_adv: 0.017961 (0.015468)
	cen_loss: 0.614721 (0.614133)	cls_loss: 0.040418 (0.057513)
	loc_loss: 0.199990 (0.194788)	total_loss: 1.255110 (1.256010)

[2023-05-04 23:32:13,535-rk0-log_helper.py#102] Progress: 2500 / 15625 [16%], Speed: 2.088 s/iter, ETA 0:07:36 (D:H:M)

[2023-05-04 23:32:14,396-rk0-train.py#235] epoch: 5
[2023-05-04 23:32:14,396-rk0-train.py#240] epoch 5 lr 0.00010871694955165431
[2023-05-04 23:32:14,397-rk0-train.py#240] epoch 5 lr 0.0010871694955165432
[2023-05-04 23:32:14,397-rk0-train.py#240] epoch 5 lr 0.003623898318388477
[2023-05-04 23:32:14,397-rk0-train.py#240] epoch 5 lr 0.0010871694955165432
[2023-05-04 23:32:14,397-rk0-train.py#240] epoch 5 lr 0.0010871694955165432
[2023-05-04 23:32:56,103-rk0-train.py#348] Epoch: [5][20/625] lr: 0.001087
	batch_time: 2.092378 (2.096270)	data_time: 0.000154 (0.009112)
	loss_fool: 0.193278 (0.176855)	loss_train_adv: 0.019951 (0.016633)
	cen_loss: 0.620304 (0.613900)	cls_loss: 0.059328 (0.056856)
	loc_loss: 0.233018 (0.194686)	total_loss: 1.378687 (1.254814)

[2023-05-04 23:32:56,105-rk0-log_helper.py#102] Progress: 2520 / 15625 [16%], Speed: 2.096 s/iter, ETA 0:07:37 (D:H:M)

[2023-05-04 23:33:37,701-rk0-train.py#348] Epoch: [5][40/625] lr: 0.001087
	batch_time: 2.074959 (2.094396)	data_time: 0.000660 (0.009067)
	loss_fool: 0.175408 (0.175182)	loss_train_adv: 0.021574 (0.017015)
	cen_loss: 0.604927 (0.614180)	cls_loss: 0.036086 (0.057407)
	loc_loss: 0.167411 (0.195263)	total_loss: 1.143245 (1.257375)

[2023-05-04 23:33:37,703-rk0-log_helper.py#102] Progress: 2540 / 15625 [16%], Speed: 2.094 s/iter, ETA 0:07:36 (D:H:M)

[2023-05-04 23:34:19,410-rk0-train.py#348] Epoch: [5][60/625] lr: 0.001087
	batch_time: 2.074888 (2.094169)	data_time: 0.000567 (0.009039)
	loss_fool: 0.174158 (0.176305)	loss_train_adv: 0.010816 (0.016625)
	cen_loss: 0.606871 (0.614069)	cls_loss: 0.037550 (0.056980)
	loc_loss: 0.170577 (0.196319)	total_loss: 1.156151 (1.260007)

[2023-05-04 23:34:19,411-rk0-log_helper.py#102] Progress: 2560 / 15625 [16%], Speed: 2.094 s/iter, ETA 0:07:36 (D:H:M)

[2023-05-04 23:35:01,490-rk0-train.py#348] Epoch: [5][80/625] lr: 0.001087
	batch_time: 2.081173 (2.096844)	data_time: 0.000576 (0.009052)
	loss_fool: 0.116714 (0.176613)	loss_train_adv: 0.028653 (0.016788)
	cen_loss: 0.617260 (0.614372)	cls_loss: 0.052638 (0.057124)
	loc_loss: 0.185831 (0.197635)	total_loss: 1.227392 (1.264401)

[2023-05-04 23:35:01,491-rk0-log_helper.py#102] Progress: 2580 / 15625 [16%], Speed: 2.097 s/iter, ETA 0:07:35 (D:H:M)

[2023-05-04 23:35:43,237-rk0-train.py#348] Epoch: [5][100/625] lr: 0.001087
	batch_time: 2.088422 (2.095784)	data_time: 0.000159 (0.009031)
	loss_fool: 0.163462 (0.175037)	loss_train_adv: 0.016078 (0.017522)
	cen_loss: 0.615241 (0.614189)	cls_loss: 0.038249 (0.055894)
	loc_loss: 0.184277 (0.197966)	total_loss: 1.206322 (1.263981)

[2023-05-04 23:35:43,239-rk0-log_helper.py#102] Progress: 2600 / 15625 [16%], Speed: 2.096 s/iter, ETA 0:07:34 (D:H:M)

[2023-05-04 23:36:25,025-rk0-train.py#348] Epoch: [5][120/625] lr: 0.001087
	batch_time: 2.082944 (2.087987)	data_time: 0.000474 (0.000484)
	loss_fool: 0.170395 (0.175089)	loss_train_adv: 0.017227 (0.017334)
	cen_loss: 0.616602 (0.614096)	cls_loss: 0.041965 (0.055768)
	loc_loss: 0.173607 (0.197892)	total_loss: 1.179390 (1.263542)

[2023-05-04 23:36:25,026-rk0-log_helper.py#102] Progress: 2620 / 15625 [16%], Speed: 2.088 s/iter, ETA 0:07:32 (D:H:M)

[2023-05-04 23:37:06,696-rk0-train.py#348] Epoch: [5][140/625] lr: 0.001087
	batch_time: 2.081467 (2.088724)	data_time: 0.000662 (0.000531)
	loss_fool: 0.180988 (0.175632)	loss_train_adv: 0.015232 (0.017375)
	cen_loss: 0.616119 (0.614074)	cls_loss: 0.050936 (0.056221)
	loc_loss: 0.206488 (0.197741)	total_loss: 1.286518 (1.263519)

[2023-05-04 23:37:06,697-rk0-log_helper.py#102] Progress: 2640 / 15625 [16%], Speed: 2.089 s/iter, ETA 0:07:32 (D:H:M)

[2023-05-04 23:37:48,420-rk0-train.py#348] Epoch: [5][160/625] lr: 0.001087
	batch_time: 2.086665 (2.088883)	data_time: 0.000671 (0.000585)
	loss_fool: 0.184110 (0.174885)	loss_train_adv: 0.007917 (0.017132)
	cen_loss: 0.609660 (0.614425)	cls_loss: 0.041242 (0.056611)
	loc_loss: 0.176027 (0.197563)	total_loss: 1.178985 (1.263726)

[2023-05-04 23:37:48,421-rk0-log_helper.py#102] Progress: 2660 / 15625 [17%], Speed: 2.089 s/iter, ETA 0:07:31 (D:H:M)

[2023-05-04 23:38:30,152-rk0-train.py#348] Epoch: [5][180/625] lr: 0.001087
	batch_time: 2.075579 (2.085380)	data_time: 0.000471 (0.000601)
	loss_fool: 0.207370 (0.176814)	loss_train_adv: 0.011041 (0.016315)
	cen_loss: 0.608363 (0.614476)	cls_loss: 0.036183 (0.055560)
	loc_loss: 0.161155 (0.197423)	total_loss: 1.128010 (1.262306)

[2023-05-04 23:38:30,153-rk0-log_helper.py#102] Progress: 2680 / 15625 [17%], Speed: 2.085 s/iter, ETA 0:07:29 (D:H:M)

[2023-05-04 23:39:11,799-rk0-train.py#348] Epoch: [5][200/625] lr: 0.001087
	batch_time: 2.095350 (2.084399)	data_time: 0.000647 (0.000590)
	loss_fool: 0.134153 (0.177533)	loss_train_adv: 0.024574 (0.015708)
	cen_loss: 0.607711 (0.614308)	cls_loss: 0.040534 (0.055837)
	loc_loss: 0.171226 (0.196331)	total_loss: 1.161924 (1.259137)

[2023-05-04 23:39:11,801-rk0-log_helper.py#102] Progress: 2700 / 15625 [17%], Speed: 2.084 s/iter, ETA 0:07:29 (D:H:M)

[2023-05-04 23:39:53,498-rk0-train.py#348] Epoch: [5][220/625] lr: 0.001087
	batch_time: 2.079545 (2.083511)	data_time: 0.000695 (0.000547)
	loss_fool: 0.161899 (0.177185)	loss_train_adv: 0.015332 (0.015991)
	cen_loss: 0.609525 (0.614305)	cls_loss: 0.034522 (0.055843)
	loc_loss: 0.170608 (0.194983)	total_loss: 1.155870 (1.255096)

[2023-05-04 23:39:53,499-rk0-log_helper.py#102] Progress: 2720 / 15625 [17%], Speed: 2.084 s/iter, ETA 0:07:28 (D:H:M)

[2023-05-04 23:40:35,168-rk0-train.py#348] Epoch: [5][240/625] lr: 0.001087
	batch_time: 2.098962 (2.083499)	data_time: 0.000638 (0.000559)
	loss_fool: 0.167329 (0.178535)	loss_train_adv: 0.014341 (0.015344)
	cen_loss: 0.609727 (0.614359)	cls_loss: 0.043998 (0.054830)
	loc_loss: 0.189238 (0.195711)	total_loss: 1.221441 (1.256322)

[2023-05-04 23:40:35,170-rk0-log_helper.py#102] Progress: 2740 / 15625 [17%], Speed: 2.083 s/iter, ETA 0:07:27 (D:H:M)

[2023-05-04 23:41:16,831-rk0-train.py#348] Epoch: [5][260/625] lr: 0.001087
	batch_time: 2.079627 (2.082888)	data_time: 0.000609 (0.000537)
	loss_fool: 0.183146 (0.179664)	loss_train_adv: 0.014251 (0.014629)
	cen_loss: 0.616665 (0.614638)	cls_loss: 0.060718 (0.054462)
	loc_loss: 0.229159 (0.195315)	total_loss: 1.364860 (1.255046)

[2023-05-04 23:41:16,833-rk0-log_helper.py#102] Progress: 2760 / 15625 [17%], Speed: 2.083 s/iter, ETA 0:07:26 (D:H:M)

[2023-05-04 23:41:58,535-rk0-train.py#348] Epoch: [5][280/625] lr: 0.001087
	batch_time: 2.061089 (2.082612)	data_time: 0.000395 (0.000526)
	loss_fool: 0.193462 (0.180077)	loss_train_adv: 0.014269 (0.014422)
	cen_loss: 0.615468 (0.614388)	cls_loss: 0.052302 (0.052711)
	loc_loss: 0.212935 (0.194571)	total_loss: 1.306574 (1.250811)

[2023-05-04 23:41:58,535-rk0-log_helper.py#102] Progress: 2780 / 15625 [17%], Speed: 2.083 s/iter, ETA 0:07:25 (D:H:M)

[2023-05-04 23:42:40,750-rk0-train.py#348] Epoch: [5][300/625] lr: 0.001087
	batch_time: 2.085087 (2.088288)	data_time: 0.000250 (0.000532)
	loss_fool: 0.161818 (0.180816)	loss_train_adv: 0.015034 (0.014139)
	cen_loss: 0.614996 (0.614103)	cls_loss: 0.057111 (0.051949)
	loc_loss: 0.220804 (0.196075)	total_loss: 1.334521 (1.254276)

[2023-05-04 23:42:40,752-rk0-log_helper.py#102] Progress: 2800 / 15625 [17%], Speed: 2.088 s/iter, ETA 0:07:26 (D:H:M)

[2023-05-04 23:43:22,425-rk0-train.py#348] Epoch: [5][320/625] lr: 0.001087
	batch_time: 2.062534 (2.088018)	data_time: 0.000554 (0.000551)
	loss_fool: 0.165834 (0.180903)	loss_train_adv: 0.010554 (0.013752)
	cen_loss: 0.619765 (0.614335)	cls_loss: 0.077653 (0.051632)
	loc_loss: 0.203360 (0.198170)	total_loss: 1.307498 (1.260478)

[2023-05-04 23:43:22,425-rk0-log_helper.py#102] Progress: 2820 / 15625 [18%], Speed: 2.088 s/iter, ETA 0:07:25 (D:H:M)

[2023-05-04 23:44:04,060-rk0-train.py#348] Epoch: [5][340/625] lr: 0.001087
	batch_time: 2.081759 (2.087677)	data_time: 0.000578 (0.000535)
	loss_fool: 0.191737 (0.180018)	loss_train_adv: 0.016891 (0.013724)
	cen_loss: 0.614687 (0.614566)	cls_loss: 0.057065 (0.053284)
	loc_loss: 0.225438 (0.198312)	total_loss: 1.348065 (1.262787)

[2023-05-04 23:44:04,061-rk0-log_helper.py#102] Progress: 2840 / 15625 [18%], Speed: 2.088 s/iter, ETA 0:07:24 (D:H:M)

[2023-05-04 23:44:45,774-rk0-train.py#348] Epoch: [5][360/625] lr: 0.001087
	batch_time: 2.089560 (2.088197)	data_time: 0.000676 (0.000540)
	loss_fool: 0.233477 (0.179100)	loss_train_adv: 0.016800 (0.014833)
	cen_loss: 0.610526 (0.614178)	cls_loss: 0.055174 (0.054081)
	loc_loss: 0.185944 (0.195719)	total_loss: 1.223531 (1.255417)

[2023-05-04 23:44:45,775-rk0-log_helper.py#102] Progress: 2860 / 15625 [18%], Speed: 2.088 s/iter, ETA 0:07:24 (D:H:M)

[2023-05-04 23:45:27,424-rk0-train.py#348] Epoch: [5][380/625] lr: 0.001087
	batch_time: 2.081956 (2.087652)	data_time: 0.000568 (0.000541)
	loss_fool: 0.196520 (0.178238)	loss_train_adv: 0.019793 (0.015427)
	cen_loss: 0.609324 (0.614291)	cls_loss: 0.047559 (0.054995)
	loc_loss: 0.178388 (0.195956)	total_loss: 1.192046 (1.257154)

[2023-05-04 23:45:27,425-rk0-log_helper.py#102] Progress: 2880 / 15625 [18%], Speed: 2.088 s/iter, ETA 0:07:23 (D:H:M)

[2023-05-04 23:46:09,109-rk0-train.py#348] Epoch: [5][400/625] lr: 0.001087
	batch_time: 2.070975 (2.082330)	data_time: 0.000159 (0.000542)
	loss_fool: 0.161940 (0.178199)	loss_train_adv: 0.019057 (0.015282)
	cen_loss: 0.620307 (0.614653)	cls_loss: 0.091639 (0.055886)
	loc_loss: 0.237138 (0.195536)	total_loss: 1.423359 (1.257147)

[2023-05-04 23:46:09,110-rk0-log_helper.py#102] Progress: 2900 / 15625 [18%], Speed: 2.082 s/iter, ETA 0:07:21 (D:H:M)

[2023-05-04 23:46:50,885-rk0-train.py#348] Epoch: [5][420/625] lr: 0.001087
	batch_time: 2.076409 (2.083361)	data_time: 0.000678 (0.000562)
	loss_fool: 0.189538 (0.179270)	loss_train_adv: 0.018903 (0.014984)
	cen_loss: 0.614981 (0.614599)	cls_loss: 0.044255 (0.053906)
	loc_loss: 0.171967 (0.194368)	total_loss: 1.175136 (1.251609)

[2023-05-04 23:46:50,887-rk0-log_helper.py#102] Progress: 2920 / 15625 [18%], Speed: 2.083 s/iter, ETA 0:07:21 (D:H:M)

[2023-05-04 23:47:32,602-rk0-train.py#348] Epoch: [5][440/625] lr: 0.001087
	batch_time: 2.085627 (2.084148)	data_time: 0.000706 (0.000529)
	loss_fool: 0.183712 (0.179248)	loss_train_adv: 0.032128 (0.015111)
	cen_loss: 0.616482 (0.614360)	cls_loss: 0.056539 (0.053059)
	loc_loss: 0.192992 (0.194261)	total_loss: 1.251998 (1.250202)

[2023-05-04 23:47:32,603-rk0-log_helper.py#102] Progress: 2940 / 15625 [18%], Speed: 2.084 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-04 23:48:14,296-rk0-train.py#348] Epoch: [5][460/625] lr: 0.001087
	batch_time: 2.089366 (2.083925)	data_time: 0.000521 (0.000522)
	loss_fool: 0.199754 (0.180390)	loss_train_adv: 0.013096 (0.013712)
	cen_loss: 0.614384 (0.614243)	cls_loss: 0.067559 (0.052333)
	loc_loss: 0.219986 (0.197499)	total_loss: 1.341901 (1.259072)

[2023-05-04 23:48:14,298-rk0-log_helper.py#102] Progress: 2960 / 15625 [18%], Speed: 2.084 s/iter, ETA 0:07:19 (D:H:M)

[2023-05-04 23:48:56,823-rk0-train.py#348] Epoch: [5][480/625] lr: 0.001087
	batch_time: 2.758370 (2.092682)	data_time: 0.000670 (0.000566)
	loss_fool: 0.186749 (0.181538)	loss_train_adv: 0.003719 (0.013086)
	cen_loss: 0.602080 (0.613744)	cls_loss: 0.034542 (0.052163)
	loc_loss: 0.175049 (0.197752)	total_loss: 1.161768 (1.259164)

[2023-05-04 23:48:56,825-rk0-log_helper.py#102] Progress: 2980 / 15625 [19%], Speed: 2.093 s/iter, ETA 0:07:21 (D:H:M)

[2023-05-04 23:49:38,813-rk0-train.py#348] Epoch: [5][500/625] lr: 0.001087
	batch_time: 2.099418 (2.095721)	data_time: 0.000681 (0.000613)
	loss_fool: 0.169002 (0.181740)	loss_train_adv: 0.013527 (0.012939)
	cen_loss: 0.612270 (0.613859)	cls_loss: 0.095357 (0.052191)
	loc_loss: 0.213880 (0.198726)	total_loss: 1.349267 (1.262228)

[2023-05-04 23:49:38,815-rk0-log_helper.py#102] Progress: 3000 / 15625 [19%], Speed: 2.096 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-04 23:50:20,767-rk0-train.py#348] Epoch: [5][520/625] lr: 0.001087
	batch_time: 2.103901 (2.097476)	data_time: 0.000584 (0.000616)
	loss_fool: 0.196756 (0.182441)	loss_train_adv: 0.020803 (0.012239)
	cen_loss: 0.614940 (0.613594)	cls_loss: 0.056035 (0.054058)
	loc_loss: 0.176216 (0.198792)	total_loss: 1.199623 (1.264029)

[2023-05-04 23:50:20,769-rk0-log_helper.py#102] Progress: 3020 / 15625 [19%], Speed: 2.097 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-04 23:51:02,789-rk0-train.py#348] Epoch: [5][540/625] lr: 0.001087
	batch_time: 2.104766 (2.100505)	data_time: 0.000645 (0.000650)
	loss_fool: 0.146845 (0.182894)	loss_train_adv: 0.018647 (0.011835)
	cen_loss: 0.613145 (0.613419)	cls_loss: 0.051957 (0.053493)
	loc_loss: 0.201624 (0.198636)	total_loss: 1.269974 (1.262820)

[2023-05-04 23:51:02,791-rk0-log_helper.py#102] Progress: 3040 / 15625 [19%], Speed: 2.101 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-04 23:51:44,772-rk0-train.py#348] Epoch: [5][560/625] lr: 0.001087
	batch_time: 2.081943 (2.103384)	data_time: 0.000139 (0.000617)
	loss_fool: 0.164749 (0.182864)	loss_train_adv: 0.015753 (0.012118)
	cen_loss: 0.606580 (0.613289)	cls_loss: 0.041560 (0.054531)
	loc_loss: 0.185548 (0.197195)	total_loss: 1.204784 (1.259405)

[2023-05-04 23:51:44,774-rk0-log_helper.py#102] Progress: 3060 / 15625 [19%], Speed: 2.103 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-04 23:52:26,679-rk0-train.py#348] Epoch: [5][580/625] lr: 0.001087
	batch_time: 2.088881 (2.097181)	data_time: 0.000706 (0.000609)
	loss_fool: 0.143627 (0.181824)	loss_train_adv: 0.015722 (0.012035)
	cen_loss: 0.618781 (0.613856)	cls_loss: 0.057935 (0.054653)
	loc_loss: 0.215164 (0.197433)	total_loss: 1.322209 (1.260808)

[2023-05-04 23:52:26,680-rk0-log_helper.py#102] Progress: 3080 / 15625 [19%], Speed: 2.097 s/iter, ETA 0:07:18 (D:H:M)

[2023-05-04 23:53:08,695-rk0-train.py#348] Epoch: [5][600/625] lr: 0.001087
	batch_time: 2.127921 (2.097443)	data_time: 0.000411 (0.000579)
	loss_fool: 0.208289 (0.182565)	loss_train_adv: 0.003661 (0.011935)
	cen_loss: 0.618888 (0.613941)	cls_loss: 0.065037 (0.054317)
	loc_loss: 0.215879 (0.195335)	total_loss: 1.331561 (1.254263)

[2023-05-04 23:53:08,696-rk0-log_helper.py#102] Progress: 3100 / 15625 [19%], Speed: 2.097 s/iter, ETA 0:07:17 (D:H:M)

[2023-05-04 23:53:50,438-rk0-train.py#348] Epoch: [5][620/625] lr: 0.001087
	batch_time: 2.078595 (2.095358)	data_time: 0.000551 (0.000551)
	loss_fool: 0.176145 (0.181800)	loss_train_adv: 0.010065 (0.012135)
	cen_loss: 0.615574 (0.614143)	cls_loss: 0.032404 (0.055567)
	loc_loss: 0.166377 (0.195206)	total_loss: 1.147108 (1.255329)

[2023-05-04 23:53:50,440-rk0-log_helper.py#102] Progress: 3120 / 15625 [19%], Speed: 2.095 s/iter, ETA 0:07:16 (D:H:M)

[2023-05-04 23:54:01,663-rk0-train.py#235] epoch: 6
[2023-05-04 23:54:01,663-rk0-train.py#240] epoch 6 lr 0.00015000000000000001
[2023-05-04 23:54:01,663-rk0-train.py#240] epoch 6 lr 0.0015
[2023-05-04 23:54:01,664-rk0-train.py#240] epoch 6 lr 0.005
[2023-05-04 23:54:01,664-rk0-train.py#240] epoch 6 lr 0.0015
[2023-05-04 23:54:01,664-rk0-train.py#240] epoch 6 lr 0.0015
[2023-05-04 23:54:33,711-rk0-train.py#348] Epoch: [6][15/625] lr: 0.001500
	batch_time: 2.078369 (2.107905)	data_time: 0.000383 (0.009002)
	loss_fool: 0.173456 (0.181480)	loss_train_adv: 0.014489 (0.012698)
	cen_loss: 0.616172 (0.614392)	cls_loss: 0.035699 (0.055497)
	loc_loss: 0.195453 (0.195666)	total_loss: 1.238231 (1.256889)

[2023-05-04 23:54:33,712-rk0-log_helper.py#102] Progress: 3140 / 15625 [20%], Speed: 2.108 s/iter, ETA 0:07:18 (D:H:M)

[2023-05-04 23:55:15,365-rk0-train.py#348] Epoch: [6][35/625] lr: 0.001500
	batch_time: 2.095410 (2.104665)	data_time: 0.000604 (0.009028)
	loss_fool: 0.208538 (0.182185)	loss_train_adv: 0.005488 (0.012511)
	cen_loss: 0.608929 (0.614657)	cls_loss: 0.055398 (0.053801)
	loc_loss: 0.177096 (0.195229)	total_loss: 1.195615 (1.254144)

[2023-05-04 23:55:15,367-rk0-log_helper.py#102] Progress: 3160 / 15625 [20%], Speed: 2.105 s/iter, ETA 0:07:17 (D:H:M)

[2023-05-04 23:55:57,066-rk0-train.py#348] Epoch: [6][55/625] lr: 0.001500
	batch_time: 2.088961 (2.102619)	data_time: 0.000678 (0.008996)
	loss_fool: 0.149880 (0.181673)	loss_train_adv: 0.024938 (0.012574)
	cen_loss: 0.619923 (0.614739)	cls_loss: 0.045834 (0.055319)
	loc_loss: 0.189004 (0.195355)	total_loss: 1.232769 (1.256123)

[2023-05-04 23:55:57,066-rk0-log_helper.py#102] Progress: 3180 / 15625 [20%], Speed: 2.103 s/iter, ETA 0:07:16 (D:H:M)

[2023-05-04 23:56:38,751-rk0-train.py#348] Epoch: [6][75/625] lr: 0.001500
	batch_time: 2.079427 (2.099345)	data_time: 0.000369 (0.008985)
	loss_fool: 0.198469 (0.180937)	loss_train_adv: 0.010563 (0.013083)
	cen_loss: 0.614003 (0.614562)	cls_loss: 0.076408 (0.055875)
	loc_loss: 0.202081 (0.195585)	total_loss: 1.296654 (1.257191)

[2023-05-04 23:56:38,753-rk0-log_helper.py#102] Progress: 3200 / 15625 [20%], Speed: 2.099 s/iter, ETA 0:07:14 (D:H:M)

[2023-05-04 23:57:28,758-rk0-train.py#348] Epoch: [6][95/625] lr: 0.001500
	batch_time: 2.441925 (2.180851)	data_time: 0.001153 (0.009301)
	loss_fool: 0.140925 (0.182119)	loss_train_adv: 0.016721 (0.012821)
	cen_loss: 0.604566 (0.614448)	cls_loss: 0.033646 (0.053711)
	loc_loss: 0.179084 (0.196076)	total_loss: 1.175464 (1.256386)

[2023-05-04 23:57:28,759-rk0-log_helper.py#102] Progress: 3220 / 15625 [20%], Speed: 2.181 s/iter, ETA 0:07:30 (D:H:M)

[2023-05-04 23:58:27,041-rk0-train.py#348] Epoch: [6][115/625] lr: 0.001500
	batch_time: 3.037486 (2.329268)	data_time: 0.002450 (0.001235)
	loss_fool: 0.163641 (0.182032)	loss_train_adv: 0.008198 (0.012362)
	cen_loss: 0.620636 (0.614390)	cls_loss: 0.045757 (0.053641)
	loc_loss: 0.201771 (0.195671)	total_loss: 1.271706 (1.255044)

[2023-05-04 23:58:27,042-rk0-log_helper.py#102] Progress: 3240 / 15625 [20%], Speed: 2.329 s/iter, ETA 0:08:00 (D:H:M)

[2023-05-04 23:59:18,465-rk0-train.py#348] Epoch: [6][135/625] lr: 0.001500
	batch_time: 2.983407 (2.426347)	data_time: 0.001080 (0.001292)
	loss_fool: 0.207088 (0.180841)	loss_train_adv: 0.014601 (0.013041)
	cen_loss: 0.618020 (0.614471)	cls_loss: 0.043231 (0.054432)
	loc_loss: 0.215463 (0.197132)	total_loss: 1.307641 (1.260300)

[2023-05-04 23:59:18,466-rk0-log_helper.py#102] Progress: 3260 / 15625 [20%], Speed: 2.426 s/iter, ETA 0:08:20 (D:H:M)

[2023-05-05 00:00:18,801-rk0-train.py#348] Epoch: [6][155/625] lr: 0.001500
	batch_time: 3.805129 (2.611123)	data_time: 0.012337 (0.001949)
	loss_fool: 0.202903 (0.181746)	loss_train_adv: 0.023374 (0.013125)
	cen_loss: 0.614345 (0.614398)	cls_loss: 0.050615 (0.053816)
	loc_loss: 0.242048 (0.198835)	total_loss: 1.391105 (1.264718)

[2023-05-05 00:00:18,802-rk0-log_helper.py#102] Progress: 3280 / 15625 [20%], Speed: 2.611 s/iter, ETA 0:08:57 (D:H:M)

[2023-05-05 00:01:16,518-rk0-train.py#348] Epoch: [6][175/625] lr: 0.001500
	batch_time: 2.651322 (2.769730)	data_time: 0.004540 (0.002512)
	loss_fool: 0.226987 (0.181504)	loss_train_adv: 0.012148 (0.012951)
	cen_loss: 0.604889 (0.614476)	cls_loss: 0.041844 (0.053209)
	loc_loss: 0.182860 (0.198618)	total_loss: 1.195314 (1.263540)

[2023-05-05 00:01:16,518-rk0-log_helper.py#102] Progress: 3300 / 15625 [21%], Speed: 2.770 s/iter, ETA 0:09:28 (D:H:M)

[2023-05-05 00:02:10,156-rk0-train.py#348] Epoch: [6][195/625] lr: 0.001500
	batch_time: 2.606592 (2.805678)	data_time: 0.001524 (0.002565)
	loss_fool: 0.173968 (0.180833)	loss_train_adv: 0.005973 (0.013270)
	cen_loss: 0.606843 (0.614599)	cls_loss: 0.044918 (0.054555)
	loc_loss: 0.191312 (0.198462)	total_loss: 1.225696 (1.264540)

[2023-05-05 00:02:10,157-rk0-log_helper.py#102] Progress: 3320 / 15625 [21%], Speed: 2.806 s/iter, ETA 0:09:35 (D:H:M)

[2023-05-05 00:03:05,404-rk0-train.py#348] Epoch: [6][215/625] lr: 0.001500
	batch_time: 2.399895 (2.775192)	data_time: 0.001147 (0.002364)
	loss_fool: 0.202446 (0.181690)	loss_train_adv: 0.007423 (0.013279)
	cen_loss: 0.617491 (0.614579)	cls_loss: 0.046336 (0.054953)
	loc_loss: 0.206110 (0.197363)	total_loss: 1.282157 (1.261620)

[2023-05-05 00:03:05,404-rk0-log_helper.py#102] Progress: 3340 / 15625 [21%], Speed: 2.775 s/iter, ETA 0:09:28 (D:H:M)

[2023-05-05 00:04:00,577-rk0-train.py#348] Epoch: [6][235/625] lr: 0.001500
	batch_time: 2.565128 (2.811899)	data_time: 0.000592 (0.002846)
	loss_fool: 0.185123 (0.182626)	loss_train_adv: 0.011740 (0.012705)
	cen_loss: 0.618380 (0.614963)	cls_loss: 0.039353 (0.054746)
	loc_loss: 0.192825 (0.197330)	total_loss: 1.236208 (1.261699)

[2023-05-05 00:04:00,578-rk0-log_helper.py#102] Progress: 3360 / 15625 [21%], Speed: 2.812 s/iter, ETA 0:09:34 (D:H:M)

[2023-05-05 00:04:56,972-rk0-train.py#348] Epoch: [6][255/625] lr: 0.001500
	batch_time: 2.697367 (2.772509)	data_time: 0.001111 (0.002434)
	loss_fool: 0.180376 (0.181872)	loss_train_adv: 0.013369 (0.012447)
	cen_loss: 0.608931 (0.615246)	cls_loss: 0.053872 (0.054458)
	loc_loss: 0.201188 (0.199182)	total_loss: 1.266368 (1.267250)

[2023-05-05 00:04:56,973-rk0-log_helper.py#102] Progress: 3380 / 15625 [21%], Speed: 2.773 s/iter, ETA 0:09:25 (D:H:M)

[2023-05-05 00:05:49,079-rk0-train.py#348] Epoch: [6][275/625] lr: 0.001500
	batch_time: 2.659536 (2.716247)	data_time: 0.001405 (0.002153)
	loss_fool: 0.180240 (0.182795)	loss_train_adv: 0.014993 (0.012234)
	cen_loss: 0.610476 (0.615336)	cls_loss: 0.050381 (0.054332)
	loc_loss: 0.172502 (0.200953)	total_loss: 1.178362 (1.272527)

[2023-05-05 00:05:49,079-rk0-log_helper.py#102] Progress: 3400 / 15625 [21%], Speed: 2.716 s/iter, ETA 0:09:13 (D:H:M)

[2023-05-05 00:06:43,226-rk0-train.py#348] Epoch: [6][295/625] lr: 0.001500
	batch_time: 2.819509 (2.721344)	data_time: 0.001227 (0.001978)
	loss_fool: 0.174258 (0.183343)	loss_train_adv: 0.007674 (0.011964)
	cen_loss: 0.611470 (0.615144)	cls_loss: 0.039656 (0.052004)
	loc_loss: 0.177659 (0.200481)	total_loss: 1.184102 (1.268590)

[2023-05-05 00:06:43,227-rk0-log_helper.py#102] Progress: 3420 / 15625 [21%], Speed: 2.721 s/iter, ETA 0:09:13 (D:H:M)

[2023-05-05 00:07:35,250-rk0-train.py#348] Epoch: [6][315/625] lr: 0.001500
	batch_time: 2.636114 (2.689474)	data_time: 0.001462 (0.002186)
	loss_fool: 0.185851 (0.183113)	loss_train_adv: 0.015391 (0.011513)
	cen_loss: 0.616603 (0.615123)	cls_loss: 0.061362 (0.054543)
	loc_loss: 0.186449 (0.200854)	total_loss: 1.237312 (1.272228)

[2023-05-05 00:07:35,252-rk0-log_helper.py#102] Progress: 3440 / 15625 [22%], Speed: 2.689 s/iter, ETA 0:09:06 (D:H:M)

[2023-05-05 00:08:27,127-rk0-train.py#348] Epoch: [6][335/625] lr: 0.001500
	batch_time: 2.643159 (2.656765)	data_time: 0.011920 (0.002075)
	loss_fool: 0.183953 (0.182409)	loss_train_adv: 0.008223 (0.011941)
	cen_loss: 0.616072 (0.614925)	cls_loss: 0.044846 (0.055787)
	loc_loss: 0.217174 (0.199198)	total_loss: 1.312441 (1.268305)

[2023-05-05 00:08:27,128-rk0-log_helper.py#102] Progress: 3460 / 15625 [22%], Speed: 2.657 s/iter, ETA 0:08:58 (D:H:M)

[2023-05-05 00:09:18,377-rk0-train.py#348] Epoch: [6][355/625] lr: 0.001500
	batch_time: 2.505276 (2.605172)	data_time: 0.000587 (0.002147)
	loss_fool: 0.210571 (0.183905)	loss_train_adv: 0.013980 (0.011678)
	cen_loss: 0.621412 (0.614639)	cls_loss: 0.059505 (0.056220)
	loc_loss: 0.233541 (0.194698)	total_loss: 1.381539 (1.254954)

[2023-05-05 00:09:18,378-rk0-log_helper.py#102] Progress: 3480 / 15625 [22%], Speed: 2.605 s/iter, ETA 0:08:47 (D:H:M)

[2023-05-05 00:10:09,623-rk0-train.py#348] Epoch: [6][375/625] lr: 0.001500
	batch_time: 2.555453 (2.597528)	data_time: 0.001570 (0.002347)
	loss_fool: 0.181943 (0.183065)	loss_train_adv: 0.014562 (0.011483)
	cen_loss: 0.620608 (0.614513)	cls_loss: 0.065465 (0.056124)
	loc_loss: 0.220625 (0.193941)	total_loss: 1.347947 (1.252460)

[2023-05-05 00:10:09,623-rk0-log_helper.py#102] Progress: 3500 / 15625 [22%], Speed: 2.598 s/iter, ETA 0:08:44 (D:H:M)

[2023-05-05 00:11:01,846-rk0-train.py#348] Epoch: [6][395/625] lr: 0.001500
	batch_time: 2.559108 (2.578942)	data_time: 0.001201 (0.002348)
	loss_fool: 0.203848 (0.183721)	loss_train_adv: 0.006111 (0.011468)
	cen_loss: 0.609456 (0.614955)	cls_loss: 0.039114 (0.058121)
	loc_loss: 0.166840 (0.194613)	total_loss: 1.149088 (1.256917)

[2023-05-05 00:11:01,847-rk0-log_helper.py#102] Progress: 3520 / 15625 [22%], Speed: 2.579 s/iter, ETA 0:08:40 (D:H:M)

[2023-05-05 00:11:51,577-rk0-train.py#348] Epoch: [6][415/625] lr: 0.001500
	batch_time: 2.479749 (2.556915)	data_time: 0.001598 (0.002124)
	loss_fool: 0.176803 (0.183388)	loss_train_adv: 0.011542 (0.011808)
	cen_loss: 0.614168 (0.615088)	cls_loss: 0.043870 (0.055576)
	loc_loss: 0.183291 (0.195662)	total_loss: 1.207911 (1.257649)

[2023-05-05 00:11:51,578-rk0-log_helper.py#102] Progress: 3540 / 15625 [22%], Speed: 2.557 s/iter, ETA 0:08:35 (D:H:M)

[2023-05-05 00:12:41,771-rk0-train.py#348] Epoch: [6][435/625] lr: 0.001500
	batch_time: 2.448191 (2.540309)	data_time: 0.001489 (0.001857)
	loss_fool: 0.190395 (0.184532)	loss_train_adv: 0.018598 (0.011390)
	cen_loss: 0.619119 (0.615034)	cls_loss: 0.053207 (0.053855)
	loc_loss: 0.184578 (0.196222)	total_loss: 1.226061 (1.257556)

[2023-05-05 00:12:41,772-rk0-log_helper.py#102] Progress: 3560 / 15625 [22%], Speed: 2.540 s/iter, ETA 0:08:30 (D:H:M)

[2023-05-05 00:13:31,011-rk0-train.py#348] Epoch: [6][455/625] lr: 0.001500
	batch_time: 2.460095 (2.521100)	data_time: 0.001251 (0.001701)
	loss_fool: 0.214432 (0.183443)	loss_train_adv: 0.007123 (0.011472)
	cen_loss: 0.618834 (0.615134)	cls_loss: 0.047550 (0.055448)
	loc_loss: 0.199940 (0.196735)	total_loss: 1.266204 (1.260788)

[2023-05-05 00:13:31,013-rk0-log_helper.py#102] Progress: 3580 / 15625 [22%], Speed: 2.521 s/iter, ETA 0:08:26 (D:H:M)

[2023-05-05 00:14:20,840-rk0-train.py#348] Epoch: [6][475/625] lr: 0.001500
	batch_time: 2.415285 (2.507288)	data_time: 0.001105 (0.001692)
	loss_fool: 0.184217 (0.184384)	loss_train_adv: 0.007982 (0.010975)
	cen_loss: 0.615638 (0.615124)	cls_loss: 0.043219 (0.056810)
	loc_loss: 0.172661 (0.196584)	total_loss: 1.176841 (1.261684)

[2023-05-05 00:14:20,841-rk0-log_helper.py#102] Progress: 3600 / 15625 [23%], Speed: 2.507 s/iter, ETA 0:08:22 (D:H:M)

[2023-05-05 00:15:10,127-rk0-train.py#348] Epoch: [6][495/625] lr: 0.001500
	batch_time: 2.463174 (2.478015)	data_time: 0.001526 (0.001830)
	loss_fool: 0.159975 (0.184268)	loss_train_adv: 0.012237 (0.010886)
	cen_loss: 0.607299 (0.614965)	cls_loss: 0.039487 (0.056901)
	loc_loss: 0.192702 (0.196918)	total_loss: 1.224891 (1.262621)

[2023-05-05 00:15:10,128-rk0-log_helper.py#102] Progress: 3620 / 15625 [23%], Speed: 2.478 s/iter, ETA 0:08:15 (D:H:M)

[2023-05-05 00:15:59,399-rk0-train.py#348] Epoch: [6][515/625] lr: 0.001500
	batch_time: 2.497053 (2.472819)	data_time: 0.001650 (0.001932)
	loss_fool: 0.201031 (0.185240)	loss_train_adv: 0.004748 (0.010224)
	cen_loss: 0.611798 (0.614884)	cls_loss: 0.050426 (0.056538)
	loc_loss: 0.199208 (0.196476)	total_loss: 1.259849 (1.260850)

[2023-05-05 00:15:59,400-rk0-log_helper.py#102] Progress: 3640 / 15625 [23%], Speed: 2.473 s/iter, ETA 0:08:13 (D:H:M)

[2023-05-05 00:16:48,213-rk0-train.py#348] Epoch: [6][535/625] lr: 0.001500
	batch_time: 2.453150 (2.459086)	data_time: 0.000890 (0.001882)
	loss_fool: 0.195114 (0.184987)	loss_train_adv: 0.007453 (0.010018)
	cen_loss: 0.612969 (0.614737)	cls_loss: 0.164049 (0.057743)
	loc_loss: 0.187325 (0.197000)	total_loss: 1.338993 (1.263481)

[2023-05-05 00:16:48,214-rk0-log_helper.py#102] Progress: 3660 / 15625 [23%], Speed: 2.459 s/iter, ETA 0:08:10 (D:H:M)

[2023-05-05 00:17:37,424-rk0-train.py#348] Epoch: [6][555/625] lr: 0.001500
	batch_time: 2.536047 (2.458872)	data_time: 0.001462 (0.002127)
	loss_fool: 0.194216 (0.185604)	loss_train_adv: 0.013606 (0.010113)
	cen_loss: 0.615408 (0.614535)	cls_loss: 0.040922 (0.055445)
	loc_loss: 0.156400 (0.200512)	total_loss: 1.125530 (1.271515)

[2023-05-05 00:17:37,424-rk0-log_helper.py#102] Progress: 3680 / 15625 [23%], Speed: 2.459 s/iter, ETA 0:08:09 (D:H:M)

[2023-05-05 00:18:26,258-rk0-train.py#348] Epoch: [6][575/625] lr: 0.001500
	batch_time: 2.514565 (2.448555)	data_time: 0.012768 (0.002328)
	loss_fool: 0.207383 (0.184357)	loss_train_adv: 0.014477 (0.010663)
	cen_loss: 0.609820 (0.614517)	cls_loss: 0.049002 (0.053658)
	loc_loss: 0.214316 (0.202118)	total_loss: 1.301770 (1.274529)

[2023-05-05 00:18:26,259-rk0-log_helper.py#102] Progress: 3700 / 15625 [23%], Speed: 2.449 s/iter, ETA 0:08:06 (D:H:M)

[2023-05-05 00:19:15,651-rk0-train.py#348] Epoch: [6][595/625] lr: 0.001500
	batch_time: 2.488845 (2.449201)	data_time: 0.000937 (0.002407)
	loss_fool: 0.202116 (0.184735)	loss_train_adv: 0.015154 (0.010952)
	cen_loss: 0.617892 (0.614347)	cls_loss: 0.065714 (0.053823)
	loc_loss: 0.225710 (0.201975)	total_loss: 1.360736 (1.274095)

[2023-05-05 00:19:15,651-rk0-log_helper.py#102] Progress: 3720 / 15625 [23%], Speed: 2.449 s/iter, ETA 0:08:05 (D:H:M)

[2023-05-05 00:20:05,854-rk0-train.py#348] Epoch: [6][615/625] lr: 0.001500
	batch_time: 2.354441 (2.458204)	data_time: 0.001255 (0.002376)
	loss_fool: 0.206473 (0.183829)	loss_train_adv: 0.004046 (0.011506)
	cen_loss: 0.615963 (0.614411)	cls_loss: 0.046148 (0.054435)
	loc_loss: 0.194050 (0.202752)	total_loss: 1.244262 (1.277100)

[2023-05-05 00:20:05,855-rk0-log_helper.py#102] Progress: 3740 / 15625 [23%], Speed: 2.458 s/iter, ETA 0:08:06 (D:H:M)

[2023-05-05 00:20:31,875-rk0-train.py#235] epoch: 7
[2023-05-05 00:20:31,875-rk0-train.py#240] epoch 7 lr 0.00013288001856151234
[2023-05-05 00:20:31,876-rk0-train.py#240] epoch 7 lr 0.0013288001856151233
[2023-05-05 00:20:31,877-rk0-train.py#240] epoch 7 lr 0.004429333952050411
[2023-05-05 00:20:31,877-rk0-train.py#240] epoch 7 lr 0.0013288001856151233
[2023-05-05 00:20:31,878-rk0-train.py#240] epoch 7 lr 0.0013288001856151233
[2023-05-05 00:20:56,693-rk0-train.py#348] Epoch: [7][10/625] lr: 0.001329
	batch_time: 2.603673 (2.478048)	data_time: 0.006593 (0.014747)
	loss_fool: 0.213076 (0.183691)	loss_train_adv: 0.009961 (0.011616)
	cen_loss: 0.610544 (0.614544)	cls_loss: 0.048881 (0.054189)
	loc_loss: 0.206122 (0.203197)	total_loss: 1.277792 (1.278323)

[2023-05-05 00:20:56,694-rk0-log_helper.py#102] Progress: 3760 / 15625 [24%], Speed: 2.478 s/iter, ETA 0:08:10 (D:H:M)

[2023-05-05 00:21:46,120-rk0-train.py#348] Epoch: [7][30/625] lr: 0.001329
	batch_time: 2.350181 (2.480315)	data_time: 0.001476 (0.014754)
	loss_fool: 0.160617 (0.183389)	loss_train_adv: 0.011819 (0.011429)
	cen_loss: 0.621143 (0.614303)	cls_loss: 0.060492 (0.054194)
	loc_loss: 0.202451 (0.198722)	total_loss: 1.288988 (1.264662)

[2023-05-05 00:21:46,121-rk0-log_helper.py#102] Progress: 3780 / 15625 [24%], Speed: 2.480 s/iter, ETA 0:08:09 (D:H:M)

[2023-05-05 00:22:35,241-rk0-train.py#348] Epoch: [7][50/625] lr: 0.001329
	batch_time: 2.491007 (2.483528)	data_time: 0.001180 (0.014489)
	loss_fool: 0.203265 (0.183840)	loss_train_adv: 0.018630 (0.011504)
	cen_loss: 0.622790 (0.614383)	cls_loss: 0.044918 (0.055114)
	loc_loss: 0.199774 (0.197442)	total_loss: 1.267030 (1.261823)

[2023-05-05 00:22:35,242-rk0-log_helper.py#102] Progress: 3800 / 15625 [24%], Speed: 2.484 s/iter, ETA 0:08:09 (D:H:M)

[2023-05-05 00:23:24,367-rk0-train.py#348] Epoch: [7][70/625] lr: 0.001329
	batch_time: 2.436950 (2.481594)	data_time: 0.001225 (0.014490)
	loss_fool: 0.157500 (0.184126)	loss_train_adv: 0.016632 (0.010751)
	cen_loss: 0.610696 (0.614279)	cls_loss: 0.046903 (0.054328)
	loc_loss: 0.223434 (0.195323)	total_loss: 1.327901 (1.254577)

[2023-05-05 00:23:24,368-rk0-log_helper.py#102] Progress: 3820 / 15625 [24%], Speed: 2.482 s/iter, ETA 0:08:08 (D:H:M)

[2023-05-05 00:24:13,479-rk0-train.py#348] Epoch: [7][90/625] lr: 0.001329
	batch_time: 2.406249 (2.471426)	data_time: 0.001607 (0.014571)
	loss_fool: 0.183140 (0.184639)	loss_train_adv: 0.005531 (0.010620)
	cen_loss: 0.621736 (0.614169)	cls_loss: 0.051451 (0.054016)
	loc_loss: 0.188697 (0.193013)	total_loss: 1.239277 (1.247224)

[2023-05-05 00:24:13,480-rk0-log_helper.py#102] Progress: 3840 / 15625 [24%], Speed: 2.471 s/iter, ETA 0:08:05 (D:H:M)

[2023-05-05 00:25:02,823-rk0-train.py#348] Epoch: [7][110/625] lr: 0.001329
	batch_time: 2.437439 (2.456995)	data_time: 0.007581 (0.002489)
	loss_fool: 0.145154 (0.183885)	loss_train_adv: 0.011049 (0.011020)
	cen_loss: 0.613638 (0.614126)	cls_loss: 0.057101 (0.053636)
	loc_loss: 0.217186 (0.191988)	total_loss: 1.322296 (1.243728)

[2023-05-05 00:25:02,824-rk0-log_helper.py#102] Progress: 3860 / 15625 [24%], Speed: 2.457 s/iter, ETA 0:08:01 (D:H:M)

[2023-05-05 00:25:52,495-rk0-train.py#348] Epoch: [7][130/625] lr: 0.001329
	batch_time: 2.339495 (2.459364)	data_time: 0.001439 (0.002355)
	loss_fool: 0.184334 (0.183654)	loss_train_adv: 0.007175 (0.011579)
	cen_loss: 0.609162 (0.614450)	cls_loss: 0.115171 (0.054973)
	loc_loss: 0.222855 (0.195055)	total_loss: 1.392897 (1.254587)

[2023-05-05 00:25:52,495-rk0-log_helper.py#102] Progress: 3880 / 15625 [24%], Speed: 2.459 s/iter, ETA 0:08:01 (D:H:M)

[2023-05-05 00:26:40,998-rk0-train.py#348] Epoch: [7][150/625] lr: 0.001329
	batch_time: 2.361480 (2.453171)	data_time: 0.001297 (0.002276)
	loss_fool: 0.173188 (0.184572)	loss_train_adv: 0.008970 (0.011099)
	cen_loss: 0.616618 (0.614644)	cls_loss: 0.073626 (0.054672)
	loc_loss: 0.200135 (0.195370)	total_loss: 1.290649 (1.255426)

[2023-05-05 00:26:41,000-rk0-log_helper.py#102] Progress: 3900 / 15625 [24%], Speed: 2.453 s/iter, ETA 0:07:59 (D:H:M)

[2023-05-05 00:27:30,070-rk0-train.py#348] Epoch: [7][170/625] lr: 0.001329
	batch_time: 2.495977 (2.452587)	data_time: 0.001224 (0.002181)
	loss_fool: 0.187179 (0.184047)	loss_train_adv: 0.007654 (0.011493)
	cen_loss: 0.617196 (0.614440)	cls_loss: 0.040207 (0.053685)
	loc_loss: 0.197737 (0.194616)	total_loss: 1.250614 (1.251974)

[2023-05-05 00:27:30,071-rk0-log_helper.py#102] Progress: 3920 / 15625 [25%], Speed: 2.453 s/iter, ETA 0:07:58 (D:H:M)

[2023-05-05 00:28:19,708-rk0-train.py#348] Epoch: [7][190/625] lr: 0.001329
	batch_time: 2.406522 (2.458138)	data_time: 0.001487 (0.002364)
	loss_fool: 0.200062 (0.184497)	loss_train_adv: 0.015425 (0.011013)
	cen_loss: 0.618604 (0.614324)	cls_loss: 0.038459 (0.052799)
	loc_loss: 0.195026 (0.194979)	total_loss: 1.242139 (1.252061)

[2023-05-05 00:28:19,709-rk0-log_helper.py#102] Progress: 3940 / 15625 [25%], Speed: 2.458 s/iter, ETA 0:07:58 (D:H:M)

[2023-05-05 00:29:08,855-rk0-train.py#348] Epoch: [7][210/625] lr: 0.001329
	batch_time: 2.346951 (2.455562)	data_time: 0.001518 (0.002491)
	loss_fool: 0.200795 (0.184027)	loss_train_adv: 0.023169 (0.010874)
	cen_loss: 0.611428 (0.614314)	cls_loss: 0.074782 (0.053560)
	loc_loss: 0.215993 (0.194595)	total_loss: 1.334190 (1.251659)

[2023-05-05 00:29:08,856-rk0-log_helper.py#102] Progress: 3960 / 15625 [25%], Speed: 2.456 s/iter, ETA 0:07:57 (D:H:M)

[2023-05-05 00:29:58,589-rk0-train.py#348] Epoch: [7][230/625] lr: 0.001329
	batch_time: 2.477907 (2.455807)	data_time: 0.001590 (0.002367)
	loss_fool: 0.216948 (0.184737)	loss_train_adv: 0.007518 (0.010675)
	cen_loss: 0.613646 (0.614717)	cls_loss: 0.052740 (0.053002)
	loc_loss: 0.211026 (0.194044)	total_loss: 1.299464 (1.249849)

[2023-05-05 00:29:58,590-rk0-log_helper.py#102] Progress: 3980 / 15625 [25%], Speed: 2.456 s/iter, ETA 0:07:56 (D:H:M)

[2023-05-05 00:30:48,075-rk0-train.py#348] Epoch: [7][250/625] lr: 0.001329
	batch_time: 2.536386 (2.465650)	data_time: 0.001543 (0.002290)
	loss_fool: 0.210969 (0.185026)	loss_train_adv: 0.007090 (0.010363)
	cen_loss: 0.612531 (0.614539)	cls_loss: 0.069243 (0.052833)
	loc_loss: 0.189184 (0.194900)	total_loss: 1.249326 (1.252073)

[2023-05-05 00:30:48,076-rk0-log_helper.py#102] Progress: 4000 / 15625 [25%], Speed: 2.466 s/iter, ETA 0:07:57 (D:H:M)

[2023-05-05 00:31:37,472-rk0-train.py#348] Epoch: [7][270/625] lr: 0.001329
	batch_time: 2.415182 (2.468476)	data_time: 0.001314 (0.002240)
	loss_fool: 0.171064 (0.184295)	loss_train_adv: 0.009274 (0.010447)
	cen_loss: 0.609948 (0.615139)	cls_loss: 0.056081 (0.052996)
	loc_loss: 0.175289 (0.197551)	total_loss: 1.191895 (1.260788)

[2023-05-05 00:31:37,472-rk0-log_helper.py#102] Progress: 4020 / 15625 [25%], Speed: 2.468 s/iter, ETA 0:07:57 (D:H:M)

[2023-05-05 00:32:26,813-rk0-train.py#348] Epoch: [7][290/625] lr: 0.001329
	batch_time: 2.447938 (2.464628)	data_time: 0.001619 (0.001928)
	loss_fool: 0.203404 (0.185445)	loss_train_adv: 0.016348 (0.010445)
	cen_loss: 0.613235 (0.614926)	cls_loss: 0.059877 (0.052319)
	loc_loss: 0.191625 (0.197403)	total_loss: 1.247986 (1.259455)

[2023-05-05 00:32:26,814-rk0-log_helper.py#102] Progress: 4040 / 15625 [25%], Speed: 2.465 s/iter, ETA 0:07:55 (D:H:M)

[2023-05-05 00:33:16,291-rk0-train.py#348] Epoch: [7][310/625] lr: 0.001329
	batch_time: 2.438219 (2.468663)	data_time: 0.001220 (0.001954)
	loss_fool: 0.202366 (0.186718)	loss_train_adv: 0.010233 (0.009745)
	cen_loss: 0.620816 (0.614759)	cls_loss: 0.052084 (0.051138)
	loc_loss: 0.199925 (0.198369)	total_loss: 1.272676 (1.261005)

[2023-05-05 00:33:16,292-rk0-log_helper.py#102] Progress: 4060 / 15625 [25%], Speed: 2.469 s/iter, ETA 0:07:55 (D:H:M)

[2023-05-05 00:34:05,196-rk0-train.py#348] Epoch: [7][330/625] lr: 0.001329
	batch_time: 2.443173 (2.461177)	data_time: 0.001483 (0.002045)
	loss_fool: 0.214701 (0.186612)	loss_train_adv: 0.013342 (0.009465)
	cen_loss: 0.614484 (0.614465)	cls_loss: 0.043731 (0.051131)
	loc_loss: 0.160204 (0.196377)	total_loss: 1.138826 (1.254727)

[2023-05-05 00:34:05,197-rk0-log_helper.py#102] Progress: 4080 / 15625 [26%], Speed: 2.461 s/iter, ETA 0:07:53 (D:H:M)

[2023-05-05 00:34:54,863-rk0-train.py#348] Epoch: [7][350/625] lr: 0.001329
	batch_time: 2.372405 (2.462541)	data_time: 0.001523 (0.002296)
	loss_fool: 0.183254 (0.186635)	loss_train_adv: 0.007366 (0.009390)
	cen_loss: 0.609728 (0.614661)	cls_loss: 0.041939 (0.051359)
	loc_loss: 0.166084 (0.194574)	total_loss: 1.149918 (1.249744)

[2023-05-05 00:34:54,864-rk0-log_helper.py#102] Progress: 4100 / 15625 [26%], Speed: 2.463 s/iter, ETA 0:07:53 (D:H:M)

[2023-05-05 00:35:44,625-rk0-train.py#348] Epoch: [7][370/625] lr: 0.001329
	batch_time: 2.458194 (2.466031)	data_time: 0.001661 (0.002360)
	loss_fool: 0.192081 (0.187381)	loss_train_adv: 0.012784 (0.009296)
	cen_loss: 0.614387 (0.614421)	cls_loss: 0.043212 (0.052525)
	loc_loss: 0.171226 (0.192494)	total_loss: 1.171277 (1.244428)

[2023-05-05 00:35:44,626-rk0-log_helper.py#102] Progress: 4120 / 15625 [26%], Speed: 2.466 s/iter, ETA 0:07:52 (D:H:M)

[2023-05-05 00:36:34,162-rk0-train.py#348] Epoch: [7][390/625] lr: 0.001329
	batch_time: 2.573368 (2.468188)	data_time: 0.000721 (0.002545)
	loss_fool: 0.181709 (0.185700)	loss_train_adv: 0.006263 (0.009540)
	cen_loss: 0.603560 (0.614628)	cls_loss: 0.042069 (0.053522)
	loc_loss: 0.182091 (0.192802)	total_loss: 1.191901 (1.246555)

[2023-05-05 00:36:34,163-rk0-log_helper.py#102] Progress: 4140 / 15625 [26%], Speed: 2.468 s/iter, ETA 0:07:52 (D:H:M)

[2023-05-05 00:37:23,535-rk0-train.py#348] Epoch: [7][410/625] lr: 0.001329
	batch_time: 2.372864 (2.466736)	data_time: 0.001212 (0.002500)
	loss_fool: 0.195325 (0.185508)	loss_train_adv: 0.009301 (0.009637)
	cen_loss: 0.618008 (0.615142)	cls_loss: 0.034449 (0.053406)
	loc_loss: 0.173631 (0.191693)	total_loss: 1.173349 (1.243626)

[2023-05-05 00:37:23,536-rk0-log_helper.py#102] Progress: 4160 / 15625 [26%], Speed: 2.467 s/iter, ETA 0:07:51 (D:H:M)

[2023-05-05 00:38:13,162-rk0-train.py#348] Epoch: [7][430/625] lr: 0.001329
	batch_time: 2.354067 (2.473569)	data_time: 0.001494 (0.002484)
	loss_fool: 0.175677 (0.186169)	loss_train_adv: 0.006128 (0.009486)
	cen_loss: 0.618353 (0.614763)	cls_loss: 0.047232 (0.052538)
	loc_loss: 0.197063 (0.192250)	total_loss: 1.256774 (1.244052)

[2023-05-05 00:38:13,163-rk0-log_helper.py#102] Progress: 4180 / 15625 [26%], Speed: 2.474 s/iter, ETA 0:07:51 (D:H:M)

[2023-05-05 00:39:02,561-rk0-train.py#348] Epoch: [7][450/625] lr: 0.001329
	batch_time: 2.448044 (2.471071)	data_time: 0.001491 (0.002215)
	loss_fool: 0.178198 (0.185906)	loss_train_adv: 0.003883 (0.009792)
	cen_loss: 0.623022 (0.614660)	cls_loss: 0.053400 (0.052538)
	loc_loss: 0.235875 (0.192510)	total_loss: 1.384048 (1.244729)

[2023-05-05 00:39:02,561-rk0-log_helper.py#102] Progress: 4200 / 15625 [26%], Speed: 2.471 s/iter, ETA 0:07:50 (D:H:M)

[2023-05-05 00:39:51,523-rk0-train.py#348] Epoch: [7][470/625] lr: 0.001329
	batch_time: 2.485226 (2.463287)	data_time: 0.001507 (0.002069)
	loss_fool: 0.194268 (0.186608)	loss_train_adv: 0.007015 (0.009314)
	cen_loss: 0.609782 (0.614866)	cls_loss: 0.051576 (0.051701)
	loc_loss: 0.200946 (0.194202)	total_loss: 1.264195 (1.249173)

[2023-05-05 00:39:51,524-rk0-log_helper.py#102] Progress: 4220 / 15625 [27%], Speed: 2.463 s/iter, ETA 0:07:48 (D:H:M)

[2023-05-05 00:40:41,276-rk0-train.py#348] Epoch: [7][490/625] lr: 0.001329
	batch_time: 3.369281 (2.466154)	data_time: 0.001190 (0.001973)
	loss_fool: 0.185868 (0.187262)	loss_train_adv: 0.004589 (0.008876)
	cen_loss: 0.612305 (0.614999)	cls_loss: 0.055867 (0.052065)
	loc_loss: 0.195769 (0.193726)	total_loss: 1.255480 (1.248243)

[2023-05-05 00:40:41,276-rk0-log_helper.py#102] Progress: 4240 / 15625 [27%], Speed: 2.466 s/iter, ETA 0:07:47 (D:H:M)

[2023-05-05 00:41:30,591-rk0-train.py#348] Epoch: [7][510/625] lr: 0.001329
	batch_time: 2.397703 (2.466097)	data_time: 0.001236 (0.001946)
	loss_fool: 0.168198 (0.188304)	loss_train_adv: 0.008579 (0.008195)
	cen_loss: 0.607713 (0.614470)	cls_loss: 0.064367 (0.054119)
	loc_loss: 0.179147 (0.194017)	total_loss: 1.209521 (1.250641)

[2023-05-05 00:41:30,591-rk0-log_helper.py#102] Progress: 4260 / 15625 [27%], Speed: 2.466 s/iter, ETA 0:07:47 (D:H:M)

[2023-05-05 00:42:20,488-rk0-train.py#348] Epoch: [7][530/625] lr: 0.001329
	batch_time: 2.454000 (2.468546)	data_time: 0.001226 (0.001945)
	loss_fool: 0.200705 (0.187720)	loss_train_adv: 0.012232 (0.008554)
	cen_loss: 0.612904 (0.614243)	cls_loss: 0.042899 (0.054335)
	loc_loss: 0.203190 (0.193599)	total_loss: 1.265373 (1.249375)

[2023-05-05 00:42:20,488-rk0-log_helper.py#102] Progress: 4280 / 15625 [27%], Speed: 2.469 s/iter, ETA 0:07:46 (D:H:M)

[2023-05-05 00:43:10,095-rk0-train.py#348] Epoch: [7][550/625] lr: 0.001329
	batch_time: 2.510678 (2.470308)	data_time: 0.001072 (0.001888)
	loss_fool: 0.199579 (0.187316)	loss_train_adv: 0.017692 (0.008993)
	cen_loss: 0.621294 (0.614146)	cls_loss: 0.061732 (0.055194)
	loc_loss: 0.194394 (0.193390)	total_loss: 1.266207 (1.249511)

[2023-05-05 00:43:10,096-rk0-log_helper.py#102] Progress: 4300 / 15625 [27%], Speed: 2.470 s/iter, ETA 0:07:46 (D:H:M)

[2023-05-05 00:43:59,157-rk0-train.py#348] Epoch: [7][570/625] lr: 0.001329
	batch_time: 2.369320 (2.471358)	data_time: 0.001137 (0.001975)
	loss_fool: 0.185450 (0.186505)	loss_train_adv: 0.005493 (0.008874)
	cen_loss: 0.611966 (0.614006)	cls_loss: 0.036355 (0.055183)
	loc_loss: 0.179427 (0.192430)	total_loss: 1.186603 (1.246480)

[2023-05-05 00:43:59,158-rk0-log_helper.py#102] Progress: 4320 / 15625 [27%], Speed: 2.471 s/iter, ETA 0:07:45 (D:H:M)

[2023-05-05 00:44:48,620-rk0-train.py#348] Epoch: [7][590/625] lr: 0.001329
	batch_time: 2.396059 (2.468040)	data_time: 0.001179 (0.001881)
	loss_fool: 0.190703 (0.186873)	loss_train_adv: 0.012253 (0.009207)
	cen_loss: 0.613844 (0.614152)	cls_loss: 0.044573 (0.054451)
	loc_loss: 0.177253 (0.192317)	total_loss: 1.190177 (1.245554)

[2023-05-05 00:44:48,621-rk0-log_helper.py#102] Progress: 4340 / 15625 [27%], Speed: 2.468 s/iter, ETA 0:07:44 (D:H:M)

[2023-05-05 00:45:37,099-rk0-train.py#348] Epoch: [7][610/625] lr: 0.001329
	batch_time: 2.378169 (2.459526)	data_time: 0.001253 (0.001856)
	loss_fool: 0.213157 (0.186935)	loss_train_adv: 0.008866 (0.009352)
	cen_loss: 0.605429 (0.613937)	cls_loss: 0.045601 (0.051967)
	loc_loss: 0.178696 (0.190840)	total_loss: 1.187119 (1.238424)

[2023-05-05 00:45:37,100-rk0-log_helper.py#102] Progress: 4360 / 15625 [27%], Speed: 2.460 s/iter, ETA 0:07:41 (D:H:M)

[2023-05-05 00:46:15,108-rk0-train.py#235] epoch: 8
[2023-05-05 00:46:15,108-rk0-train.py#240] epoch 8 lr 0.00011771399555271923
[2023-05-05 00:46:15,109-rk0-train.py#240] epoch 8 lr 0.001177139955527192
[2023-05-05 00:46:15,113-rk0-train.py#240] epoch 8 lr 0.003923799851757307
[2023-05-05 00:46:15,121-rk0-train.py#240] epoch 8 lr 0.001177139955527192
[2023-05-05 00:46:15,122-rk0-train.py#240] epoch 8 lr 0.001177139955527192
[2023-05-05 00:46:27,486-rk0-train.py#348] Epoch: [8][5/625] lr: 0.001177
	batch_time: 2.467411 (2.464536)	data_time: 0.001276 (0.014243)
	loss_fool: 0.215977 (0.186246)	loss_train_adv: 0.006139 (0.009471)
	cen_loss: 0.606762 (0.614206)	cls_loss: 0.039559 (0.051223)
	loc_loss: 0.168469 (0.190326)	total_loss: 1.151729 (1.236406)

[2023-05-05 00:46:27,488-rk0-log_helper.py#102] Progress: 4380 / 15625 [28%], Speed: 2.465 s/iter, ETA 0:07:41 (D:H:M)

[2023-05-05 00:47:16,855-rk0-train.py#348] Epoch: [8][25/625] lr: 0.001177
	batch_time: 2.470057 (2.462338)	data_time: 0.001142 (0.014369)
	loss_fool: 0.203187 (0.186745)	loss_train_adv: 0.006953 (0.009128)
	cen_loss: 0.612869 (0.614166)	cls_loss: 0.039723 (0.049249)
	loc_loss: 0.199553 (0.189555)	total_loss: 1.251250 (1.232079)

[2023-05-05 00:47:16,855-rk0-log_helper.py#102] Progress: 4400 / 15625 [28%], Speed: 2.462 s/iter, ETA 0:07:40 (D:H:M)

[2023-05-05 00:48:05,577-rk0-train.py#348] Epoch: [8][45/625] lr: 0.001177
	batch_time: 2.506292 (2.458965)	data_time: 0.001292 (0.014434)
	loss_fool: 0.196243 (0.186945)	loss_train_adv: 0.010197 (0.009308)
	cen_loss: 0.614866 (0.614157)	cls_loss: 0.050781 (0.049466)
	loc_loss: 0.175723 (0.189059)	total_loss: 1.192816 (1.230799)

[2023-05-05 00:48:05,578-rk0-log_helper.py#102] Progress: 4420 / 15625 [28%], Speed: 2.459 s/iter, ETA 0:07:39 (D:H:M)

[2023-05-05 00:48:56,163-rk0-train.py#348] Epoch: [8][65/625] lr: 0.001177
	batch_time: 2.483230 (2.469595)	data_time: 0.000654 (0.014588)
	loss_fool: 0.202342 (0.186598)	loss_train_adv: 0.007830 (0.009182)
	cen_loss: 0.614686 (0.614045)	cls_loss: 0.035961 (0.049798)
	loc_loss: 0.182131 (0.189311)	total_loss: 1.197040 (1.231776)

[2023-05-05 00:48:56,164-rk0-log_helper.py#102] Progress: 4440 / 15625 [28%], Speed: 2.470 s/iter, ETA 0:07:40 (D:H:M)

[2023-05-05 00:49:45,183-rk0-train.py#348] Epoch: [8][85/625] lr: 0.001177
	batch_time: 2.377549 (2.474825)	data_time: 0.001416 (0.014470)
	loss_fool: 0.203957 (0.186249)	loss_train_adv: 0.038033 (0.010045)
	cen_loss: 0.612354 (0.614039)	cls_loss: 0.041654 (0.050301)
	loc_loss: 0.188297 (0.190223)	total_loss: 1.218900 (1.235009)

[2023-05-05 00:49:45,183-rk0-log_helper.py#102] Progress: 4460 / 15625 [28%], Speed: 2.475 s/iter, ETA 0:07:40 (D:H:M)

[2023-05-05 00:50:34,952-rk0-train.py#348] Epoch: [8][105/625] lr: 0.001177
	batch_time: 2.425361 (2.468946)	data_time: 0.001245 (0.002062)
	loss_fool: 0.035624 (0.179823)	loss_train_adv: 0.086526 (0.015428)
	cen_loss: 0.616038 (0.613966)	cls_loss: 0.055757 (0.051732)
	loc_loss: 0.209774 (0.190743)	total_loss: 1.301116 (1.237928)

[2023-05-05 00:50:34,953-rk0-log_helper.py#102] Progress: 4480 / 15625 [28%], Speed: 2.469 s/iter, ETA 0:07:38 (D:H:M)

[2023-05-05 00:51:25,107-rk0-train.py#348] Epoch: [8][125/625] lr: 0.001177
	batch_time: 2.529328 (2.477145)	data_time: 0.001448 (0.002258)
	loss_fool: 0.135242 (0.161236)	loss_train_adv: 0.024969 (0.024792)
	cen_loss: 0.617965 (0.613791)	cls_loss: 0.056938 (0.052664)
	loc_loss: 0.229773 (0.191344)	total_loss: 1.364222 (1.240488)

[2023-05-05 00:51:25,108-rk0-log_helper.py#102] Progress: 4500 / 15625 [28%], Speed: 2.477 s/iter, ETA 0:07:39 (D:H:M)

[2023-05-05 00:52:15,063-rk0-train.py#348] Epoch: [8][145/625] lr: 0.001177
	batch_time: 2.485596 (2.489171)	data_time: 0.001456 (0.002165)
	loss_fool: 0.141571 (0.159984)	loss_train_adv: 0.019359 (0.027575)
	cen_loss: 0.614628 (0.613744)	cls_loss: 0.037242 (0.053172)
	loc_loss: 0.171472 (0.192836)	total_loss: 1.166285 (1.245425)

[2023-05-05 00:52:15,064-rk0-log_helper.py#102] Progress: 4520 / 15625 [28%], Speed: 2.489 s/iter, ETA 0:07:40 (D:H:M)

[2023-05-05 00:53:04,498-rk0-train.py#348] Epoch: [8][165/625] lr: 0.001177
	batch_time: 2.424117 (2.478310)	data_time: 0.001464 (0.002160)
	loss_fool: 0.208808 (0.156167)	loss_train_adv: 0.008737 (0.030325)
	cen_loss: 0.617109 (0.613595)	cls_loss: 0.034608 (0.054170)
	loc_loss: 0.164137 (0.193463)	total_loss: 1.144130 (1.248154)

[2023-05-05 00:53:04,499-rk0-log_helper.py#102] Progress: 4540 / 15625 [29%], Speed: 2.478 s/iter, ETA 0:07:37 (D:H:M)

[2023-05-05 00:53:53,859-rk0-train.py#348] Epoch: [8][185/625] lr: 0.001177
	batch_time: 2.601956 (2.481793)	data_time: 0.001310 (0.002016)
	loss_fool: 0.187018 (0.152428)	loss_train_adv: 0.017257 (0.032421)
	cen_loss: 0.620285 (0.613701)	cls_loss: 0.063846 (0.054866)
	loc_loss: 0.203354 (0.193958)	total_loss: 1.294193 (1.250439)

[2023-05-05 00:53:53,859-rk0-log_helper.py#102] Progress: 4560 / 15625 [29%], Speed: 2.482 s/iter, ETA 0:07:37 (D:H:M)

[2023-05-05 00:54:43,289-rk0-train.py#348] Epoch: [8][205/625] lr: 0.001177
	batch_time: 2.495356 (2.478175)	data_time: 0.001352 (0.002050)
	loss_fool: 0.205219 (0.157654)	loss_train_adv: 0.019627 (0.028421)
	cen_loss: 0.611194 (0.613950)	cls_loss: 0.061692 (0.053708)
	loc_loss: 0.222418 (0.193493)	total_loss: 1.340142 (1.248137)

[2023-05-05 00:54:43,290-rk0-log_helper.py#102] Progress: 4580 / 15625 [29%], Speed: 2.478 s/iter, ETA 0:07:36 (D:H:M)

[2023-05-05 00:55:32,238-rk0-train.py#348] Epoch: [8][225/625] lr: 0.001177
	batch_time: 2.472231 (2.466042)	data_time: 0.001370 (0.001721)
	loss_fool: 0.171596 (0.174023)	loss_train_adv: 0.013599 (0.020367)
	cen_loss: 0.619868 (0.613997)	cls_loss: 0.045151 (0.052741)
	loc_loss: 0.200917 (0.192314)	total_loss: 1.267769 (1.243680)

[2023-05-05 00:55:32,240-rk0-log_helper.py#102] Progress: 4600 / 15625 [29%], Speed: 2.466 s/iter, ETA 0:07:33 (D:H:M)

[2023-05-05 00:56:21,186-rk0-train.py#348] Epoch: [8][245/625] lr: 0.001177
	batch_time: 2.360253 (2.456696)	data_time: 0.001155 (0.001847)
	loss_fool: 0.191864 (0.172898)	loss_train_adv: 0.022004 (0.019217)
	cen_loss: 0.618601 (0.614264)	cls_loss: 0.054608 (0.052455)
	loc_loss: 0.227764 (0.191742)	total_loss: 1.356501 (1.241945)

[2023-05-05 00:56:21,187-rk0-log_helper.py#102] Progress: 4620 / 15625 [29%], Speed: 2.457 s/iter, ETA 0:07:30 (D:H:M)

[2023-05-05 00:57:10,848-rk0-train.py#348] Epoch: [8][265/625] lr: 0.001177
	batch_time: 2.407170 (2.458306)	data_time: 0.001316 (0.001674)
	loss_fool: 0.183495 (0.175381)	loss_train_adv: 0.013660 (0.017962)
	cen_loss: 0.616592 (0.614388)	cls_loss: 0.059345 (0.052127)
	loc_loss: 0.220964 (0.190234)	total_loss: 1.338829 (1.237218)

[2023-05-05 00:57:10,849-rk0-log_helper.py#102] Progress: 4640 / 15625 [29%], Speed: 2.458 s/iter, ETA 0:07:30 (D:H:M)

[2023-05-05 00:58:01,418-rk0-train.py#348] Epoch: [8][285/625] lr: 0.001177
	batch_time: 2.327945 (2.470675)	data_time: 0.001373 (0.001767)
	loss_fool: 0.164245 (0.177429)	loss_train_adv: 0.011747 (0.016568)
	cen_loss: 0.614700 (0.614622)	cls_loss: 0.042480 (0.052247)
	loc_loss: 0.198647 (0.189446)	total_loss: 1.253121 (1.235208)

[2023-05-05 00:58:01,419-rk0-log_helper.py#102] Progress: 4660 / 15625 [29%], Speed: 2.471 s/iter, ETA 0:07:31 (D:H:M)

[2023-05-05 00:58:50,719-rk0-train.py#348] Epoch: [8][305/625] lr: 0.001177
	batch_time: 2.411339 (2.469174)	data_time: 0.001162 (0.001874)
	loss_fool: 0.176907 (0.178103)	loss_train_adv: 0.015980 (0.015621)
	cen_loss: 0.612404 (0.614608)	cls_loss: 0.049116 (0.053309)
	loc_loss: 0.186989 (0.190428)	total_loss: 1.222486 (1.239202)

[2023-05-05 00:58:50,720-rk0-log_helper.py#102] Progress: 4680 / 15625 [29%], Speed: 2.469 s/iter, ETA 0:07:30 (D:H:M)

[2023-05-05 00:59:39,428-rk0-train.py#348] Epoch: [8][325/625] lr: 0.001177
	batch_time: 2.442517 (2.466471)	data_time: 0.015062 (0.002117)
	loss_fool: 0.188391 (0.178779)	loss_train_adv: 0.016495 (0.015300)
	cen_loss: 0.616224 (0.614494)	cls_loss: 0.037231 (0.054269)
	loc_loss: 0.173054 (0.191458)	total_loss: 1.172619 (1.243137)

[2023-05-05 00:59:39,428-rk0-log_helper.py#102] Progress: 4700 / 15625 [30%], Speed: 2.466 s/iter, ETA 0:07:29 (D:H:M)

[2023-05-05 01:00:28,103-rk0-train.py#348] Epoch: [8][345/625] lr: 0.001177
	batch_time: 2.426739 (2.463505)	data_time: 0.004077 (0.002190)
	loss_fool: 0.177364 (0.180104)	loss_train_adv: 0.016406 (0.014883)
	cen_loss: 0.615695 (0.614237)	cls_loss: 0.042970 (0.053604)
	loc_loss: 0.182430 (0.190576)	total_loss: 1.205954 (1.239570)

[2023-05-05 01:00:28,104-rk0-log_helper.py#102] Progress: 4720 / 15625 [30%], Speed: 2.464 s/iter, ETA 0:07:27 (D:H:M)

[2023-05-05 01:01:16,671-rk0-train.py#348] Epoch: [8][365/625] lr: 0.001177
	batch_time: 2.366730 (2.453342)	data_time: 0.001249 (0.002189)
	loss_fool: 0.170395 (0.180565)	loss_train_adv: 0.010286 (0.014419)
	cen_loss: 0.623415 (0.614213)	cls_loss: 0.043058 (0.053359)
	loc_loss: 0.215121 (0.191468)	total_loss: 1.311837 (1.241976)

[2023-05-05 01:01:16,671-rk0-log_helper.py#102] Progress: 4740 / 15625 [30%], Speed: 2.453 s/iter, ETA 0:07:25 (D:H:M)

[2023-05-05 01:02:05,738-rk0-train.py#348] Epoch: [8][385/625] lr: 0.001177
	batch_time: 2.435157 (2.437996)	data_time: 0.001284 (0.002284)
	loss_fool: 0.177982 (0.180173)	loss_train_adv: 0.011511 (0.014499)
	cen_loss: 0.613398 (0.613998)	cls_loss: 0.046916 (0.052453)
	loc_loss: 0.188891 (0.191371)	total_loss: 1.226988 (1.240564)

[2023-05-05 01:02:05,739-rk0-log_helper.py#102] Progress: 4760 / 15625 [30%], Speed: 2.438 s/iter, ETA 0:07:21 (D:H:M)

[2023-05-05 01:02:55,042-rk0-train.py#348] Epoch: [8][405/625] lr: 0.001177
	batch_time: 2.430863 (2.437931)	data_time: 0.000545 (0.002139)
	loss_fool: 0.206436 (0.180378)	loss_train_adv: 0.012685 (0.015150)
	cen_loss: 0.613563 (0.613964)	cls_loss: 0.043158 (0.050800)
	loc_loss: 0.160144 (0.187844)	total_loss: 1.137153 (1.228297)

[2023-05-05 01:02:55,044-rk0-log_helper.py#102] Progress: 4780 / 15625 [30%], Speed: 2.438 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-05 01:03:44,059-rk0-train.py#348] Epoch: [8][425/625] lr: 0.001177
	batch_time: 2.338828 (2.441706)	data_time: 0.001295 (0.001909)
	loss_fool: 0.187567 (0.180447)	loss_train_adv: 0.019447 (0.015047)
	cen_loss: 0.623984 (0.614069)	cls_loss: 0.049289 (0.050662)
	loc_loss: 0.219744 (0.186132)	total_loss: 1.332506 (1.223125)

[2023-05-05 01:03:44,060-rk0-log_helper.py#102] Progress: 4800 / 15625 [30%], Speed: 2.442 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-05 01:04:32,959-rk0-train.py#348] Epoch: [8][445/625] lr: 0.001177
	batch_time: 2.436896 (2.443575)	data_time: 0.001131 (0.001681)
	loss_fool: 0.172191 (0.181000)	loss_train_adv: 0.013938 (0.014698)
	cen_loss: 0.615968 (0.614121)	cls_loss: 0.052175 (0.050305)
	loc_loss: 0.196310 (0.186088)	total_loss: 1.257071 (1.222688)

[2023-05-05 01:04:32,959-rk0-log_helper.py#102] Progress: 4820 / 15625 [30%], Speed: 2.444 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-05 01:05:22,487-rk0-train.py#348] Epoch: [8][465/625] lr: 0.001177
	batch_time: 2.415559 (2.453139)	data_time: 0.001149 (0.002129)
	loss_fool: 0.174092 (0.180862)	loss_train_adv: 0.016909 (0.014514)
	cen_loss: 0.615498 (0.614023)	cls_loss: 0.101646 (0.049746)
	loc_loss: 0.230940 (0.185366)	total_loss: 1.409962 (1.219866)

[2023-05-05 01:05:22,487-rk0-log_helper.py#102] Progress: 4840 / 15625 [30%], Speed: 2.453 s/iter, ETA 0:07:20 (D:H:M)

[2023-05-05 01:06:12,783-rk0-train.py#348] Epoch: [8][485/625] lr: 0.001177
	batch_time: 2.432573 (2.465493)	data_time: 0.001141 (0.002399)
	loss_fool: 0.185209 (0.181847)	loss_train_adv: 0.006236 (0.013844)
	cen_loss: 0.614084 (0.614233)	cls_loss: 0.041878 (0.051031)
	loc_loss: 0.184112 (0.186419)	total_loss: 1.208299 (1.224521)

[2023-05-05 01:06:12,785-rk0-log_helper.py#102] Progress: 4860 / 15625 [31%], Speed: 2.465 s/iter, ETA 0:07:22 (D:H:M)

[2023-05-05 01:07:00,983-rk0-train.py#348] Epoch: [8][505/625] lr: 0.001177
	batch_time: 2.507209 (2.455025)	data_time: 0.001174 (0.002310)
	loss_fool: 0.184767 (0.182508)	loss_train_adv: 0.011078 (0.012592)
	cen_loss: 0.612388 (0.614087)	cls_loss: 0.063846 (0.051405)
	loc_loss: 0.202110 (0.187824)	total_loss: 1.282565 (1.228964)

[2023-05-05 01:07:00,985-rk0-log_helper.py#102] Progress: 4880 / 15625 [31%], Speed: 2.455 s/iter, ETA 0:07:19 (D:H:M)

[2023-05-05 01:07:50,162-rk0-train.py#348] Epoch: [8][525/625] lr: 0.001177
	batch_time: 2.350588 (2.456388)	data_time: 0.001323 (0.002344)
	loss_fool: 0.196047 (0.182750)	loss_train_adv: 0.004461 (0.012752)
	cen_loss: 0.613927 (0.614193)	cls_loss: 0.047136 (0.051695)
	loc_loss: 0.179357 (0.189489)	total_loss: 1.199133 (1.234355)

[2023-05-05 01:07:50,163-rk0-log_helper.py#102] Progress: 4900 / 15625 [31%], Speed: 2.456 s/iter, ETA 0:07:19 (D:H:M)

[2023-05-05 01:08:38,337-rk0-train.py#348] Epoch: [8][545/625] lr: 0.001177
	batch_time: 2.418350 (2.449367)	data_time: 0.001410 (0.002259)
	loss_fool: 0.182579 (0.182453)	loss_train_adv: 0.013371 (0.012518)
	cen_loss: 0.619384 (0.614435)	cls_loss: 0.047056 (0.052578)
	loc_loss: 0.205410 (0.189577)	total_loss: 1.282669 (1.235744)

[2023-05-05 01:08:38,337-rk0-log_helper.py#102] Progress: 4920 / 15625 [31%], Speed: 2.449 s/iter, ETA 0:07:17 (D:H:M)

[2023-05-05 01:09:26,814-rk0-train.py#348] Epoch: [8][565/625] lr: 0.001177
	batch_time: 2.369686 (2.438987)	data_time: 0.001122 (0.001891)
	loss_fool: 0.171349 (0.183217)	loss_train_adv: 0.011551 (0.012305)
	cen_loss: 0.616008 (0.614430)	cls_loss: 0.040330 (0.053661)
	loc_loss: 0.178016 (0.190312)	total_loss: 1.190387 (1.239028)

[2023-05-05 01:09:26,815-rk0-log_helper.py#102] Progress: 4940 / 15625 [31%], Speed: 2.439 s/iter, ETA 0:07:14 (D:H:M)

[2023-05-05 01:10:15,956-rk0-train.py#348] Epoch: [8][585/625] lr: 0.001177
	batch_time: 2.445222 (2.427105)	data_time: 0.001416 (0.001608)
	loss_fool: 0.158475 (0.183314)	loss_train_adv: 0.014762 (0.012208)
	cen_loss: 0.609719 (0.614354)	cls_loss: 0.070227 (0.054299)
	loc_loss: 0.196405 (0.190728)	total_loss: 1.269161 (1.240839)

[2023-05-05 01:10:15,956-rk0-log_helper.py#102] Progress: 4960 / 15625 [31%], Speed: 2.427 s/iter, ETA 0:07:11 (D:H:M)

[2023-05-05 01:11:04,829-rk0-train.py#348] Epoch: [8][605/625] lr: 0.001177
	batch_time: 2.423256 (2.433977)	data_time: 0.001589 (0.001752)
	loss_fool: 0.181316 (0.183443)	loss_train_adv: 0.009729 (0.012231)
	cen_loss: 0.608387 (0.614278)	cls_loss: 0.041460 (0.055171)
	loc_loss: 0.173018 (0.191641)	total_loss: 1.168900 (1.244373)

[2023-05-05 01:11:04,829-rk0-log_helper.py#102] Progress: 4980 / 15625 [31%], Speed: 2.434 s/iter, ETA 0:07:11 (D:H:M)

[2023-05-05 01:11:54,015-rk0-train.py#348] Epoch: [8][0/625] lr: 0.001177
	batch_time: 2.342860 (2.434041)	data_time: 0.000563 (0.001966)
	loss_fool: 0.201094 (0.184549)	loss_train_adv: 0.007272 (0.011338)
	cen_loss: 0.619534 (0.614359)	cls_loss: 0.112784 (0.055281)
	loc_loss: 0.222723 (0.190406)	total_loss: 1.400486 (1.240859)

[2023-05-05 01:11:54,015-rk0-log_helper.py#102] Progress: 5000 / 15625 [32%], Speed: 2.434 s/iter, ETA 0:07:11 (D:H:M)

[2023-05-05 01:11:55,202-rk0-train.py#235] epoch: 9
[2023-05-05 01:11:55,202-rk0-train.py#240] epoch 9 lr 0.00010427891942663408
[2023-05-05 01:11:55,203-rk0-train.py#240] epoch 9 lr 0.0010427891942663408
[2023-05-05 01:11:55,204-rk0-train.py#240] epoch 9 lr 0.0034759639808878023
[2023-05-05 01:11:55,204-rk0-train.py#240] epoch 9 lr 0.0010427891942663408
[2023-05-05 01:11:55,205-rk0-train.py#240] epoch 9 lr 0.0010427891942663408
[2023-05-05 01:12:45,024-rk0-train.py#348] Epoch: [9][20/625] lr: 0.001043
	batch_time: 2.396223 (2.462132)	data_time: 0.001458 (0.014117)
	loss_fool: 0.157942 (0.185202)	loss_train_adv: 0.012501 (0.011063)
	cen_loss: 0.617146 (0.614106)	cls_loss: 0.044384 (0.055702)
	loc_loss: 0.190915 (0.190359)	total_loss: 1.234275 (1.240884)

[2023-05-05 01:12:45,024-rk0-log_helper.py#102] Progress: 5020 / 15625 [32%], Speed: 2.462 s/iter, ETA 0:07:15 (D:H:M)

[2023-05-05 01:13:33,628-rk0-train.py#348] Epoch: [9][40/625] lr: 0.001043
	batch_time: 2.545181 (2.463639)	data_time: 0.004785 (0.014236)
	loss_fool: 0.160210 (0.185056)	loss_train_adv: 0.014539 (0.010874)
	cen_loss: 0.616300 (0.613899)	cls_loss: 0.065684 (0.055277)
	loc_loss: 0.191049 (0.190764)	total_loss: 1.255132 (1.241468)

[2023-05-05 01:13:33,629-rk0-log_helper.py#102] Progress: 5040 / 15625 [32%], Speed: 2.464 s/iter, ETA 0:07:14 (D:H:M)

[2023-05-05 01:14:22,182-rk0-train.py#348] Epoch: [9][60/625] lr: 0.001043
	batch_time: 2.634689 (2.457890)	data_time: 0.001470 (0.014009)
	loss_fool: 0.183672 (0.185043)	loss_train_adv: 0.005026 (0.010762)
	cen_loss: 0.616206 (0.613749)	cls_loss: 0.052186 (0.053810)
	loc_loss: 0.207898 (0.189058)	total_loss: 1.292087 (1.234734)

[2023-05-05 01:14:22,183-rk0-log_helper.py#102] Progress: 5060 / 15625 [32%], Speed: 2.458 s/iter, ETA 0:07:12 (D:H:M)

[2023-05-05 01:15:11,457-rk0-train.py#348] Epoch: [9][80/625] lr: 0.001043
	batch_time: 2.570103 (2.461637)	data_time: 0.001493 (0.014095)
	loss_fool: 0.192269 (0.186271)	loss_train_adv: 0.006511 (0.010258)
	cen_loss: 0.609055 (0.613875)	cls_loss: 0.040930 (0.053396)
	loc_loss: 0.200873 (0.189686)	total_loss: 1.252604 (1.236329)

[2023-05-05 01:15:11,458-rk0-log_helper.py#102] Progress: 5080 / 15625 [32%], Speed: 2.462 s/iter, ETA 0:07:12 (D:H:M)

[2023-05-05 01:16:00,815-rk0-train.py#348] Epoch: [9][100/625] lr: 0.001043
	batch_time: 2.433522 (2.463391)	data_time: 0.002163 (0.013904)
	loss_fool: 0.217213 (0.185643)	loss_train_adv: 0.011660 (0.010445)
	cen_loss: 0.617173 (0.613682)	cls_loss: 0.038995 (0.052956)
	loc_loss: 0.164383 (0.190884)	total_loss: 1.149316 (1.239291)

[2023-05-05 01:16:00,817-rk0-log_helper.py#102] Progress: 5100 / 15625 [32%], Speed: 2.463 s/iter, ETA 0:07:12 (D:H:M)

[2023-05-05 01:16:50,033-rk0-train.py#348] Epoch: [9][120/625] lr: 0.001043
	batch_time: 2.543660 (2.445639)	data_time: 0.001378 (0.001748)
	loss_fool: 0.210431 (0.185068)	loss_train_adv: 0.014090 (0.011156)
	cen_loss: 0.609364 (0.613271)	cls_loss: 0.055516 (0.052176)
	loc_loss: 0.208779 (0.190900)	total_loss: 1.291216 (1.238147)

[2023-05-05 01:16:50,034-rk0-log_helper.py#102] Progress: 5120 / 15625 [32%], Speed: 2.446 s/iter, ETA 0:07:08 (D:H:M)

[2023-05-05 01:17:39,084-rk0-train.py#348] Epoch: [9][140/625] lr: 0.001043
	batch_time: 2.353902 (2.449673)	data_time: 0.001221 (0.001696)
	loss_fool: 0.189616 (0.184586)	loss_train_adv: 0.015923 (0.011298)
	cen_loss: 0.618324 (0.613607)	cls_loss: 0.043147 (0.051550)
	loc_loss: 0.179667 (0.189817)	total_loss: 1.200474 (1.234608)

[2023-05-05 01:17:39,085-rk0-log_helper.py#102] Progress: 5140 / 15625 [32%], Speed: 2.450 s/iter, ETA 0:07:08 (D:H:M)

[2023-05-05 01:18:28,036-rk0-train.py#348] Epoch: [9][160/625] lr: 0.001043
	batch_time: 2.363005 (2.453688)	data_time: 0.001408 (0.002204)
	loss_fool: 0.193068 (0.184988)	loss_train_adv: 0.015515 (0.010976)
	cen_loss: 0.610377 (0.613393)	cls_loss: 0.050478 (0.051462)
	loc_loss: 0.185479 (0.189119)	total_loss: 1.217291 (1.232212)

[2023-05-05 01:18:28,037-rk0-log_helper.py#102] Progress: 5160 / 15625 [33%], Speed: 2.454 s/iter, ETA 0:07:07 (D:H:M)

[2023-05-05 01:19:17,356-rk0-train.py#348] Epoch: [9][180/625] lr: 0.001043
	batch_time: 2.487079 (2.454087)	data_time: 0.001283 (0.002333)
	loss_fool: 0.173448 (0.184165)	loss_train_adv: 0.005410 (0.011027)
	cen_loss: 0.612920 (0.613655)	cls_loss: 0.078778 (0.052585)
	loc_loss: 0.205900 (0.189818)	total_loss: 1.309398 (1.235693)

[2023-05-05 01:19:17,357-rk0-log_helper.py#102] Progress: 5180 / 15625 [33%], Speed: 2.454 s/iter, ETA 0:07:07 (D:H:M)

[2023-05-05 01:20:05,825-rk0-train.py#348] Epoch: [9][200/625] lr: 0.001043
	batch_time: 2.409343 (2.444967)	data_time: 0.001219 (0.002550)
	loss_fool: 0.190327 (0.185512)	loss_train_adv: 0.009927 (0.010452)
	cen_loss: 0.622973 (0.613594)	cls_loss: 0.067412 (0.052117)
	loc_loss: 0.207704 (0.187330)	total_loss: 1.313496 (1.227699)

[2023-05-05 01:20:05,825-rk0-log_helper.py#102] Progress: 5200 / 15625 [33%], Speed: 2.445 s/iter, ETA 0:07:04 (D:H:M)

[2023-05-05 01:20:54,580-rk0-train.py#348] Epoch: [9][220/625] lr: 0.001043
	batch_time: 2.454379 (2.440190)	data_time: 0.001297 (0.002562)
	loss_fool: 0.183217 (0.187141)	loss_train_adv: 0.009287 (0.009228)
	cen_loss: 0.609089 (0.613381)	cls_loss: 0.058124 (0.052144)
	loc_loss: 0.189783 (0.186071)	total_loss: 1.236562 (1.223740)

[2023-05-05 01:20:54,581-rk0-log_helper.py#102] Progress: 5220 / 15625 [33%], Speed: 2.440 s/iter, ETA 0:07:03 (D:H:M)

[2023-05-05 01:21:44,259-rk0-train.py#348] Epoch: [9][240/625] lr: 0.001043
	batch_time: 2.418562 (2.446751)	data_time: 0.001322 (0.002465)
	loss_fool: 0.181353 (0.187670)	loss_train_adv: 0.003035 (0.008506)
	cen_loss: 0.612930 (0.613560)	cls_loss: 0.061127 (0.053174)
	loc_loss: 0.182976 (0.186921)	total_loss: 1.222985 (1.227498)

[2023-05-05 01:21:44,260-rk0-log_helper.py#102] Progress: 5240 / 15625 [33%], Speed: 2.447 s/iter, ETA 0:07:03 (D:H:M)

[2023-05-05 01:22:33,476-rk0-train.py#348] Epoch: [9][260/625] lr: 0.001043
	batch_time: 2.382428 (2.449889)	data_time: 0.001162 (0.002178)
	loss_fool: 0.171185 (0.187944)	loss_train_adv: 0.015927 (0.008745)
	cen_loss: 0.608329 (0.613610)	cls_loss: 0.037968 (0.052611)
	loc_loss: 0.184376 (0.187093)	total_loss: 1.199423 (1.227500)

[2023-05-05 01:22:33,477-rk0-log_helper.py#102] Progress: 5260 / 15625 [33%], Speed: 2.450 s/iter, ETA 0:07:03 (D:H:M)

[2023-05-05 01:23:22,536-rk0-train.py#348] Epoch: [9][280/625] lr: 0.001043
	batch_time: 2.418116 (2.447038)	data_time: 0.001304 (0.001943)
	loss_fool: 0.196382 (0.189033)	loss_train_adv: 0.001305 (0.008489)
	cen_loss: 0.617406 (0.613596)	cls_loss: 0.037107 (0.052130)
	loc_loss: 0.179621 (0.185516)	total_loss: 1.193377 (1.222273)

[2023-05-05 01:23:22,537-rk0-log_helper.py#102] Progress: 5280 / 15625 [33%], Speed: 2.447 s/iter, ETA 0:07:01 (D:H:M)

[2023-05-05 01:24:11,457-rk0-train.py#348] Epoch: [9][300/625] lr: 0.001043
	batch_time: 2.536819 (2.451664)	data_time: 0.002013 (0.001760)
	loss_fool: 0.200375 (0.188312)	loss_train_adv: 0.006925 (0.008163)
	cen_loss: 0.610139 (0.613712)	cls_loss: 0.037675 (0.052979)
	loc_loss: 0.152390 (0.185732)	total_loss: 1.104983 (1.223887)

[2023-05-05 01:24:11,457-rk0-log_helper.py#102] Progress: 5300 / 15625 [33%], Speed: 2.452 s/iter, ETA 0:07:01 (D:H:M)

[2023-05-05 01:25:00,339-rk0-train.py#348] Epoch: [9][320/625] lr: 0.001043
	batch_time: 2.520455 (2.453273)	data_time: 0.004306 (0.001986)
	loss_fool: 0.201648 (0.188918)	loss_train_adv: 0.012217 (0.008101)
	cen_loss: 0.614457 (0.614720)	cls_loss: 0.056170 (0.054386)
	loc_loss: 0.178983 (0.187333)	total_loss: 1.207577 (1.231107)

[2023-05-05 01:25:00,340-rk0-log_helper.py#102] Progress: 5320 / 15625 [34%], Speed: 2.453 s/iter, ETA 0:07:01 (D:H:M)

[2023-05-05 01:25:49,530-rk0-train.py#348] Epoch: [9][340/625] lr: 0.001043
	batch_time: 2.372078 (2.448176)	data_time: 0.001358 (0.002259)
	loss_fool: 0.192538 (0.188602)	loss_train_adv: 0.007317 (0.008086)
	cen_loss: 0.610806 (0.614510)	cls_loss: 0.046561 (0.052634)
	loc_loss: 0.195316 (0.186425)	total_loss: 1.243315 (1.226418)

[2023-05-05 01:25:49,531-rk0-log_helper.py#102] Progress: 5340 / 15625 [34%], Speed: 2.448 s/iter, ETA 0:06:59 (D:H:M)

[2023-05-05 01:26:38,101-rk0-train.py#348] Epoch: [9][360/625] lr: 0.001043
	batch_time: 2.406299 (2.441199)	data_time: 0.001097 (0.002247)
	loss_fool: 0.193146 (0.189484)	loss_train_adv: 0.003186 (0.007393)
	cen_loss: 0.619358 (0.614818)	cls_loss: 0.048952 (0.053984)
	loc_loss: 0.196283 (0.187624)	total_loss: 1.257159 (1.231675)

[2023-05-05 01:26:38,101-rk0-log_helper.py#102] Progress: 5360 / 15625 [34%], Speed: 2.441 s/iter, ETA 0:06:57 (D:H:M)

[2023-05-05 01:27:26,703-rk0-train.py#348] Epoch: [9][380/625] lr: 0.001043
	batch_time: 2.464454 (2.436710)	data_time: 0.001291 (0.002313)
	loss_fool: 0.207237 (0.190099)	loss_train_adv: 0.006660 (0.006910)
	cen_loss: 0.617367 (0.614822)	cls_loss: 0.037307 (0.052369)
	loc_loss: 0.179123 (0.185993)	total_loss: 1.192043 (1.225170)

[2023-05-05 01:27:26,704-rk0-log_helper.py#102] Progress: 5380 / 15625 [34%], Speed: 2.437 s/iter, ETA 0:06:56 (D:H:M)

[2023-05-05 01:28:16,210-rk0-train.py#348] Epoch: [9][400/625] lr: 0.001043
	batch_time: 2.396459 (2.442347)	data_time: 0.001452 (0.002371)
	loss_fool: 0.186947 (0.190482)	loss_train_adv: 0.007152 (0.007049)
	cen_loss: 0.612635 (0.614684)	cls_loss: 0.038277 (0.051413)
	loc_loss: 0.165644 (0.187515)	total_loss: 1.147845 (1.228640)

[2023-05-05 01:28:16,211-rk0-log_helper.py#102] Progress: 5400 / 15625 [34%], Speed: 2.442 s/iter, ETA 0:06:56 (D:H:M)

[2023-05-05 01:29:05,215-rk0-train.py#348] Epoch: [9][420/625] lr: 0.001043
	batch_time: 2.491867 (2.443384)	data_time: 0.001484 (0.002295)
	loss_fool: 0.213884 (0.189708)	loss_train_adv: 0.010424 (0.007252)
	cen_loss: 0.606977 (0.613986)	cls_loss: 0.047836 (0.049213)
	loc_loss: 0.182854 (0.186495)	total_loss: 1.203375 (1.222684)

[2023-05-05 01:29:05,216-rk0-log_helper.py#102] Progress: 5420 / 15625 [34%], Speed: 2.443 s/iter, ETA 0:06:55 (D:H:M)

[2023-05-05 01:29:54,527-rk0-train.py#348] Epoch: [9][440/625] lr: 0.001043
	batch_time: 2.485354 (2.444804)	data_time: 0.001257 (0.002129)
	loss_fool: 0.194542 (0.190770)	loss_train_adv: 0.001506 (0.006961)
	cen_loss: 0.615774 (0.614218)	cls_loss: 0.040092 (0.050084)
	loc_loss: 0.187030 (0.188591)	total_loss: 1.216955 (1.230075)

[2023-05-05 01:29:54,527-rk0-log_helper.py#102] Progress: 5440 / 15625 [34%], Speed: 2.445 s/iter, ETA 0:06:55 (D:H:M)

[2023-05-05 01:30:42,981-rk0-train.py#348] Epoch: [9][460/625] lr: 0.001043
	batch_time: 2.473668 (2.444185)	data_time: 0.001270 (0.002295)
	loss_fool: 0.198651 (0.191324)	loss_train_adv: 0.002776 (0.006976)
	cen_loss: 0.611355 (0.614191)	cls_loss: 0.039280 (0.049590)
	loc_loss: 0.172242 (0.188554)	total_loss: 1.167361 (1.229444)

[2023-05-05 01:30:42,981-rk0-log_helper.py#102] Progress: 5460 / 15625 [34%], Speed: 2.444 s/iter, ETA 0:06:54 (D:H:M)

[2023-05-05 01:31:31,667-rk0-train.py#348] Epoch: [9][480/625] lr: 0.001043
	batch_time: 2.367667 (2.445328)	data_time: 0.001173 (0.002703)
	loss_fool: 0.193825 (0.189303)	loss_train_adv: 0.006484 (0.007260)
	cen_loss: 0.600715 (0.613885)	cls_loss: 0.061938 (0.049758)
	loc_loss: 0.200745 (0.188988)	total_loss: 1.264888 (1.230608)

[2023-05-05 01:31:31,667-rk0-log_helper.py#102] Progress: 5480 / 15625 [35%], Speed: 2.445 s/iter, ETA 0:06:53 (D:H:M)

[2023-05-05 01:32:20,156-rk0-train.py#348] Epoch: [9][500/625] lr: 0.001043
	batch_time: 2.367962 (2.435327)	data_time: 0.001228 (0.002517)
	loss_fool: 0.187301 (0.190892)	loss_train_adv: 0.002176 (0.006667)
	cen_loss: 0.617520 (0.614208)	cls_loss: 0.046031 (0.049860)
	loc_loss: 0.183835 (0.187597)	total_loss: 1.215055 (1.226859)

[2023-05-05 01:32:20,157-rk0-log_helper.py#102] Progress: 5500 / 15625 [35%], Speed: 2.435 s/iter, ETA 0:06:50 (D:H:M)

[2023-05-05 01:33:08,881-rk0-train.py#348] Epoch: [9][520/625] lr: 0.001043
	batch_time: 2.422390 (2.432855)	data_time: 0.001474 (0.002409)
	loss_fool: 0.205496 (0.191227)	loss_train_adv: 0.005885 (0.006447)
	cen_loss: 0.612290 (0.614514)	cls_loss: 0.059908 (0.050455)
	loc_loss: 0.198676 (0.189167)	total_loss: 1.268226 (1.232471)

[2023-05-05 01:33:08,882-rk0-log_helper.py#102] Progress: 5520 / 15625 [35%], Speed: 2.433 s/iter, ETA 0:06:49 (D:H:M)

[2023-05-05 01:33:57,734-rk0-train.py#348] Epoch: [9][540/625] lr: 0.001043
	batch_time: 2.456003 (2.428351)	data_time: 0.013849 (0.002740)
	loss_fool: 0.187633 (0.191216)	loss_train_adv: 0.010695 (0.006333)
	cen_loss: 0.612393 (0.614149)	cls_loss: 0.042720 (0.050504)
	loc_loss: 0.187946 (0.187094)	total_loss: 1.218950 (1.225934)

[2023-05-05 01:33:57,735-rk0-log_helper.py#102] Progress: 5540 / 15625 [35%], Speed: 2.428 s/iter, ETA 0:06:48 (D:H:M)

[2023-05-05 01:34:46,729-rk0-train.py#348] Epoch: [9][560/625] lr: 0.001043
	batch_time: 2.530794 (2.433242)	data_time: 0.001515 (0.002460)
	loss_fool: 0.183750 (0.191052)	loss_train_adv: 0.010638 (0.006001)
	cen_loss: 0.611520 (0.614118)	cls_loss: 0.028196 (0.050017)
	loc_loss: 0.172793 (0.184791)	total_loss: 1.158095 (1.218508)

[2023-05-05 01:34:46,733-rk0-log_helper.py#102] Progress: 5560 / 15625 [35%], Speed: 2.433 s/iter, ETA 0:06:48 (D:H:M)

[2023-05-05 01:35:34,793-rk0-train.py#348] Epoch: [9][580/625] lr: 0.001043
	batch_time: 2.268475 (2.427023)	data_time: 0.001381 (0.001886)
	loss_fool: 0.178132 (0.192574)	loss_train_adv: 0.006001 (0.006016)
	cen_loss: 0.615555 (0.614130)	cls_loss: 0.033965 (0.051043)
	loc_loss: 0.179475 (0.186739)	total_loss: 1.187945 (1.225389)

[2023-05-05 01:35:34,793-rk0-log_helper.py#102] Progress: 5580 / 15625 [35%], Speed: 2.427 s/iter, ETA 0:06:46 (D:H:M)

[2023-05-05 01:36:23,279-rk0-train.py#348] Epoch: [9][600/625] lr: 0.001043
	batch_time: 2.327978 (2.426804)	data_time: 0.001275 (0.002042)
	loss_fool: 0.153360 (0.191069)	loss_train_adv: 0.007509 (0.006525)
	cen_loss: 0.612531 (0.614035)	cls_loss: 0.088896 (0.052157)
	loc_loss: 0.217965 (0.188975)	total_loss: 1.355321 (1.233118)

[2023-05-05 01:36:23,279-rk0-log_helper.py#102] Progress: 5600 / 15625 [35%], Speed: 2.427 s/iter, ETA 0:06:45 (D:H:M)

[2023-05-05 01:37:13,122-rk0-train.py#348] Epoch: [9][620/625] lr: 0.001043
	batch_time: 2.402687 (2.438084)	data_time: 0.001063 (0.002214)
	loss_fool: 0.206147 (0.190563)	loss_train_adv: 0.002159 (0.006275)
	cen_loss: 0.610262 (0.614280)	cls_loss: 0.037828 (0.052933)
	loc_loss: 0.188389 (0.187922)	total_loss: 1.213256 (1.230979)

[2023-05-05 01:37:13,122-rk0-log_helper.py#102] Progress: 5620 / 15625 [35%], Speed: 2.438 s/iter, ETA 0:06:46 (D:H:M)

[2023-05-05 01:37:26,717-rk0-train.py#235] epoch: 10
[2023-05-05 01:37:26,717-rk0-train.py#240] epoch 10 lr 9.237723165990401e-05
[2023-05-05 01:37:26,718-rk0-train.py#240] epoch 10 lr 0.00092377231659904
[2023-05-05 01:37:26,719-rk0-train.py#240] epoch 10 lr 0.0030792410553301336
[2023-05-05 01:37:26,719-rk0-train.py#240] epoch 10 lr 0.00092377231659904
[2023-05-05 01:37:26,720-rk0-train.py#240] epoch 10 lr 0.00092377231659904
[2023-05-05 01:38:02,697-rk0-train.py#348] Epoch: [10][15/625] lr: 0.000924
	batch_time: 2.481098 (2.445046)	data_time: 0.001154 (0.015148)
	loss_fool: 0.175877 (0.191078)	loss_train_adv: 0.009311 (0.006453)
	cen_loss: 0.620018 (0.614557)	cls_loss: 0.061551 (0.053273)
	loc_loss: 0.226096 (0.188120)	total_loss: 1.359858 (1.232189)

[2023-05-05 01:38:02,698-rk0-log_helper.py#102] Progress: 5640 / 15625 [36%], Speed: 2.445 s/iter, ETA 0:06:46 (D:H:M)

[2023-05-05 01:38:51,519-rk0-train.py#348] Epoch: [10][35/625] lr: 0.000924
	batch_time: 2.438304 (2.443456)	data_time: 0.001117 (0.015529)
	loss_fool: 0.206815 (0.190693)	loss_train_adv: 0.003588 (0.006583)
	cen_loss: 0.617227 (0.614739)	cls_loss: 0.045912 (0.053382)
	loc_loss: 0.190778 (0.190431)	total_loss: 1.235474 (1.239413)

[2023-05-05 01:38:51,519-rk0-log_helper.py#102] Progress: 5660 / 15625 [36%], Speed: 2.443 s/iter, ETA 0:06:45 (D:H:M)

[2023-05-05 01:39:39,956-rk0-train.py#348] Epoch: [10][55/625] lr: 0.000924
	batch_time: 2.419038 (2.446856)	data_time: 0.001421 (0.015646)
	loss_fool: 0.190970 (0.190649)	loss_train_adv: 0.005370 (0.006242)
	cen_loss: 0.607605 (0.614473)	cls_loss: 0.031958 (0.052271)
	loc_loss: 0.176371 (0.189278)	total_loss: 1.168675 (1.234578)

[2023-05-05 01:39:39,956-rk0-log_helper.py#102] Progress: 5680 / 15625 [36%], Speed: 2.447 s/iter, ETA 0:06:45 (D:H:M)

[2023-05-05 01:40:28,315-rk0-train.py#348] Epoch: [10][75/625] lr: 0.000924
	batch_time: 2.480026 (2.445915)	data_time: 0.001318 (0.015663)
	loss_fool: 0.150226 (0.190640)	loss_train_adv: 0.011138 (0.006599)
	cen_loss: 0.611289 (0.614342)	cls_loss: 0.049055 (0.053082)
	loc_loss: 0.162624 (0.186613)	total_loss: 1.148216 (1.227262)

[2023-05-05 01:40:28,316-rk0-log_helper.py#102] Progress: 5700 / 15625 [36%], Speed: 2.446 s/iter, ETA 0:06:44 (D:H:M)

[2023-05-05 01:41:17,415-rk0-train.py#348] Epoch: [10][95/625] lr: 0.000924
	batch_time: 2.417518 (2.438488)	data_time: 0.001357 (0.015899)
	loss_fool: 0.199470 (0.190694)	loss_train_adv: 0.009633 (0.006782)
	cen_loss: 0.610355 (0.614109)	cls_loss: 0.039340 (0.053880)
	loc_loss: 0.186115 (0.185568)	total_loss: 1.208041 (1.224692)

[2023-05-05 01:41:17,416-rk0-log_helper.py#102] Progress: 5720 / 15625 [36%], Speed: 2.438 s/iter, ETA 0:06:42 (D:H:M)

[2023-05-05 01:42:05,928-rk0-train.py#348] Epoch: [10][115/625] lr: 0.000924
	batch_time: 2.415391 (2.427341)	data_time: 0.000722 (0.002788)
	loss_fool: 0.191732 (0.191187)	loss_train_adv: 0.007795 (0.006192)
	cen_loss: 0.609348 (0.613703)	cls_loss: 0.049157 (0.052977)
	loc_loss: 0.179469 (0.183865)	total_loss: 1.196913 (1.218276)

[2023-05-05 01:42:05,929-rk0-log_helper.py#102] Progress: 5740 / 15625 [36%], Speed: 2.427 s/iter, ETA 0:06:39 (D:H:M)

[2023-05-05 01:42:54,681-rk0-train.py#348] Epoch: [10][135/625] lr: 0.000924
	batch_time: 2.420367 (2.427123)	data_time: 0.000428 (0.002326)
	loss_fool: 0.211517 (0.191848)	loss_train_adv: 0.005619 (0.005854)
	cen_loss: 0.616495 (0.613545)	cls_loss: 0.042614 (0.053585)
	loc_loss: 0.177394 (0.184142)	total_loss: 1.191291 (1.219557)

[2023-05-05 01:42:54,682-rk0-log_helper.py#102] Progress: 5760 / 15625 [36%], Speed: 2.427 s/iter, ETA 0:06:39 (D:H:M)

[2023-05-05 01:43:43,100-rk0-train.py#348] Epoch: [10][155/625] lr: 0.000924
	batch_time: 2.418297 (2.427238)	data_time: 0.001330 (0.002449)
	loss_fool: 0.183569 (0.192277)	loss_train_adv: 0.002761 (0.005761)
	cen_loss: 0.610192 (0.613766)	cls_loss: 0.040338 (0.054986)
	loc_loss: 0.174713 (0.185262)	total_loss: 1.174669 (1.224537)

[2023-05-05 01:43:43,101-rk0-log_helper.py#102] Progress: 5780 / 15625 [36%], Speed: 2.427 s/iter, ETA 0:06:38 (D:H:M)

[2023-05-05 01:44:32,012-rk0-train.py#348] Epoch: [10][175/625] lr: 0.000924
	batch_time: 2.435336 (2.432704)	data_time: 0.001248 (0.002680)
	loss_fool: 0.170798 (0.192687)	loss_train_adv: 0.011392 (0.004983)
	cen_loss: 0.607620 (0.613683)	cls_loss: 0.080440 (0.052817)
	loc_loss: 0.205210 (0.185883)	total_loss: 1.303690 (1.224150)

[2023-05-05 01:44:32,012-rk0-log_helper.py#102] Progress: 5800 / 15625 [37%], Speed: 2.433 s/iter, ETA 0:06:38 (D:H:M)

[2023-05-05 01:45:22,232-rk0-train.py#348] Epoch: [10][195/625] lr: 0.000924
	batch_time: 2.386298 (2.443801)	data_time: 0.001195 (0.002429)
	loss_fool: 0.187610 (0.193974)	loss_train_adv: 0.009277 (0.004436)
	cen_loss: 0.614571 (0.613578)	cls_loss: 0.049212 (0.052921)
	loc_loss: 0.175397 (0.186439)	total_loss: 1.189974 (1.225815)

[2023-05-05 01:45:22,232-rk0-log_helper.py#102] Progress: 5820 / 15625 [37%], Speed: 2.444 s/iter, ETA 0:06:39 (D:H:M)

[2023-05-05 01:46:10,445-rk0-train.py#348] Epoch: [10][215/625] lr: 0.000924
	batch_time: 2.472003 (2.441522)	data_time: 0.000613 (0.002440)
	loss_fool: 0.204659 (0.193973)	loss_train_adv: 0.001116 (0.004307)
	cen_loss: 0.612479 (0.613437)	cls_loss: 0.040188 (0.052306)
	loc_loss: 0.202166 (0.187679)	total_loss: 1.259165 (1.228780)

[2023-05-05 01:46:10,446-rk0-log_helper.py#102] Progress: 5840 / 15625 [37%], Speed: 2.442 s/iter, ETA 0:06:38 (D:H:M)

[2023-05-05 01:46:58,776-rk0-train.py#348] Epoch: [10][235/625] lr: 0.000924
	batch_time: 2.381337 (2.436659)	data_time: 0.001299 (0.002644)
	loss_fool: 0.182748 (0.193734)	loss_train_adv: 0.003229 (0.004404)
	cen_loss: 0.615152 (0.613230)	cls_loss: 0.044025 (0.052856)
	loc_loss: 0.180044 (0.186525)	total_loss: 1.199308 (1.225659)

[2023-05-05 01:46:58,777-rk0-log_helper.py#102] Progress: 5860 / 15625 [37%], Speed: 2.437 s/iter, ETA 0:06:36 (D:H:M)

[2023-05-05 01:47:48,191-rk0-train.py#348] Epoch: [10][255/625] lr: 0.000924
	batch_time: 2.557559 (2.446166)	data_time: 0.012151 (0.003057)
	loss_fool: 0.214162 (0.193245)	loss_train_adv: 0.002327 (0.004550)
	cen_loss: 0.617047 (0.613238)	cls_loss: 0.047557 (0.052526)
	loc_loss: 0.199363 (0.184818)	total_loss: 1.262695 (1.220219)

[2023-05-05 01:47:48,192-rk0-log_helper.py#102] Progress: 5880 / 15625 [37%], Speed: 2.446 s/iter, ETA 0:06:37 (D:H:M)

[2023-05-05 01:48:36,723-rk0-train.py#348] Epoch: [10][275/625] lr: 0.000924
	batch_time: 2.430912 (2.442500)	data_time: 0.001381 (0.002956)
	loss_fool: 0.190938 (0.194213)	loss_train_adv: 0.002904 (0.004351)
	cen_loss: 0.621603 (0.613699)	cls_loss: 0.049507 (0.053960)
	loc_loss: 0.201064 (0.186131)	total_loss: 1.274302 (1.226053)

[2023-05-05 01:48:36,723-rk0-log_helper.py#102] Progress: 5900 / 15625 [37%], Speed: 2.443 s/iter, ETA 0:06:35 (D:H:M)

[2023-05-05 01:49:25,467-rk0-train.py#348] Epoch: [10][295/625] lr: 0.000924
	batch_time: 2.454423 (2.427588)	data_time: 0.001639 (0.003012)
	loss_fool: 0.182356 (0.192966)	loss_train_adv: 0.006034 (0.004592)
	cen_loss: 0.618503 (0.613637)	cls_loss: 0.047468 (0.051972)
	loc_loss: 0.208965 (0.185489)	total_loss: 1.292867 (1.222076)

[2023-05-05 01:49:25,468-rk0-log_helper.py#102] Progress: 5920 / 15625 [37%], Speed: 2.428 s/iter, ETA 0:06:32 (D:H:M)

[2023-05-05 01:50:14,660-rk0-train.py#348] Epoch: [10][315/625] lr: 0.000924
	batch_time: 2.587548 (2.437292)	data_time: 0.016044 (0.003015)
	loss_fool: 0.167243 (0.192948)	loss_train_adv: 0.005638 (0.004923)
	cen_loss: 0.612865 (0.613980)	cls_loss: 0.096039 (0.054713)
	loc_loss: 0.217404 (0.185525)	total_loss: 1.361115 (1.225267)

[2023-05-05 01:50:14,661-rk0-log_helper.py#102] Progress: 5940 / 15625 [38%], Speed: 2.437 s/iter, ETA 0:06:33 (D:H:M)

[2023-05-05 01:51:03,412-rk0-train.py#348] Epoch: [10][335/625] lr: 0.000924
	batch_time: 2.389298 (2.442197)	data_time: 0.003148 (0.002919)
	loss_fool: 0.169426 (0.192723)	loss_train_adv: 0.010424 (0.005157)
	cen_loss: 0.617447 (0.614020)	cls_loss: 0.063527 (0.052763)
	loc_loss: 0.179137 (0.184727)	total_loss: 1.218384 (1.220963)

[2023-05-05 01:51:03,412-rk0-log_helper.py#102] Progress: 5960 / 15625 [38%], Speed: 2.442 s/iter, ETA 0:06:33 (D:H:M)

[2023-05-05 01:51:53,235-rk0-train.py#348] Epoch: [10][355/625] lr: 0.000924
	batch_time: 2.452117 (2.446396)	data_time: 0.001291 (0.002344)
	loss_fool: 0.207387 (0.192737)	loss_train_adv: 0.003786 (0.005409)
	cen_loss: 0.616360 (0.614073)	cls_loss: 0.043017 (0.053240)
	loc_loss: 0.169313 (0.185130)	total_loss: 1.167315 (1.222704)

[2023-05-05 01:51:53,236-rk0-log_helper.py#102] Progress: 5980 / 15625 [38%], Speed: 2.446 s/iter, ETA 0:06:33 (D:H:M)

[2023-05-05 01:52:43,071-rk0-train.py#348] Epoch: [10][375/625] lr: 0.000924
	batch_time: 2.625952 (2.459703)	data_time: 0.001255 (0.002210)
	loss_fool: 0.196772 (0.192280)	loss_train_adv: 0.007834 (0.005470)
	cen_loss: 0.604168 (0.613860)	cls_loss: 0.045159 (0.053121)
	loc_loss: 0.160389 (0.184397)	total_loss: 1.130493 (1.220173)

[2023-05-05 01:52:43,072-rk0-log_helper.py#102] Progress: 6000 / 15625 [38%], Speed: 2.460 s/iter, ETA 0:06:34 (D:H:M)

[2023-05-05 01:53:32,699-rk0-train.py#348] Epoch: [10][395/625] lr: 0.000924
	batch_time: 2.435029 (2.468164)	data_time: 0.001183 (0.002058)
	loss_fool: 0.179549 (0.191962)	loss_train_adv: 0.005546 (0.005480)
	cen_loss: 0.614735 (0.613960)	cls_loss: 0.049754 (0.053241)
	loc_loss: 0.194926 (0.185512)	total_loss: 1.249266 (1.223736)

[2023-05-05 01:53:32,700-rk0-log_helper.py#102] Progress: 6020 / 15625 [38%], Speed: 2.468 s/iter, ETA 0:06:35 (D:H:M)

[2023-05-05 01:54:21,460-rk0-train.py#348] Epoch: [10][415/625] lr: 0.000924
	batch_time: 2.518157 (2.463435)	data_time: 0.001177 (0.001949)
	loss_fool: 0.206183 (0.192790)	loss_train_adv: 0.002793 (0.005601)
	cen_loss: 0.605635 (0.613731)	cls_loss: 0.053606 (0.050808)
	loc_loss: 0.179435 (0.184726)	total_loss: 1.197547 (1.218717)

[2023-05-05 01:54:21,460-rk0-log_helper.py#102] Progress: 6040 / 15625 [38%], Speed: 2.463 s/iter, ETA 0:06:33 (D:H:M)

[2023-05-05 01:55:10,371-rk0-train.py#348] Epoch: [10][435/625] lr: 0.000924
	batch_time: 2.431938 (2.464922)	data_time: 0.005226 (0.001888)
	loss_fool: 0.183755 (0.192908)	loss_train_adv: 0.008586 (0.005367)
	cen_loss: 0.617057 (0.613361)	cls_loss: 0.060137 (0.052736)
	loc_loss: 0.202356 (0.185039)	total_loss: 1.284261 (1.221215)

[2023-05-05 01:55:10,372-rk0-log_helper.py#102] Progress: 6060 / 15625 [38%], Speed: 2.465 s/iter, ETA 0:06:32 (D:H:M)

[2023-05-05 01:55:58,633-rk0-train.py#348] Epoch: [10][455/625] lr: 0.000924
	batch_time: 2.411515 (2.449820)	data_time: 0.001173 (0.001826)
	loss_fool: 0.173078 (0.193021)	loss_train_adv: 0.008419 (0.004783)
	cen_loss: 0.599794 (0.613487)	cls_loss: 0.030906 (0.050561)
	loc_loss: 0.149416 (0.183785)	total_loss: 1.078948 (1.215404)

[2023-05-05 01:55:58,634-rk0-log_helper.py#102] Progress: 6080 / 15625 [38%], Speed: 2.450 s/iter, ETA 0:06:29 (D:H:M)

[2023-05-05 01:56:47,273-rk0-train.py#348] Epoch: [10][475/625] lr: 0.000924
	batch_time: 2.387724 (2.437511)	data_time: 0.001160 (0.001809)
	loss_fool: 0.205904 (0.193169)	loss_train_adv: 0.001087 (0.004537)
	cen_loss: 0.609246 (0.613251)	cls_loss: 0.049276 (0.049748)
	loc_loss: 0.163750 (0.182973)	total_loss: 1.149772 (1.211918)

[2023-05-05 01:56:47,274-rk0-log_helper.py#102] Progress: 6100 / 15625 [39%], Speed: 2.438 s/iter, ETA 0:06:26 (D:H:M)

[2023-05-05 01:57:36,225-rk0-train.py#348] Epoch: [10][495/625] lr: 0.000924
	batch_time: 2.468341 (2.430720)	data_time: 0.001332 (0.001781)
	loss_fool: 0.187249 (0.194309)	loss_train_adv: 0.002539 (0.004302)
	cen_loss: 0.608352 (0.613434)	cls_loss: 0.042799 (0.050469)
	loc_loss: 0.184867 (0.182895)	total_loss: 1.205752 (1.212587)

[2023-05-05 01:57:36,226-rk0-log_helper.py#102] Progress: 6120 / 15625 [39%], Speed: 2.431 s/iter, ETA 0:06:25 (D:H:M)

[2023-05-05 01:58:25,809-rk0-train.py#348] Epoch: [10][515/625] lr: 0.000924
	batch_time: 2.353627 (2.439332)	data_time: 0.001366 (0.001787)
	loss_fool: 0.194780 (0.193286)	loss_train_adv: 0.002562 (0.004177)
	cen_loss: 0.613079 (0.613559)	cls_loss: 0.051585 (0.051597)
	loc_loss: 0.195809 (0.183029)	total_loss: 1.252091 (1.214243)

[2023-05-05 01:58:25,810-rk0-log_helper.py#102] Progress: 6140 / 15625 [39%], Speed: 2.439 s/iter, ETA 0:06:25 (D:H:M)

[2023-05-05 01:59:14,226-rk0-train.py#348] Epoch: [10][535/625] lr: 0.000924
	batch_time: 2.419560 (2.433946)	data_time: 0.001421 (0.002029)
	loss_fool: 0.199774 (0.193062)	loss_train_adv: 0.005069 (0.004219)
	cen_loss: 0.606447 (0.614176)	cls_loss: 0.044212 (0.049955)
	loc_loss: 0.164930 (0.182746)	total_loss: 1.145450 (1.212370)

[2023-05-05 01:59:14,227-rk0-log_helper.py#102] Progress: 6160 / 15625 [39%], Speed: 2.434 s/iter, ETA 0:06:23 (D:H:M)

[2023-05-05 02:00:02,653-rk0-train.py#348] Epoch: [10][555/625] lr: 0.000924
	batch_time: 2.428828 (2.435333)	data_time: 0.001374 (0.002023)
	loss_fool: 0.171291 (0.193387)	loss_train_adv: 0.004938 (0.004716)
	cen_loss: 0.604658 (0.613880)	cls_loss: 0.035171 (0.049706)
	loc_loss: 0.127796 (0.181406)	total_loss: 1.023217 (1.207805)

[2023-05-05 02:00:02,654-rk0-log_helper.py#102] Progress: 6180 / 15625 [39%], Speed: 2.435 s/iter, ETA 0:06:23 (D:H:M)

[2023-05-05 02:00:51,509-rk0-train.py#348] Epoch: [10][575/625] lr: 0.000924
	batch_time: 2.516155 (2.437555)	data_time: 0.001291 (0.001886)
	loss_fool: 0.214346 (0.193035)	loss_train_adv: 0.006774 (0.005069)
	cen_loss: 0.612799 (0.613764)	cls_loss: 0.044112 (0.050275)
	loc_loss: 0.200107 (0.182401)	total_loss: 1.257232 (1.211241)

[2023-05-05 02:00:51,510-rk0-log_helper.py#102] Progress: 6200 / 15625 [39%], Speed: 2.438 s/iter, ETA 0:06:22 (D:H:M)

[2023-05-05 02:01:40,763-rk0-train.py#348] Epoch: [10][595/625] lr: 0.000924
	batch_time: 2.489409 (2.441052)	data_time: 0.001354 (0.002095)
	loss_fool: 0.184342 (0.192995)	loss_train_adv: 0.002046 (0.004993)
	cen_loss: 0.610689 (0.613412)	cls_loss: 0.045253 (0.049593)
	loc_loss: 0.167266 (0.181482)	total_loss: 1.157741 (1.207451)

[2023-05-05 02:01:40,763-rk0-log_helper.py#102] Progress: 6220 / 15625 [39%], Speed: 2.441 s/iter, ETA 0:06:22 (D:H:M)

[2023-05-05 02:02:29,729-rk0-train.py#348] Epoch: [10][615/625] lr: 0.000924
	batch_time: 2.441063 (2.434708)	data_time: 0.001275 (0.001988)
	loss_fool: 0.188918 (0.193417)	loss_train_adv: 0.001372 (0.004745)
	cen_loss: 0.617527 (0.613270)	cls_loss: 0.057703 (0.049160)
	loc_loss: 0.208010 (0.181669)	total_loss: 1.299259 (1.207437)

[2023-05-05 02:02:29,730-rk0-log_helper.py#102] Progress: 6240 / 15625 [39%], Speed: 2.435 s/iter, ETA 0:06:20 (D:H:M)

[2023-05-05 02:02:58,031-rk0-train.py#235] epoch: 11
[2023-05-05 02:02:58,031-rk0-train.py#240] epoch 11 lr 8.18339217175278e-05
[2023-05-05 02:02:58,031-rk0-train.py#240] epoch 11 lr 0.0008183392171752779
[2023-05-05 02:02:58,032-rk0-train.py#240] epoch 11 lr 0.0027277973905842595
[2023-05-05 02:02:58,033-rk0-train.py#240] epoch 11 lr 0.0008183392171752779
[2023-05-05 02:02:58,033-rk0-train.py#240] epoch 11 lr 0.0008183392171752779
[2023-05-05 02:03:22,296-rk0-train.py#348] Epoch: [11][10/625] lr: 0.000818
	batch_time: 2.436683 (2.476487)	data_time: 0.001415 (0.022727)
	loss_fool: 0.197116 (0.194042)	loss_train_adv: 0.013759 (0.004533)
	cen_loss: 0.610503 (0.613192)	cls_loss: 0.059541 (0.049502)
	loc_loss: 0.228713 (0.182666)	total_loss: 1.356182 (1.210692)

[2023-05-05 02:03:22,297-rk0-log_helper.py#102] Progress: 6260 / 15625 [40%], Speed: 2.476 s/iter, ETA 0:06:26 (D:H:M)

[2023-05-05 02:04:12,321-rk0-train.py#348] Epoch: [11][30/625] lr: 0.000818
	batch_time: 2.456635 (2.492759)	data_time: 0.001198 (0.022829)
	loss_fool: 0.163846 (0.193558)	loss_train_adv: 0.010301 (0.004387)
	cen_loss: 0.615847 (0.613238)	cls_loss: 0.050523 (0.049827)
	loc_loss: 0.177176 (0.184672)	total_loss: 1.197897 (1.217082)

[2023-05-05 02:04:12,322-rk0-log_helper.py#102] Progress: 6280 / 15625 [40%], Speed: 2.493 s/iter, ETA 0:06:28 (D:H:M)

[2023-05-05 02:05:00,928-rk0-train.py#348] Epoch: [11][50/625] lr: 0.000818
	batch_time: 2.364601 (2.490382)	data_time: 0.001211 (0.022892)
	loss_fool: 0.177353 (0.193942)	loss_train_adv: 0.004582 (0.004350)
	cen_loss: 0.605781 (0.613104)	cls_loss: 0.049786 (0.049830)
	loc_loss: 0.197112 (0.184639)	total_loss: 1.246904 (1.216850)

[2023-05-05 02:05:00,929-rk0-log_helper.py#102] Progress: 6300 / 15625 [40%], Speed: 2.490 s/iter, ETA 0:06:27 (D:H:M)

[2023-05-05 02:05:49,002-rk0-train.py#348] Epoch: [11][70/625] lr: 0.000818
	batch_time: 2.449153 (2.478471)	data_time: 0.001233 (0.022622)
	loss_fool: 0.206724 (0.193858)	loss_train_adv: 0.001669 (0.004200)
	cen_loss: 0.618024 (0.613234)	cls_loss: 0.034498 (0.050215)
	loc_loss: 0.166764 (0.184162)	total_loss: 1.152814 (1.215934)

[2023-05-05 02:05:49,003-rk0-log_helper.py#102] Progress: 6320 / 15625 [40%], Speed: 2.478 s/iter, ETA 0:06:24 (D:H:M)

[2023-05-05 02:06:38,611-rk0-train.py#348] Epoch: [11][90/625] lr: 0.000818
	batch_time: 2.424414 (2.484958)	data_time: 0.001229 (0.022551)
	loss_fool: 0.181297 (0.193604)	loss_train_adv: 0.007536 (0.004414)
	cen_loss: 0.613679 (0.613409)	cls_loss: 0.043239 (0.050880)
	loc_loss: 0.197835 (0.185305)	total_loss: 1.250422 (1.220204)

[2023-05-05 02:06:38,611-rk0-log_helper.py#102] Progress: 6340 / 15625 [40%], Speed: 2.485 s/iter, ETA 0:06:24 (D:H:M)

[2023-05-05 02:07:26,168-rk0-train.py#348] Epoch: [11][110/625] lr: 0.000818
	batch_time: 2.516981 (2.435034)	data_time: 0.000963 (0.001590)
	loss_fool: 0.206311 (0.193755)	loss_train_adv: 0.000494 (0.004451)
	cen_loss: 0.610078 (0.613228)	cls_loss: 0.068781 (0.051038)
	loc_loss: 0.180348 (0.184059)	total_loss: 1.219902 (1.216443)

[2023-05-05 02:07:26,169-rk0-log_helper.py#102] Progress: 6360 / 15625 [40%], Speed: 2.435 s/iter, ETA 0:06:16 (D:H:M)

[2023-05-05 02:08:13,658-rk0-train.py#348] Epoch: [11][130/625] lr: 0.000818
	batch_time: 2.287915 (2.409786)	data_time: 0.001453 (0.001610)
	loss_fool: 0.168113 (0.193935)	loss_train_adv: 0.015327 (0.004068)
	cen_loss: 0.605094 (0.613075)	cls_loss: 0.046835 (0.050990)
	loc_loss: 0.223179 (0.183174)	total_loss: 1.321467 (1.213587)

[2023-05-05 02:08:13,659-rk0-log_helper.py#102] Progress: 6380 / 15625 [40%], Speed: 2.410 s/iter, ETA 0:06:11 (D:H:M)

[2023-05-05 02:09:01,083-rk0-train.py#348] Epoch: [11][150/625] lr: 0.000818
	batch_time: 2.310356 (2.398213)	data_time: 0.001429 (0.001758)
	loss_fool: 0.181240 (0.193732)	loss_train_adv: 0.003589 (0.004189)
	cen_loss: 0.609678 (0.613293)	cls_loss: 0.032146 (0.049327)
	loc_loss: 0.144180 (0.182595)	total_loss: 1.074365 (1.210406)

[2023-05-05 02:09:01,084-rk0-log_helper.py#102] Progress: 6400 / 15625 [40%], Speed: 2.398 s/iter, ETA 0:06:08 (D:H:M)

[2023-05-05 02:09:48,430-rk0-train.py#348] Epoch: [11][170/625] lr: 0.000818
	batch_time: 2.361894 (2.391298)	data_time: 0.020704 (0.002083)
	loss_fool: 0.176169 (0.193885)	loss_train_adv: 0.009703 (0.004571)
	cen_loss: 0.618987 (0.613277)	cls_loss: 0.064690 (0.050013)
	loc_loss: 0.202678 (0.183161)	total_loss: 1.291710 (1.212774)

[2023-05-05 02:09:48,430-rk0-log_helper.py#102] Progress: 6420 / 15625 [41%], Speed: 2.391 s/iter, ETA 0:06:06 (D:H:M)

[2023-05-05 02:10:36,381-rk0-train.py#348] Epoch: [11][190/625] lr: 0.000818
	batch_time: 2.371805 (2.374875)	data_time: 0.001123 (0.002070)
	loss_fool: 0.204126 (0.194024)	loss_train_adv: 0.002902 (0.004255)
	cen_loss: 0.617885 (0.613182)	cls_loss: 0.060179 (0.048982)
	loc_loss: 0.200563 (0.180799)	total_loss: 1.279752 (1.204561)

[2023-05-05 02:10:36,382-rk0-log_helper.py#102] Progress: 6440 / 15625 [41%], Speed: 2.375 s/iter, ETA 0:06:03 (D:H:M)

[2023-05-05 02:11:24,212-rk0-train.py#348] Epoch: [11][210/625] lr: 0.000818
	batch_time: 2.384918 (2.377686)	data_time: 0.001181 (0.002098)
	loss_fool: 0.187510 (0.194095)	loss_train_adv: 0.001158 (0.004218)
	cen_loss: 0.615068 (0.613032)	cls_loss: 0.050802 (0.049652)
	loc_loss: 0.194966 (0.181917)	total_loss: 1.250768 (1.208436)

[2023-05-05 02:11:24,212-rk0-log_helper.py#102] Progress: 6460 / 15625 [41%], Speed: 2.378 s/iter, ETA 0:06:03 (D:H:M)

[2023-05-05 02:12:11,943-rk0-train.py#348] Epoch: [11][230/625] lr: 0.000818
	batch_time: 2.377506 (2.379786)	data_time: 0.001245 (0.001963)
	loss_fool: 0.201659 (0.194229)	loss_train_adv: 0.006497 (0.004407)
	cen_loss: 0.614960 (0.613395)	cls_loss: 0.039625 (0.050928)
	loc_loss: 0.171682 (0.182225)	total_loss: 1.169632 (1.210998)

[2023-05-05 02:12:11,944-rk0-log_helper.py#102] Progress: 6480 / 15625 [41%], Speed: 2.380 s/iter, ETA 0:06:02 (D:H:M)

[2023-05-05 02:12:59,791-rk0-train.py#348] Epoch: [11][250/625] lr: 0.000818
	batch_time: 2.397629 (2.383897)	data_time: 0.001132 (0.001737)
	loss_fool: 0.181402 (0.194417)	loss_train_adv: 0.006332 (0.004191)
	cen_loss: 0.612972 (0.613437)	cls_loss: 0.048605 (0.053231)
	loc_loss: 0.189861 (0.180950)	total_loss: 1.231161 (1.209518)

[2023-05-05 02:12:59,792-rk0-log_helper.py#102] Progress: 6500 / 15625 [41%], Speed: 2.384 s/iter, ETA 0:06:02 (D:H:M)

[2023-05-05 02:13:47,289-rk0-train.py#348] Epoch: [11][270/625] lr: 0.000818
	batch_time: 2.458097 (2.385526)	data_time: 0.001157 (0.001374)
	loss_fool: 0.194407 (0.194030)	loss_train_adv: 0.003662 (0.003774)
	cen_loss: 0.609349 (0.613673)	cls_loss: 0.040539 (0.052452)
	loc_loss: 0.159089 (0.180797)	total_loss: 1.127156 (1.208516)

[2023-05-05 02:13:47,289-rk0-log_helper.py#102] Progress: 6520 / 15625 [41%], Speed: 2.386 s/iter, ETA 0:06:02 (D:H:M)

[2023-05-05 02:14:35,005-rk0-train.py#348] Epoch: [11][290/625] lr: 0.000818
	batch_time: 2.383706 (2.383498)	data_time: 0.001261 (0.001436)
	loss_fool: 0.197596 (0.194734)	loss_train_adv: 0.001435 (0.003960)
	cen_loss: 0.616328 (0.614182)	cls_loss: 0.038194 (0.053416)
	loc_loss: 0.159583 (0.181620)	total_loss: 1.133271 (1.212459)

[2023-05-05 02:14:35,006-rk0-log_helper.py#102] Progress: 6540 / 15625 [41%], Speed: 2.383 s/iter, ETA 0:06:00 (D:H:M)

[2023-05-05 02:15:23,663-rk0-train.py#348] Epoch: [11][310/625] lr: 0.000818
	batch_time: 2.441992 (2.391811)	data_time: 0.001120 (0.001357)
	loss_fool: 0.199877 (0.194095)	loss_train_adv: 0.000202 (0.003905)
	cen_loss: 0.624751 (0.614653)	cls_loss: 0.043369 (0.052596)
	loc_loss: 0.183841 (0.181456)	total_loss: 1.219645 (1.211618)

[2023-05-05 02:15:23,664-rk0-log_helper.py#102] Progress: 6560 / 15625 [41%], Speed: 2.392 s/iter, ETA 0:06:01 (D:H:M)

[2023-05-05 02:16:11,612-rk0-train.py#348] Epoch: [11][330/625] lr: 0.000818
	batch_time: 2.368026 (2.394006)	data_time: 0.001387 (0.001347)
	loss_fool: 0.188255 (0.194466)	loss_train_adv: 0.006198 (0.003885)
	cen_loss: 0.613672 (0.614630)	cls_loss: 0.049311 (0.052885)
	loc_loss: 0.173121 (0.182940)	total_loss: 1.182345 (1.216336)

[2023-05-05 02:16:11,613-rk0-log_helper.py#102] Progress: 6580 / 15625 [42%], Speed: 2.394 s/iter, ETA 0:06:00 (D:H:M)

[2023-05-05 02:16:59,132-rk0-train.py#348] Epoch: [11][350/625] lr: 0.000818
	batch_time: 2.359128 (2.390804)	data_time: 0.001191 (0.001781)
	loss_fool: 0.198016 (0.194374)	loss_train_adv: 0.006999 (0.003722)
	cen_loss: 0.604154 (0.614508)	cls_loss: 0.048443 (0.052387)
	loc_loss: 0.175542 (0.184168)	total_loss: 1.179224 (1.219400)

[2023-05-05 02:16:59,133-rk0-log_helper.py#102] Progress: 6600 / 15625 [42%], Speed: 2.391 s/iter, ETA 0:05:59 (D:H:M)

[2023-05-05 02:17:46,326-rk0-train.py#348] Epoch: [11][370/625] lr: 0.000818
	batch_time: 2.381378 (2.387736)	data_time: 0.001532 (0.001955)
	loss_fool: 0.171970 (0.194978)	loss_train_adv: 0.008270 (0.003731)
	cen_loss: 0.603534 (0.613815)	cls_loss: 0.042184 (0.052689)
	loc_loss: 0.175461 (0.183554)	total_loss: 1.172101 (1.217166)

[2023-05-05 02:17:46,327-rk0-log_helper.py#102] Progress: 6620 / 15625 [42%], Speed: 2.388 s/iter, ETA 0:05:58 (D:H:M)

[2023-05-05 02:18:34,311-rk0-train.py#348] Epoch: [11][390/625] lr: 0.000818
	batch_time: 2.425467 (2.390258)	data_time: 0.001445 (0.001904)
	loss_fool: 0.206168 (0.194310)	loss_train_adv: 0.001573 (0.003911)
	cen_loss: 0.611594 (0.613469)	cls_loss: 0.065185 (0.052350)
	loc_loss: 0.199316 (0.183981)	total_loss: 1.274727 (1.217762)

[2023-05-05 02:18:34,312-rk0-log_helper.py#102] Progress: 6640 / 15625 [42%], Speed: 2.390 s/iter, ETA 0:05:57 (D:H:M)

[2023-05-05 02:19:23,498-rk0-train.py#348] Epoch: [11][410/625] lr: 0.000818
	batch_time: 2.445520 (2.395247)	data_time: 0.001454 (0.002202)
	loss_fool: 0.177549 (0.194296)	loss_train_adv: 0.004013 (0.004040)
	cen_loss: 0.617524 (0.613350)	cls_loss: 0.059474 (0.051753)
	loc_loss: 0.202892 (0.182416)	total_loss: 1.285674 (1.212350)

[2023-05-05 02:19:23,499-rk0-log_helper.py#102] Progress: 6660 / 15625 [42%], Speed: 2.395 s/iter, ETA 0:05:57 (D:H:M)

[2023-05-05 02:20:12,626-rk0-train.py#348] Epoch: [11][430/625] lr: 0.000818
	batch_time: 2.364856 (2.406474)	data_time: 0.001144 (0.002306)
	loss_fool: 0.175030 (0.193921)	loss_train_adv: 0.010043 (0.004275)
	cen_loss: 0.614040 (0.613093)	cls_loss: 0.051771 (0.051498)
	loc_loss: 0.165659 (0.180667)	total_loss: 1.162788 (1.206591)

[2023-05-05 02:20:12,627-rk0-log_helper.py#102] Progress: 6680 / 15625 [42%], Speed: 2.406 s/iter, ETA 0:05:58 (D:H:M)

[2023-05-05 02:21:00,890-rk0-train.py#348] Epoch: [11][450/625] lr: 0.000818
	batch_time: 2.456114 (2.413779)	data_time: 0.001168 (0.002097)
	loss_fool: 0.186174 (0.194369)	loss_train_adv: 0.003466 (0.004427)
	cen_loss: 0.608448 (0.612972)	cls_loss: 0.053464 (0.050292)
	loc_loss: 0.189877 (0.180759)	total_loss: 1.231544 (1.205540)

[2023-05-05 02:21:00,891-rk0-log_helper.py#102] Progress: 6700 / 15625 [42%], Speed: 2.414 s/iter, ETA 0:05:59 (D:H:M)

[2023-05-05 02:21:50,482-rk0-train.py#348] Epoch: [11][470/625] lr: 0.000818
	batch_time: 2.450260 (2.437832)	data_time: 0.001364 (0.002323)
	loss_fool: 0.195025 (0.193949)	loss_train_adv: 0.005127 (0.004522)
	cen_loss: 0.619462 (0.613831)	cls_loss: 0.066033 (0.050688)
	loc_loss: 0.178885 (0.183521)	total_loss: 1.222150 (1.215083)

[2023-05-05 02:21:50,482-rk0-log_helper.py#102] Progress: 6720 / 15625 [43%], Speed: 2.438 s/iter, ETA 0:06:01 (D:H:M)

[2023-05-05 02:22:38,448-rk0-train.py#348] Epoch: [11][490/625] lr: 0.000818
	batch_time: 2.307127 (2.437749)	data_time: 0.001324 (0.002267)
	loss_fool: 0.196298 (0.194234)	loss_train_adv: 0.002288 (0.004364)
	cen_loss: 0.611831 (0.613757)	cls_loss: 0.045342 (0.050333)
	loc_loss: 0.184374 (0.182852)	total_loss: 1.210295 (1.212647)

[2023-05-05 02:22:38,448-rk0-log_helper.py#102] Progress: 6740 / 15625 [43%], Speed: 2.438 s/iter, ETA 0:06:00 (D:H:M)

[2023-05-05 02:23:27,062-rk0-train.py#348] Epoch: [11][510/625] lr: 0.000818
	batch_time: 2.538482 (2.431767)	data_time: 0.001483 (0.001935)
	loss_fool: 0.187951 (0.194437)	loss_train_adv: 0.003908 (0.004230)
	cen_loss: 0.606615 (0.613679)	cls_loss: 0.041843 (0.050170)
	loc_loss: 0.171503 (0.183631)	total_loss: 1.162968 (1.214743)

[2023-05-05 02:23:27,063-rk0-log_helper.py#102] Progress: 6760 / 15625 [43%], Speed: 2.432 s/iter, ETA 0:05:59 (D:H:M)

[2023-05-05 02:24:17,150-rk0-train.py#348] Epoch: [11][530/625] lr: 0.000818
	batch_time: 2.329785 (2.442171)	data_time: 0.001193 (0.001966)
	loss_fool: 0.198810 (0.195041)	loss_train_adv: 0.000285 (0.003783)
	cen_loss: 0.613343 (0.614095)	cls_loss: 0.038650 (0.048967)
	loc_loss: 0.161583 (0.183680)	total_loss: 1.136741 (1.214101)

[2023-05-05 02:24:17,151-rk0-log_helper.py#102] Progress: 6780 / 15625 [43%], Speed: 2.442 s/iter, ETA 0:06:00 (D:H:M)

[2023-05-05 02:25:09,337-rk0-train.py#348] Epoch: [11][550/625] lr: 0.000818
	batch_time: 2.521875 (2.481235)	data_time: 0.001363 (0.001992)
	loss_fool: 0.198428 (0.195166)	loss_train_adv: 0.000411 (0.003594)
	cen_loss: 0.611899 (0.614365)	cls_loss: 0.042731 (0.049276)
	loc_loss: 0.171381 (0.183884)	total_loss: 1.168772 (1.215295)

[2023-05-05 02:25:09,338-rk0-log_helper.py#102] Progress: 6800 / 15625 [43%], Speed: 2.481 s/iter, ETA 0:06:04 (D:H:M)

[2023-05-05 02:25:56,567-rk0-train.py#348] Epoch: [11][570/625] lr: 0.000818
	batch_time: 2.338643 (2.457444)	data_time: 0.005105 (0.001679)
	loss_fool: 0.163859 (0.194730)	loss_train_adv: 0.004189 (0.003720)
	cen_loss: 0.612879 (0.614061)	cls_loss: 0.039061 (0.049290)
	loc_loss: 0.215632 (0.182035)	total_loss: 1.298836 (1.209456)

[2023-05-05 02:25:56,567-rk0-log_helper.py#102] Progress: 6820 / 15625 [43%], Speed: 2.457 s/iter, ETA 0:06:00 (D:H:M)

[2023-05-05 02:26:43,914-rk0-train.py#348] Epoch: [11][590/625] lr: 0.000818
	batch_time: 2.424308 (2.451207)	data_time: 0.001180 (0.001713)
	loss_fool: 0.201568 (0.194521)	loss_train_adv: 0.003984 (0.003591)
	cen_loss: 0.607380 (0.614014)	cls_loss: 0.042761 (0.049636)
	loc_loss: 0.177669 (0.181190)	total_loss: 1.183149 (1.207219)

[2023-05-05 02:26:43,914-rk0-log_helper.py#102] Progress: 6840 / 15625 [43%], Speed: 2.451 s/iter, ETA 0:05:58 (D:H:M)

[2023-05-05 02:27:31,452-rk0-train.py#348] Epoch: [11][610/625] lr: 0.000818
	batch_time: 2.336361 (2.440996)	data_time: 0.001176 (0.001707)
	loss_fool: 0.190613 (0.194385)	loss_train_adv: 0.002911 (0.003757)
	cen_loss: 0.614028 (0.613885)	cls_loss: 0.096933 (0.051250)
	loc_loss: 0.194944 (0.181294)	total_loss: 1.295793 (1.209018)

[2023-05-05 02:27:31,452-rk0-log_helper.py#102] Progress: 6860 / 15625 [43%], Speed: 2.441 s/iter, ETA 0:05:56 (D:H:M)

[2023-05-05 02:28:08,368-rk0-train.py#235] epoch: 12
[2023-05-05 02:28:08,368-rk0-train.py#240] epoch 12 lr 7.249395357857628e-05
[2023-05-05 02:28:08,368-rk0-train.py#240] epoch 12 lr 0.0007249395357857627
[2023-05-05 02:28:08,369-rk0-train.py#240] epoch 12 lr 0.002416465119285876
[2023-05-05 02:28:08,370-rk0-train.py#240] epoch 12 lr 0.0007249395357857627
[2023-05-05 02:28:08,370-rk0-train.py#240] epoch 12 lr 0.0007249395357857627
[2023-05-05 02:28:20,352-rk0-train.py#348] Epoch: [12][5/625] lr: 0.000725
	batch_time: 2.442979 (2.429067)	data_time: 0.001334 (0.015565)
	loss_fool: 0.185606 (0.194025)	loss_train_adv: 0.008618 (0.004059)
	cen_loss: 0.612710 (0.613342)	cls_loss: 0.065376 (0.053262)
	loc_loss: 0.172865 (0.180717)	total_loss: 1.196682 (1.208756)

[2023-05-05 02:28:20,352-rk0-log_helper.py#102] Progress: 6880 / 15625 [44%], Speed: 2.429 s/iter, ETA 0:05:54 (D:H:M)

[2023-05-05 02:29:07,546-rk0-train.py#348] Epoch: [12][25/625] lr: 0.000725
	batch_time: 2.284052 (2.379188)	data_time: 0.001152 (0.015325)
	loss_fool: 0.208657 (0.193306)	loss_train_adv: 0.003037 (0.004267)
	cen_loss: 0.622690 (0.613443)	cls_loss: 0.071828 (0.055051)
	loc_loss: 0.196135 (0.180382)	total_loss: 1.282921 (1.209639)

[2023-05-05 02:29:07,546-rk0-log_helper.py#102] Progress: 6900 / 15625 [44%], Speed: 2.379 s/iter, ETA 0:05:45 (D:H:M)

[2023-05-05 02:29:56,606-rk0-train.py#348] Epoch: [12][45/625] lr: 0.000725
	batch_time: 2.305403 (2.397580)	data_time: 0.001148 (0.015305)
	loss_fool: 0.183151 (0.194407)	loss_train_adv: 0.004256 (0.003990)
	cen_loss: 0.617880 (0.613286)	cls_loss: 0.047817 (0.053937)
	loc_loss: 0.188232 (0.179445)	total_loss: 1.230393 (1.205558)

[2023-05-05 02:29:56,607-rk0-log_helper.py#102] Progress: 6920 / 15625 [44%], Speed: 2.398 s/iter, ETA 0:05:47 (D:H:M)

[2023-05-05 02:30:44,449-rk0-train.py#348] Epoch: [12][65/625] lr: 0.000725
	batch_time: 2.400523 (2.402622)	data_time: 0.001420 (0.015378)
	loss_fool: 0.189901 (0.194506)	loss_train_adv: 0.003612 (0.003895)
	cen_loss: 0.614088 (0.613291)	cls_loss: 0.064287 (0.053419)
	loc_loss: 0.202334 (0.179458)	total_loss: 1.285379 (1.205086)

[2023-05-05 02:30:44,450-rk0-log_helper.py#102] Progress: 6940 / 15625 [44%], Speed: 2.403 s/iter, ETA 0:05:47 (D:H:M)

[2023-05-05 02:31:33,959-rk0-train.py#348] Epoch: [12][85/625] lr: 0.000725
	batch_time: 2.371902 (2.422202)	data_time: 0.001300 (0.015595)
	loss_fool: 0.204171 (0.195359)	loss_train_adv: 0.004354 (0.003594)
	cen_loss: 0.617764 (0.613444)	cls_loss: 0.044133 (0.052646)
	loc_loss: 0.190996 (0.178698)	total_loss: 1.234886 (1.202184)

[2023-05-05 02:31:33,960-rk0-log_helper.py#102] Progress: 6960 / 15625 [44%], Speed: 2.422 s/iter, ETA 0:05:49 (D:H:M)

[2023-05-05 02:32:22,876-rk0-train.py#348] Epoch: [12][105/625] lr: 0.000725
	batch_time: 2.372122 (2.422392)	data_time: 0.001187 (0.001727)
	loss_fool: 0.187370 (0.194872)	loss_train_adv: 0.007799 (0.003714)
	cen_loss: 0.613949 (0.614065)	cls_loss: 0.036498 (0.051713)
	loc_loss: 0.168116 (0.179820)	total_loss: 1.154795 (1.205239)

[2023-05-05 02:32:22,876-rk0-log_helper.py#102] Progress: 6980 / 15625 [44%], Speed: 2.422 s/iter, ETA 0:05:49 (D:H:M)

[2023-05-05 02:33:10,218-rk0-train.py#348] Epoch: [12][125/625] lr: 0.000725
	batch_time: 2.322235 (2.423957)	data_time: 0.001128 (0.001973)
	loss_fool: 0.178400 (0.194960)	loss_train_adv: 0.001151 (0.003703)
	cen_loss: 0.620876 (0.613781)	cls_loss: 0.102830 (0.049948)
	loc_loss: 0.196209 (0.178905)	total_loss: 1.312332 (1.200445)

[2023-05-05 02:33:10,219-rk0-log_helper.py#102] Progress: 7000 / 15625 [44%], Speed: 2.424 s/iter, ETA 0:05:48 (D:H:M)

[2023-05-05 02:34:01,011-rk0-train.py#348] Epoch: [12][145/625] lr: 0.000725
	batch_time: 2.387041 (2.441045)	data_time: 0.001372 (0.002167)
	loss_fool: 0.205299 (0.194308)	loss_train_adv: 0.001855 (0.003925)
	cen_loss: 0.615367 (0.614146)	cls_loss: 0.040824 (0.051117)
	loc_loss: 0.171463 (0.179341)	total_loss: 1.170580 (1.203284)

[2023-05-05 02:34:01,012-rk0-log_helper.py#102] Progress: 7020 / 15625 [44%], Speed: 2.441 s/iter, ETA 0:05:50 (D:H:M)

[2023-05-05 02:34:49,391-rk0-train.py#348] Epoch: [12][165/625] lr: 0.000725
	batch_time: 2.356848 (2.446168)	data_time: 0.001410 (0.002316)
	loss_fool: 0.185608 (0.194268)	loss_train_adv: 0.008409 (0.004518)
	cen_loss: 0.619074 (0.614284)	cls_loss: 0.048998 (0.052679)
	loc_loss: 0.187427 (0.180171)	total_loss: 1.230354 (1.207475)

[2023-05-05 02:34:49,392-rk0-log_helper.py#102] Progress: 7040 / 15625 [45%], Speed: 2.446 s/iter, ETA 0:05:50 (D:H:M)

[2023-05-05 02:35:37,436-rk0-train.py#348] Epoch: [12][185/625] lr: 0.000725
	batch_time: 2.359917 (2.431705)	data_time: 0.001260 (0.002264)
	loss_fool: 0.205099 (0.193405)	loss_train_adv: 0.001103 (0.004738)
	cen_loss: 0.612951 (0.614552)	cls_loss: 0.038218 (0.054625)
	loc_loss: 0.174516 (0.182610)	total_loss: 1.174717 (1.217007)

[2023-05-05 02:35:37,437-rk0-log_helper.py#102] Progress: 7060 / 15625 [45%], Speed: 2.432 s/iter, ETA 0:05:47 (D:H:M)

[2023-05-05 02:36:24,827-rk0-train.py#348] Epoch: [12][205/625] lr: 0.000725
	batch_time: 2.353652 (2.416389)	data_time: 0.001264 (0.002262)
	loss_fool: 0.178183 (0.193832)	loss_train_adv: 0.003819 (0.004465)
	cen_loss: 0.612520 (0.614329)	cls_loss: 0.042322 (0.054117)
	loc_loss: 0.174485 (0.181483)	total_loss: 1.178297 (1.212895)

[2023-05-05 02:36:24,828-rk0-log_helper.py#102] Progress: 7080 / 15625 [45%], Speed: 2.416 s/iter, ETA 0:05:44 (D:H:M)

[2023-05-05 02:37:14,798-rk0-train.py#348] Epoch: [12][225/625] lr: 0.000725
	batch_time: 2.398308 (2.442686)	data_time: 0.001459 (0.002172)
	loss_fool: 0.201839 (0.194388)	loss_train_adv: 0.004161 (0.004196)
	cen_loss: 0.609256 (0.614650)	cls_loss: 0.044835 (0.054830)
	loc_loss: 0.184147 (0.182420)	total_loss: 1.206531 (1.216740)

[2023-05-05 02:37:14,798-rk0-log_helper.py#102] Progress: 7100 / 15625 [45%], Speed: 2.443 s/iter, ETA 0:05:47 (D:H:M)

[2023-05-05 02:38:03,046-rk0-train.py#348] Epoch: [12][245/625] lr: 0.000725
	batch_time: 2.414924 (2.417421)	data_time: 0.001349 (0.001947)
	loss_fool: 0.195539 (0.194762)	loss_train_adv: 0.003134 (0.004015)
	cen_loss: 0.610910 (0.614385)	cls_loss: 0.064128 (0.054724)
	loc_loss: 0.193309 (0.182419)	total_loss: 1.254964 (1.216366)

[2023-05-05 02:38:03,046-rk0-log_helper.py#102] Progress: 7120 / 15625 [45%], Speed: 2.417 s/iter, ETA 0:05:42 (D:H:M)

[2023-05-05 02:38:51,435-rk0-train.py#348] Epoch: [12][265/625] lr: 0.000725
	batch_time: 2.389294 (2.417833)	data_time: 0.001233 (0.002068)
	loss_fool: 0.179583 (0.193918)	loss_train_adv: 0.003001 (0.003692)
	cen_loss: 0.613362 (0.614123)	cls_loss: 0.050033 (0.053828)
	loc_loss: 0.183729 (0.181987)	total_loss: 1.214582 (1.213912)

[2023-05-05 02:38:51,436-rk0-log_helper.py#102] Progress: 7140 / 15625 [45%], Speed: 2.418 s/iter, ETA 0:05:41 (D:H:M)

[2023-05-05 02:39:39,163-rk0-train.py#348] Epoch: [12][285/625] lr: 0.000725
	batch_time: 2.437951 (2.414528)	data_time: 0.001190 (0.001923)
	loss_fool: 0.200786 (0.194099)	loss_train_adv: 0.005381 (0.003903)
	cen_loss: 0.610781 (0.613884)	cls_loss: 0.039606 (0.051001)
	loc_loss: 0.184082 (0.179889)	total_loss: 1.202633 (1.204552)

[2023-05-05 02:39:39,164-rk0-log_helper.py#102] Progress: 7160 / 15625 [45%], Speed: 2.415 s/iter, ETA 0:05:40 (D:H:M)

[2023-05-05 02:40:26,264-rk0-train.py#348] Epoch: [12][305/625] lr: 0.000725
	batch_time: 2.443652 (2.411647)	data_time: 0.001152 (0.001839)
	loss_fool: 0.182859 (0.194396)	loss_train_adv: 0.005615 (0.003724)
	cen_loss: 0.620291 (0.613752)	cls_loss: 0.046453 (0.051646)
	loc_loss: 0.187961 (0.180209)	total_loss: 1.230627 (1.206024)

[2023-05-05 02:40:26,265-rk0-log_helper.py#102] Progress: 7180 / 15625 [45%], Speed: 2.412 s/iter, ETA 0:05:39 (D:H:M)

[2023-05-05 02:41:14,692-rk0-train.py#348] Epoch: [12][325/625] lr: 0.000725
	batch_time: 2.434527 (2.396288)	data_time: 0.001175 (0.001834)
	loss_fool: 0.206817 (0.194450)	loss_train_adv: 0.000534 (0.003655)
	cen_loss: 0.603260 (0.613548)	cls_loss: 0.042841 (0.052697)
	loc_loss: 0.150491 (0.179735)	total_loss: 1.097574 (1.205451)

[2023-05-05 02:41:14,693-rk0-log_helper.py#102] Progress: 7200 / 15625 [46%], Speed: 2.396 s/iter, ETA 0:05:36 (D:H:M)

[2023-05-05 02:42:01,823-rk0-train.py#348] Epoch: [12][345/625] lr: 0.000725
	batch_time: 2.334240 (2.385324)	data_time: 0.001141 (0.001993)
	loss_fool: 0.192144 (0.194308)	loss_train_adv: 0.008983 (0.003993)
	cen_loss: 0.612272 (0.613656)	cls_loss: 0.045665 (0.052481)
	loc_loss: 0.182555 (0.179485)	total_loss: 1.205603 (1.204592)

[2023-05-05 02:42:01,824-rk0-log_helper.py#102] Progress: 7220 / 15625 [46%], Speed: 2.385 s/iter, ETA 0:05:34 (D:H:M)

[2023-05-05 02:42:50,386-rk0-train.py#348] Epoch: [12][365/625] lr: 0.000725
	batch_time: 2.956560 (2.386944)	data_time: 0.005348 (0.001974)
	loss_fool: 0.173624 (0.194158)	loss_train_adv: 0.002239 (0.004130)
	cen_loss: 0.612471 (0.613944)	cls_loss: 0.041976 (0.051348)
	loc_loss: 0.162056 (0.178803)	total_loss: 1.140615 (1.201701)

[2023-05-05 02:42:50,387-rk0-log_helper.py#102] Progress: 7240 / 15625 [46%], Speed: 2.387 s/iter, ETA 0:05:33 (D:H:M)

[2023-05-05 02:43:37,867-rk0-train.py#348] Epoch: [12][385/625] lr: 0.000725
	batch_time: 2.387980 (2.384639)	data_time: 0.001184 (0.001998)
	loss_fool: 0.196330 (0.194898)	loss_train_adv: 0.004245 (0.003803)
	cen_loss: 0.604422 (0.613641)	cls_loss: 0.180540 (0.053371)
	loc_loss: 0.192788 (0.178048)	total_loss: 1.363326 (1.201156)

[2023-05-05 02:43:37,867-rk0-log_helper.py#102] Progress: 7260 / 15625 [46%], Speed: 2.385 s/iter, ETA 0:05:32 (D:H:M)

[2023-05-05 02:44:24,863-rk0-train.py#348] Epoch: [12][405/625] lr: 0.000725
	batch_time: 2.406737 (2.383670)	data_time: 0.001423 (0.002029)
	loss_fool: 0.170278 (0.194045)	loss_train_adv: 0.009139 (0.004032)
	cen_loss: 0.612027 (0.613602)	cls_loss: 0.044553 (0.052926)
	loc_loss: 0.192175 (0.178313)	total_loss: 1.233105 (1.201468)

[2023-05-05 02:44:24,864-rk0-log_helper.py#102] Progress: 7280 / 15625 [46%], Speed: 2.384 s/iter, ETA 0:05:31 (D:H:M)

[2023-05-05 02:45:13,599-rk0-train.py#348] Epoch: [12][425/625] lr: 0.000725
	batch_time: 2.322065 (2.386752)	data_time: 0.001142 (0.001965)
	loss_fool: 0.207840 (0.194110)	loss_train_adv: 0.008288 (0.004327)
	cen_loss: 0.610897 (0.613854)	cls_loss: 0.044378 (0.051794)
	loc_loss: 0.205189 (0.178618)	total_loss: 1.270841 (1.201502)

[2023-05-05 02:45:13,601-rk0-log_helper.py#102] Progress: 7300 / 15625 [46%], Speed: 2.387 s/iter, ETA 0:05:31 (D:H:M)

[2023-05-05 02:46:01,167-rk0-train.py#348] Epoch: [12][445/625] lr: 0.000725
	batch_time: 2.492844 (2.390803)	data_time: 0.001275 (0.001818)
	loss_fool: 0.193542 (0.194283)	loss_train_adv: 0.000191 (0.004271)
	cen_loss: 0.614972 (0.613630)	cls_loss: 0.057475 (0.051143)
	loc_loss: 0.193784 (0.179165)	total_loss: 1.253800 (1.202267)

[2023-05-05 02:46:01,167-rk0-log_helper.py#102] Progress: 7320 / 15625 [46%], Speed: 2.391 s/iter, ETA 0:05:30 (D:H:M)

[2023-05-05 02:46:48,492-rk0-train.py#348] Epoch: [12][465/625] lr: 0.000725
	batch_time: 2.313101 (2.378257)	data_time: 0.001150 (0.001466)
	loss_fool: 0.180027 (0.194173)	loss_train_adv: 0.006711 (0.004101)
	cen_loss: 0.622570 (0.613270)	cls_loss: 0.033374 (0.051103)
	loc_loss: 0.165047 (0.180485)	total_loss: 1.151085 (1.205828)

[2023-05-05 02:46:48,492-rk0-log_helper.py#102] Progress: 7340 / 15625 [46%], Speed: 2.378 s/iter, ETA 0:05:28 (D:H:M)

[2023-05-05 02:47:38,333-rk0-train.py#348] Epoch: [12][485/625] lr: 0.000725
	batch_time: 2.993232 (2.401484)	data_time: 0.001198 (0.001699)
	loss_fool: 0.186998 (0.194121)	loss_train_adv: 0.002099 (0.004040)
	cen_loss: 0.613335 (0.613241)	cls_loss: 0.038038 (0.049734)
	loc_loss: 0.188489 (0.180801)	total_loss: 1.216839 (1.205379)

[2023-05-05 02:47:38,334-rk0-log_helper.py#102] Progress: 7360 / 15625 [47%], Speed: 2.401 s/iter, ETA 0:05:30 (D:H:M)

[2023-05-05 02:48:28,788-rk0-train.py#348] Epoch: [12][505/625] lr: 0.000725
	batch_time: 2.327782 (2.436061)	data_time: 0.001192 (0.001682)
	loss_fool: 0.202471 (0.194389)	loss_train_adv: 0.000741 (0.003910)
	cen_loss: 0.613732 (0.613027)	cls_loss: 0.035733 (0.049457)
	loc_loss: 0.174086 (0.180862)	total_loss: 1.171721 (1.205070)

[2023-05-05 02:48:28,789-rk0-log_helper.py#102] Progress: 7380 / 15625 [47%], Speed: 2.436 s/iter, ETA 0:05:34 (D:H:M)

[2023-05-05 02:49:16,637-rk0-train.py#348] Epoch: [12][525/625] lr: 0.000725
	batch_time: 2.405439 (2.427061)	data_time: 0.001181 (0.001612)
	loss_fool: 0.198726 (0.194582)	loss_train_adv: 0.000319 (0.003709)
	cen_loss: 0.615968 (0.612937)	cls_loss: 0.053845 (0.048233)
	loc_loss: 0.192725 (0.180231)	total_loss: 1.247987 (1.201863)

[2023-05-05 02:49:16,638-rk0-log_helper.py#102] Progress: 7400 / 15625 [47%], Speed: 2.427 s/iter, ETA 0:05:32 (D:H:M)

[2023-05-05 02:50:07,250-rk0-train.py#348] Epoch: [12][545/625] lr: 0.000725
	batch_time: 3.555295 (2.457721)	data_time: 0.001160 (0.001787)
	loss_fool: 0.193019 (0.194072)	loss_train_adv: 0.006601 (0.003461)
	cen_loss: 0.617213 (0.612946)	cls_loss: 0.039945 (0.048555)
	loc_loss: 0.177732 (0.180199)	total_loss: 1.190352 (1.202099)

[2023-05-05 02:50:07,250-rk0-log_helper.py#102] Progress: 7420 / 15625 [47%], Speed: 2.458 s/iter, ETA 0:05:36 (D:H:M)

[2023-05-05 02:50:55,542-rk0-train.py#348] Epoch: [12][565/625] lr: 0.000725
	batch_time: 2.477763 (2.467466)	data_time: 0.001143 (0.001947)
	loss_fool: 0.190679 (0.195221)	loss_train_adv: 0.000771 (0.003339)
	cen_loss: 0.607417 (0.612963)	cls_loss: 0.049286 (0.048292)
	loc_loss: 0.173341 (0.179645)	total_loss: 1.176727 (1.200190)

[2023-05-05 02:50:55,544-rk0-log_helper.py#102] Progress: 7440 / 15625 [47%], Speed: 2.467 s/iter, ETA 0:05:36 (D:H:M)

[2023-05-05 02:51:43,199-rk0-train.py#348] Epoch: [12][585/625] lr: 0.000725
	batch_time: 2.358372 (2.445827)	data_time: 0.001196 (0.001676)
	loss_fool: 0.201888 (0.195259)	loss_train_adv: 0.006041 (0.003506)
	cen_loss: 0.611117 (0.613475)	cls_loss: 0.060136 (0.049296)
	loc_loss: 0.174318 (0.181506)	total_loss: 1.194207 (1.207290)

[2023-05-05 02:51:43,199-rk0-log_helper.py#102] Progress: 7460 / 15625 [47%], Speed: 2.446 s/iter, ETA 0:05:32 (D:H:M)

[2023-05-05 02:52:32,667-rk0-train.py#348] Epoch: [12][605/625] lr: 0.000725
	batch_time: 2.330383 (2.435926)	data_time: 0.002020 (0.001985)
	loss_fool: 0.189830 (0.195157)	loss_train_adv: 0.001673 (0.003463)
	cen_loss: 0.625762 (0.614166)	cls_loss: 0.057375 (0.051322)
	loc_loss: 0.193197 (0.182931)	total_loss: 1.262730 (1.214280)

[2023-05-05 02:52:32,667-rk0-log_helper.py#102] Progress: 7480 / 15625 [47%], Speed: 2.436 s/iter, ETA 0:05:30 (D:H:M)

[2023-05-05 02:53:21,768-rk0-train.py#348] Epoch: [12][0/625] lr: 0.000725
	batch_time: 2.345663 (2.448530)	data_time: 0.001209 (0.002112)
	loss_fool: 0.204753 (0.194619)	loss_train_adv: 0.000928 (0.003473)
	cen_loss: 0.612778 (0.614152)	cls_loss: 0.040366 (0.051512)
	loc_loss: 0.162124 (0.181928)	total_loss: 1.139516 (1.211448)

[2023-05-05 02:53:21,768-rk0-log_helper.py#102] Progress: 7500 / 15625 [48%], Speed: 2.449 s/iter, ETA 0:05:31 (D:H:M)

[2023-05-05 02:53:23,175-rk0-train.py#235] epoch: 13
[2023-05-05 02:53:23,176-rk0-train.py#240] epoch 13 lr 6.421998598079094e-05
[2023-05-05 02:53:23,176-rk0-train.py#240] epoch 13 lr 0.0006421998598079094
[2023-05-05 02:53:23,177-rk0-train.py#240] epoch 13 lr 0.002140666199359698
[2023-05-05 02:53:23,177-rk0-train.py#240] epoch 13 lr 0.0006421998598079094
[2023-05-05 02:53:23,178-rk0-train.py#240] epoch 13 lr 0.0006421998598079094
[2023-05-05 02:54:10,674-rk0-train.py#348] Epoch: [13][20/625] lr: 0.000642
	batch_time: 2.321932 (2.431548)	data_time: 0.001217 (0.016003)
	loss_fool: 0.198811 (0.194582)	loss_train_adv: 0.004264 (0.003779)
	cen_loss: 0.610267 (0.614113)	cls_loss: 0.033532 (0.051368)
	loc_loss: 0.180337 (0.180314)	total_loss: 1.184810 (1.206423)

[2023-05-05 02:54:10,675-rk0-log_helper.py#102] Progress: 7520 / 15625 [48%], Speed: 2.432 s/iter, ETA 0:05:28 (D:H:M)

[2023-05-05 02:54:58,355-rk0-train.py#348] Epoch: [13][40/625] lr: 0.000642
	batch_time: 2.346519 (2.425651)	data_time: 0.001204 (0.015879)
	loss_fool: 0.191998 (0.194991)	loss_train_adv: 0.001042 (0.003750)
	cen_loss: 0.613023 (0.613883)	cls_loss: 0.036050 (0.052260)
	loc_loss: 0.188438 (0.179638)	total_loss: 1.214387 (1.205056)

[2023-05-05 02:54:58,356-rk0-log_helper.py#102] Progress: 7540 / 15625 [48%], Speed: 2.426 s/iter, ETA 0:05:26 (D:H:M)

[2023-05-05 02:55:45,986-rk0-train.py#348] Epoch: [13][60/625] lr: 0.000642
	batch_time: 2.469590 (2.425260)	data_time: 0.000191 (0.016074)
	loss_fool: 0.192270 (0.194394)	loss_train_adv: 0.001628 (0.003791)
	cen_loss: 0.616527 (0.613751)	cls_loss: 0.035423 (0.052725)
	loc_loss: 0.183144 (0.180150)	total_loss: 1.201382 (1.206927)

[2023-05-05 02:55:45,986-rk0-log_helper.py#102] Progress: 7560 / 15625 [48%], Speed: 2.425 s/iter, ETA 0:05:25 (D:H:M)

[2023-05-05 02:56:33,215-rk0-train.py#348] Epoch: [13][80/625] lr: 0.000642
	batch_time: 2.410058 (2.402849)	data_time: 0.001592 (0.015718)
	loss_fool: 0.192989 (0.194292)	loss_train_adv: 0.005172 (0.003866)
	cen_loss: 0.621316 (0.613449)	cls_loss: 0.036733 (0.051573)
	loc_loss: 0.157975 (0.178214)	total_loss: 1.131972 (1.199665)

[2023-05-05 02:56:33,215-rk0-log_helper.py#102] Progress: 7580 / 15625 [48%], Speed: 2.403 s/iter, ETA 0:05:22 (D:H:M)

[2023-05-05 02:57:20,191-rk0-train.py#348] Epoch: [13][100/625] lr: 0.000642
	batch_time: 2.465037 (2.381502)	data_time: 0.001304 (0.015661)
	loss_fool: 0.200860 (0.194887)	loss_train_adv: 0.004814 (0.004297)
	cen_loss: 0.614415 (0.613145)	cls_loss: 0.089869 (0.051358)
	loc_loss: 0.156992 (0.178378)	total_loss: 1.175260 (1.199637)

[2023-05-05 02:57:20,192-rk0-log_helper.py#102] Progress: 7600 / 15625 [48%], Speed: 2.382 s/iter, ETA 0:05:18 (D:H:M)

[2023-05-05 02:58:08,634-rk0-train.py#348] Epoch: [13][120/625] lr: 0.000642
	batch_time: 2.451923 (2.376755)	data_time: 0.001502 (0.001835)
	loss_fool: 0.190800 (0.194629)	loss_train_adv: 0.000782 (0.003979)
	cen_loss: 0.607252 (0.612899)	cls_loss: 0.037335 (0.051410)
	loc_loss: 0.166756 (0.179255)	total_loss: 1.144855 (1.202074)

[2023-05-05 02:58:08,634-rk0-log_helper.py#102] Progress: 7620 / 15625 [48%], Speed: 2.377 s/iter, ETA 0:05:17 (D:H:M)

[2023-05-05 02:58:56,023-rk0-train.py#348] Epoch: [13][140/625] lr: 0.000642
	batch_time: 2.370565 (2.373619)	data_time: 0.001131 (0.002032)
	loss_fool: 0.204055 (0.194493)	loss_train_adv: 0.001709 (0.003934)
	cen_loss: 0.609837 (0.613350)	cls_loss: 0.038605 (0.051771)
	loc_loss: 0.164893 (0.180113)	total_loss: 1.143120 (1.205459)

[2023-05-05 02:58:56,024-rk0-log_helper.py#102] Progress: 7640 / 15625 [48%], Speed: 2.374 s/iter, ETA 0:05:15 (D:H:M)

[2023-05-05 02:59:43,130-rk0-train.py#348] Epoch: [13][160/625] lr: 0.000642
	batch_time: 2.385895 (2.368614)	data_time: 0.004581 (0.001889)
	loss_fool: 0.185176 (0.194762)	loss_train_adv: 0.001528 (0.003676)
	cen_loss: 0.614725 (0.613504)	cls_loss: 0.047899 (0.050192)
	loc_loss: 0.210884 (0.178624)	total_loss: 1.295275 (1.199566)

[2023-05-05 02:59:43,130-rk0-log_helper.py#102] Progress: 7660 / 15625 [49%], Speed: 2.369 s/iter, ETA 0:05:14 (D:H:M)

[2023-05-05 03:00:31,488-rk0-train.py#348] Epoch: [13][180/625] lr: 0.000642
	batch_time: 2.497229 (2.379916)	data_time: 0.001128 (0.002028)
	loss_fool: 0.215259 (0.195020)	loss_train_adv: 0.009930 (0.003879)
	cen_loss: 0.625288 (0.613063)	cls_loss: 0.049997 (0.049218)
	loc_loss: 0.189896 (0.178306)	total_loss: 1.244972 (1.197198)

[2023-05-05 03:00:31,488-rk0-log_helper.py#102] Progress: 7680 / 15625 [49%], Speed: 2.380 s/iter, ETA 0:05:15 (D:H:M)

[2023-05-05 03:01:18,786-rk0-train.py#348] Epoch: [13][200/625] lr: 0.000642
	batch_time: 2.352392 (2.383399)	data_time: 0.001116 (0.001943)
	loss_fool: 0.189018 (0.194261)	loss_train_adv: 0.001876 (0.003557)
	cen_loss: 0.618439 (0.613234)	cls_loss: 0.039017 (0.049247)
	loc_loss: 0.176452 (0.178853)	total_loss: 1.186810 (1.199040)

[2023-05-05 03:01:18,787-rk0-log_helper.py#102] Progress: 7700 / 15625 [49%], Speed: 2.383 s/iter, ETA 0:05:14 (D:H:M)

[2023-05-05 03:02:06,436-rk0-train.py#348] Epoch: [13][220/625] lr: 0.000642
	batch_time: 2.480918 (2.375332)	data_time: 0.001161 (0.001829)
	loss_fool: 0.199840 (0.195056)	loss_train_adv: 0.000368 (0.003707)
	cen_loss: 0.606840 (0.613714)	cls_loss: 0.043935 (0.048076)
	loc_loss: 0.177340 (0.179182)	total_loss: 1.182794 (1.199336)

[2023-05-05 03:02:06,437-rk0-log_helper.py#102] Progress: 7720 / 15625 [49%], Speed: 2.375 s/iter, ETA 0:05:12 (D:H:M)

[2023-05-05 03:02:53,879-rk0-train.py#348] Epoch: [13][240/625] lr: 0.000642
	batch_time: 2.321748 (2.376031)	data_time: 0.001253 (0.001698)
	loss_fool: 0.192246 (0.194615)	loss_train_adv: 0.003006 (0.003597)
	cen_loss: 0.615995 (0.613911)	cls_loss: 0.039517 (0.047552)
	loc_loss: 0.160884 (0.179602)	total_loss: 1.138165 (1.200267)

[2023-05-05 03:02:53,880-rk0-log_helper.py#102] Progress: 7740 / 15625 [49%], Speed: 2.376 s/iter, ETA 0:05:12 (D:H:M)

[2023-05-05 03:03:41,502-rk0-train.py#348] Epoch: [13][260/625] lr: 0.000642
	batch_time: 2.453722 (2.381159)	data_time: 0.001353 (0.001842)
	loss_fool: 0.198003 (0.195119)	loss_train_adv: 0.007202 (0.003527)
	cen_loss: 0.610796 (0.613881)	cls_loss: 0.034393 (0.047654)
	loc_loss: 0.158113 (0.178896)	total_loss: 1.119529 (1.198224)

[2023-05-05 03:03:41,503-rk0-log_helper.py#102] Progress: 7760 / 15625 [49%], Speed: 2.381 s/iter, ETA 0:05:12 (D:H:M)

[2023-05-05 03:04:28,912-rk0-train.py#348] Epoch: [13][280/625] lr: 0.000642
	batch_time: 2.317955 (2.371547)	data_time: 0.001392 (0.001789)
	loss_fool: 0.181518 (0.194954)	loss_train_adv: 0.000820 (0.003486)
	cen_loss: 0.616463 (0.613952)	cls_loss: 0.052640 (0.047408)
	loc_loss: 0.176321 (0.179886)	total_loss: 1.198065 (1.201017)

[2023-05-05 03:04:28,913-rk0-log_helper.py#102] Progress: 7780 / 15625 [49%], Speed: 2.372 s/iter, ETA 0:05:10 (D:H:M)

[2023-05-05 03:05:16,628-rk0-train.py#348] Epoch: [13][300/625] lr: 0.000642
	batch_time: 2.389577 (2.375557)	data_time: 0.001090 (0.001813)
	loss_fool: 0.185484 (0.194970)	loss_train_adv: 0.003925 (0.003551)
	cen_loss: 0.608977 (0.613540)	cls_loss: 0.075698 (0.048214)
	loc_loss: 0.169580 (0.180205)	total_loss: 1.193416 (1.202370)

[2023-05-05 03:05:16,629-rk0-log_helper.py#102] Progress: 7800 / 15625 [49%], Speed: 2.376 s/iter, ETA 0:05:09 (D:H:M)

[2023-05-05 03:06:03,883-rk0-train.py#348] Epoch: [13][320/625] lr: 0.000642
	batch_time: 2.404840 (2.371833)	data_time: 0.001089 (0.001651)
	loss_fool: 0.199375 (0.194984)	loss_train_adv: 0.000404 (0.003338)
	cen_loss: 0.612359 (0.613596)	cls_loss: 0.036007 (0.049282)
	loc_loss: 0.154473 (0.179748)	total_loss: 1.111784 (1.202122)

[2023-05-05 03:06:03,884-rk0-log_helper.py#102] Progress: 7820 / 15625 [50%], Speed: 2.372 s/iter, ETA 0:05:08 (D:H:M)

[2023-05-05 03:06:53,323-rk0-train.py#348] Epoch: [13][340/625] lr: 0.000642
	batch_time: 2.396048 (2.391688)	data_time: 0.001069 (0.001540)
	loss_fool: 0.193738 (0.195244)	loss_train_adv: 0.000184 (0.003393)
	cen_loss: 0.608639 (0.613019)	cls_loss: 0.041266 (0.048307)
	loc_loss: 0.168331 (0.176494)	total_loss: 1.154899 (1.190807)

[2023-05-05 03:06:53,324-rk0-log_helper.py#102] Progress: 7840 / 15625 [50%], Speed: 2.392 s/iter, ETA 0:05:10 (D:H:M)

[2023-05-05 03:07:41,227-rk0-train.py#348] Epoch: [13][360/625] lr: 0.000642
	batch_time: 2.388370 (2.394490)	data_time: 0.001116 (0.001349)
	loss_fool: 0.217494 (0.194422)	loss_train_adv: 0.002580 (0.003678)
	cen_loss: 0.609858 (0.612942)	cls_loss: 0.037297 (0.047383)
	loc_loss: 0.167123 (0.175521)	total_loss: 1.148522 (1.186888)

[2023-05-05 03:07:41,228-rk0-log_helper.py#102] Progress: 7860 / 15625 [50%], Speed: 2.394 s/iter, ETA 0:05:09 (D:H:M)

[2023-05-05 03:08:28,652-rk0-train.py#348] Epoch: [13][380/625] lr: 0.000642
	batch_time: 2.424081 (2.394953)	data_time: 0.001163 (0.001500)
	loss_fool: 0.182802 (0.194867)	loss_train_adv: 0.003816 (0.003567)
	cen_loss: 0.617496 (0.613562)	cls_loss: 0.052244 (0.048359)
	loc_loss: 0.172635 (0.176713)	total_loss: 1.187645 (1.192060)

[2023-05-05 03:08:28,652-rk0-log_helper.py#102] Progress: 7880 / 15625 [50%], Speed: 2.395 s/iter, ETA 0:05:09 (D:H:M)

[2023-05-05 03:09:16,021-rk0-train.py#348] Epoch: [13][400/625] lr: 0.000642
	batch_time: 2.387992 (2.391299)	data_time: 0.001246 (0.001567)
	loss_fool: 0.204933 (0.194781)	loss_train_adv: 0.005079 (0.003693)
	cen_loss: 0.615136 (0.614042)	cls_loss: 0.048463 (0.047353)
	loc_loss: 0.194718 (0.176363)	total_loss: 1.247754 (1.190485)

[2023-05-05 03:09:16,022-rk0-log_helper.py#102] Progress: 7900 / 15625 [50%], Speed: 2.391 s/iter, ETA 0:05:07 (D:H:M)

[2023-05-05 03:10:03,519-rk0-train.py#348] Epoch: [13][420/625] lr: 0.000642
	batch_time: 2.402610 (2.393283)	data_time: 0.001346 (0.001789)
	loss_fool: 0.184278 (0.193667)	loss_train_adv: 0.004622 (0.004345)
	cen_loss: 0.612058 (0.613800)	cls_loss: 0.047521 (0.047137)
	loc_loss: 0.171482 (0.175503)	total_loss: 1.174026 (1.187445)

[2023-05-05 03:10:03,520-rk0-log_helper.py#102] Progress: 7920 / 15625 [50%], Speed: 2.393 s/iter, ETA 0:05:07 (D:H:M)

[2023-05-05 03:10:50,580-rk0-train.py#348] Epoch: [13][440/625] lr: 0.000642
	batch_time: 2.372244 (2.369581)	data_time: 0.001175 (0.002062)
	loss_fool: 0.200974 (0.193594)	loss_train_adv: 0.002947 (0.004704)
	cen_loss: 0.617174 (0.614044)	cls_loss: 0.041830 (0.048187)
	loc_loss: 0.166569 (0.178043)	total_loss: 1.158710 (1.196359)

[2023-05-05 03:10:50,581-rk0-log_helper.py#102] Progress: 7940 / 15625 [50%], Speed: 2.370 s/iter, ETA 0:05:03 (D:H:M)

[2023-05-05 03:11:38,068-rk0-train.py#348] Epoch: [13][460/625] lr: 0.000642
	batch_time: 2.403516 (2.365522)	data_time: 0.001350 (0.002045)
	loss_fool: 0.187266 (0.193782)	loss_train_adv: 0.004647 (0.004508)
	cen_loss: 0.618195 (0.613875)	cls_loss: 0.041590 (0.048305)
	loc_loss: 0.193792 (0.179659)	total_loss: 1.241161 (1.201156)

[2023-05-05 03:11:38,069-rk0-log_helper.py#102] Progress: 7960 / 15625 [50%], Speed: 2.366 s/iter, ETA 0:05:02 (D:H:M)

[2023-05-05 03:12:25,435-rk0-train.py#348] Epoch: [13][480/625] lr: 0.000642
	batch_time: 2.426052 (2.364933)	data_time: 0.023185 (0.002100)
	loss_fool: 0.190981 (0.193886)	loss_train_adv: 0.006111 (0.004308)
	cen_loss: 0.609096 (0.613539)	cls_loss: 0.038401 (0.047306)
	loc_loss: 0.167013 (0.177483)	total_loss: 1.148536 (1.193295)

[2023-05-05 03:12:25,436-rk0-log_helper.py#102] Progress: 7980 / 15625 [51%], Speed: 2.365 s/iter, ETA 0:05:01 (D:H:M)

[2023-05-05 03:13:15,027-rk0-train.py#348] Epoch: [13][500/625] lr: 0.000642
	batch_time: 2.391688 (2.387336)	data_time: 0.001256 (0.002252)
	loss_fool: 0.130150 (0.191433)	loss_train_adv: 0.018793 (0.005755)
	cen_loss: 0.611023 (0.613612)	cls_loss: 0.065649 (0.048645)
	loc_loss: 0.178530 (0.178803)	total_loss: 1.212260 (1.198667)

[2023-05-05 03:13:15,027-rk0-log_helper.py#102] Progress: 8000 / 15625 [51%], Speed: 2.387 s/iter, ETA 0:05:03 (D:H:M)

[2023-05-05 03:14:02,968-rk0-train.py#348] Epoch: [13][520/625] lr: 0.000642
	batch_time: 2.503446 (2.392091)	data_time: 0.011933 (0.002158)
	loss_fool: 0.191649 (0.192609)	loss_train_adv: 0.004130 (0.005733)
	cen_loss: 0.615715 (0.613831)	cls_loss: 0.037280 (0.048552)
	loc_loss: 0.174378 (0.179491)	total_loss: 1.176130 (1.200858)

[2023-05-05 03:14:02,969-rk0-log_helper.py#102] Progress: 8020 / 15625 [51%], Speed: 2.392 s/iter, ETA 0:05:03 (D:H:M)

[2023-05-05 03:14:50,256-rk0-train.py#348] Epoch: [13][540/625] lr: 0.000642
	batch_time: 2.390449 (2.394400)	data_time: 0.001345 (0.001987)
	loss_fool: 0.201325 (0.192024)	loss_train_adv: 0.002667 (0.005473)
	cen_loss: 0.617836 (0.613862)	cls_loss: 0.036510 (0.049054)
	loc_loss: 0.161816 (0.180317)	total_loss: 1.139795 (1.203867)

[2023-05-05 03:14:50,261-rk0-log_helper.py#102] Progress: 8040 / 15625 [51%], Speed: 2.394 s/iter, ETA 0:05:02 (D:H:M)

[2023-05-05 03:15:37,180-rk0-train.py#348] Epoch: [13][560/625] lr: 0.000642
	batch_time: 2.322060 (2.388512)	data_time: 0.001121 (0.002108)
	loss_fool: 0.217515 (0.192380)	loss_train_adv: 0.005037 (0.005786)
	cen_loss: 0.619084 (0.613971)	cls_loss: 0.060000 (0.050300)
	loc_loss: 0.199610 (0.181594)	total_loss: 1.277916 (1.209053)

[2023-05-05 03:15:37,180-rk0-log_helper.py#102] Progress: 8060 / 15625 [51%], Speed: 2.389 s/iter, ETA 0:05:01 (D:H:M)

[2023-05-05 03:16:25,737-rk0-train.py#348] Epoch: [13][580/625] lr: 0.000642
	batch_time: 2.411684 (2.400381)	data_time: 0.001670 (0.002013)
	loss_fool: 0.205081 (0.192503)	loss_train_adv: 0.000720 (0.005904)
	cen_loss: 0.610839 (0.613871)	cls_loss: 0.058172 (0.051521)
	loc_loss: 0.174741 (0.181706)	total_loss: 1.193235 (1.210509)

[2023-05-05 03:16:25,737-rk0-log_helper.py#102] Progress: 8080 / 15625 [51%], Speed: 2.400 s/iter, ETA 0:05:01 (D:H:M)

[2023-05-05 03:17:13,416-rk0-train.py#348] Epoch: [13][600/625] lr: 0.000642
	batch_time: 2.372615 (2.381202)	data_time: 0.001163 (0.001775)
	loss_fool: 0.194868 (0.195515)	loss_train_adv: 0.004858 (0.003873)
	cen_loss: 0.612539 (0.613428)	cls_loss: 0.068733 (0.053623)
	loc_loss: 0.216527 (0.181084)	total_loss: 1.330852 (1.210302)

[2023-05-05 03:17:13,417-rk0-log_helper.py#102] Progress: 8100 / 15625 [51%], Speed: 2.381 s/iter, ETA 0:04:58 (D:H:M)

[2023-05-05 03:18:01,307-rk0-train.py#348] Epoch: [13][620/625] lr: 0.000642
	batch_time: 2.415035 (2.380610)	data_time: 0.001448 (0.001776)
	loss_fool: 0.188790 (0.195460)	loss_train_adv: 0.003749 (0.003237)
	cen_loss: 0.612606 (0.613080)	cls_loss: 0.059515 (0.054737)
	loc_loss: 0.196589 (0.182191)	total_loss: 1.261889 (1.214389)

[2023-05-05 03:18:01,307-rk0-log_helper.py#102] Progress: 8120 / 15625 [51%], Speed: 2.381 s/iter, ETA 0:04:57 (D:H:M)

[2023-05-05 03:18:14,402-rk0-train.py#235] epoch: 14
[2023-05-05 03:18:14,402-rk0-train.py#240] epoch 14 lr 5.6890352860983745e-05
[2023-05-05 03:18:14,403-rk0-train.py#240] epoch 14 lr 0.0005689035286098374
[2023-05-05 03:18:14,403-rk0-train.py#240] epoch 14 lr 0.0018963450953661245
[2023-05-05 03:18:14,404-rk0-train.py#240] epoch 14 lr 0.0005689035286098374
[2023-05-05 03:18:14,404-rk0-train.py#240] epoch 14 lr 0.0005689035286098374
[2023-05-05 03:18:50,141-rk0-train.py#348] Epoch: [14][15/625] lr: 0.000569
	batch_time: 2.351082 (2.395998)	data_time: 0.001220 (0.015467)
	loss_fool: 0.197945 (0.196178)	loss_train_adv: 0.006423 (0.003036)
	cen_loss: 0.610942 (0.612813)	cls_loss: 0.056038 (0.053679)
	loc_loss: 0.188698 (0.178385)	total_loss: 1.233073 (1.201648)

[2023-05-05 03:18:50,142-rk0-log_helper.py#102] Progress: 8140 / 15625 [52%], Speed: 2.396 s/iter, ETA 0:04:58 (D:H:M)

[2023-05-05 03:19:38,613-rk0-train.py#348] Epoch: [14][35/625] lr: 0.000569
	batch_time: 2.388112 (2.411208)	data_time: 0.001501 (0.015806)
	loss_fool: 0.187146 (0.195861)	loss_train_adv: 0.003870 (0.002842)
	cen_loss: 0.615479 (0.612400)	cls_loss: 0.040826 (0.055043)
	loc_loss: 0.188189 (0.177256)	total_loss: 1.220870 (1.199212)

[2023-05-05 03:19:38,614-rk0-log_helper.py#102] Progress: 8160 / 15625 [52%], Speed: 2.411 s/iter, ETA 0:04:59 (D:H:M)

[2023-05-05 03:20:25,884-rk0-train.py#348] Epoch: [14][55/625] lr: 0.000569
	batch_time: 2.279599 (2.398190)	data_time: 0.001382 (0.015877)
	loss_fool: 0.196993 (0.195985)	loss_train_adv: 0.001091 (0.002673)
	cen_loss: 0.617523 (0.612726)	cls_loss: 0.035195 (0.054464)
	loc_loss: 0.189768 (0.178372)	total_loss: 1.222023 (1.202305)

[2023-05-05 03:20:25,884-rk0-log_helper.py#102] Progress: 8180 / 15625 [52%], Speed: 2.398 s/iter, ETA 0:04:57 (D:H:M)

[2023-05-05 03:21:13,427-rk0-train.py#348] Epoch: [14][75/625] lr: 0.000569
	batch_time: 2.326064 (2.396909)	data_time: 0.001132 (0.016106)
	loss_fool: 0.196413 (0.196204)	loss_train_adv: 0.000459 (0.002698)
	cen_loss: 0.615661 (0.613162)	cls_loss: 0.044147 (0.052048)
	loc_loss: 0.188254 (0.178287)	total_loss: 1.224571 (1.200073)

[2023-05-05 03:21:13,428-rk0-log_helper.py#102] Progress: 8200 / 15625 [52%], Speed: 2.397 s/iter, ETA 0:04:56 (D:H:M)

[2023-05-05 03:22:00,951-rk0-train.py#348] Epoch: [14][95/625] lr: 0.000569
	batch_time: 2.330521 (2.393400)	data_time: 0.001185 (0.016096)
	loss_fool: 0.197436 (0.196273)	loss_train_adv: 0.000129 (0.002448)
	cen_loss: 0.612110 (0.613394)	cls_loss: 0.068774 (0.052597)
	loc_loss: 0.182917 (0.177536)	total_loss: 1.229634 (1.198598)

[2023-05-05 03:22:00,952-rk0-log_helper.py#102] Progress: 8220 / 15625 [52%], Speed: 2.393 s/iter, ETA 0:04:55 (D:H:M)

[2023-05-05 03:22:48,606-rk0-train.py#348] Epoch: [14][115/625] lr: 0.000569
	batch_time: 2.347064 (2.381352)	data_time: 0.001115 (0.002829)
	loss_fool: 0.201956 (0.196446)	loss_train_adv: 0.002424 (0.002390)
	cen_loss: 0.613655 (0.613521)	cls_loss: 0.039375 (0.053255)
	loc_loss: 0.157983 (0.180233)	total_loss: 1.126978 (1.207474)

[2023-05-05 03:22:48,607-rk0-log_helper.py#102] Progress: 8240 / 15625 [52%], Speed: 2.381 s/iter, ETA 0:04:53 (D:H:M)

[2023-05-05 03:23:37,149-rk0-train.py#348] Epoch: [14][135/625] lr: 0.000569
	batch_time: 2.430034 (2.382287)	data_time: 0.001159 (0.002486)
	loss_fool: 0.202393 (0.196840)	loss_train_adv: 0.000666 (0.002086)
	cen_loss: 0.613058 (0.613366)	cls_loss: 0.032297 (0.050678)
	loc_loss: 0.161753 (0.177774)	total_loss: 1.130614 (1.197365)

[2023-05-05 03:23:37,150-rk0-log_helper.py#102] Progress: 8260 / 15625 [52%], Speed: 2.382 s/iter, ETA 0:04:52 (D:H:M)

[2023-05-05 03:24:24,669-rk0-train.py#348] Epoch: [14][155/625] lr: 0.000569
	batch_time: 2.517499 (2.384949)	data_time: 0.001142 (0.002410)
	loss_fool: 0.196692 (0.196870)	loss_train_adv: 0.000352 (0.001959)
	cen_loss: 0.608934 (0.613246)	cls_loss: 0.054193 (0.051001)
	loc_loss: 0.165239 (0.178286)	total_loss: 1.158845 (1.199104)

[2023-05-05 03:24:24,669-rk0-log_helper.py#102] Progress: 8280 / 15625 [52%], Speed: 2.385 s/iter, ETA 0:04:51 (D:H:M)

[2023-05-05 03:25:11,813-rk0-train.py#348] Epoch: [14][175/625] lr: 0.000569
	batch_time: 2.354529 (2.380982)	data_time: 0.001367 (0.002153)
	loss_fool: 0.195006 (0.196637)	loss_train_adv: 0.000200 (0.002015)
	cen_loss: 0.617618 (0.613264)	cls_loss: 0.054718 (0.051267)
	loc_loss: 0.184881 (0.178069)	total_loss: 1.226980 (1.198738)

[2023-05-05 03:25:11,813-rk0-log_helper.py#102] Progress: 8300 / 15625 [53%], Speed: 2.381 s/iter, ETA 0:04:50 (D:H:M)

[2023-05-05 03:25:59,287-rk0-train.py#348] Epoch: [14][195/625] lr: 0.000569
	batch_time: 2.404879 (2.380295)	data_time: 0.001164 (0.002177)
	loss_fool: 0.194715 (0.196900)	loss_train_adv: 0.000639 (0.002017)
	cen_loss: 0.612612 (0.613005)	cls_loss: 0.042612 (0.048694)
	loc_loss: 0.161363 (0.175509)	total_loss: 1.139312 (1.188225)

[2023-05-05 03:25:59,288-rk0-log_helper.py#102] Progress: 8320 / 15625 [53%], Speed: 2.380 s/iter, ETA 0:04:49 (D:H:M)

[2023-05-05 03:26:48,691-rk0-train.py#348] Epoch: [14][215/625] lr: 0.000569
	batch_time: 2.338398 (2.397833)	data_time: 0.001181 (0.001931)
	loss_fool: 0.193266 (0.196789)	loss_train_adv: 0.000180 (0.002078)
	cen_loss: 0.611354 (0.613177)	cls_loss: 0.049499 (0.048261)
	loc_loss: 0.171653 (0.176492)	total_loss: 1.175812 (1.190912)

[2023-05-05 03:26:48,692-rk0-log_helper.py#102] Progress: 8340 / 15625 [53%], Speed: 2.398 s/iter, ETA 0:04:51 (D:H:M)

[2023-05-05 03:27:36,149-rk0-train.py#348] Epoch: [14][235/625] lr: 0.000569
	batch_time: 2.367775 (2.387200)	data_time: 0.001150 (0.002047)
	loss_fool: 0.200478 (0.196565)	loss_train_adv: 0.002339 (0.002172)
	cen_loss: 0.614703 (0.613433)	cls_loss: 0.051730 (0.048631)
	loc_loss: 0.193605 (0.177199)	total_loss: 1.247249 (1.193662)

[2023-05-05 03:27:36,150-rk0-log_helper.py#102] Progress: 8360 / 15625 [53%], Speed: 2.387 s/iter, ETA 0:04:49 (D:H:M)

[2023-05-05 03:28:23,571-rk0-train.py#348] Epoch: [14][255/625] lr: 0.000569
	batch_time: 2.424723 (2.386173)	data_time: 0.001192 (0.002044)
	loss_fool: 0.198589 (0.196864)	loss_train_adv: 0.003082 (0.002238)
	cen_loss: 0.617680 (0.613063)	cls_loss: 0.034820 (0.048848)
	loc_loss: 0.161776 (0.175335)	total_loss: 1.137827 (1.187915)

[2023-05-05 03:28:23,572-rk0-log_helper.py#102] Progress: 8380 / 15625 [53%], Speed: 2.386 s/iter, ETA 0:04:48 (D:H:M)

[2023-05-05 03:29:10,976-rk0-train.py#348] Epoch: [14][275/625] lr: 0.000569
	batch_time: 2.383584 (2.388654)	data_time: 0.001189 (0.002055)
	loss_fool: 0.183449 (0.196287)	loss_train_adv: 0.006344 (0.002346)
	cen_loss: 0.614780 (0.612588)	cls_loss: 0.049965 (0.047795)
	loc_loss: 0.157518 (0.175166)	total_loss: 1.137299 (1.185881)

[2023-05-05 03:29:10,976-rk0-log_helper.py#102] Progress: 8400 / 15625 [53%], Speed: 2.389 s/iter, ETA 0:04:47 (D:H:M)

[2023-05-05 03:29:58,229-rk0-train.py#348] Epoch: [14][295/625] lr: 0.000569
	batch_time: 2.330228 (2.386522)	data_time: 0.001141 (0.001946)
	loss_fool: 0.189949 (0.196434)	loss_train_adv: 0.004468 (0.002805)
	cen_loss: 0.611217 (0.612839)	cls_loss: 0.031722 (0.048949)
	loc_loss: 0.160524 (0.177855)	total_loss: 1.124509 (1.195353)

[2023-05-05 03:29:58,230-rk0-log_helper.py#102] Progress: 8420 / 15625 [53%], Speed: 2.387 s/iter, ETA 0:04:46 (D:H:M)

[2023-05-05 03:30:45,799-rk0-train.py#348] Epoch: [14][315/625] lr: 0.000569
	batch_time: 2.295410 (2.368151)	data_time: 0.001132 (0.001830)
	loss_fool: 0.198937 (0.196093)	loss_train_adv: 0.001207 (0.002872)
	cen_loss: 0.612929 (0.612983)	cls_loss: 0.035143 (0.049302)
	loc_loss: 0.159868 (0.176400)	total_loss: 1.127676 (1.191484)

[2023-05-05 03:30:45,800-rk0-log_helper.py#102] Progress: 8440 / 15625 [54%], Speed: 2.368 s/iter, ETA 0:04:43 (D:H:M)

[2023-05-05 03:31:33,873-rk0-train.py#348] Epoch: [14][335/625] lr: 0.000569
	batch_time: 2.345507 (2.374273)	data_time: 0.001410 (0.001632)
	loss_fool: 0.199499 (0.196163)	loss_train_adv: 0.000589 (0.002868)
	cen_loss: 0.611075 (0.613195)	cls_loss: 0.050637 (0.050027)
	loc_loss: 0.222532 (0.178448)	total_loss: 1.329308 (1.198566)

[2023-05-05 03:31:33,874-rk0-log_helper.py#102] Progress: 8460 / 15625 [54%], Speed: 2.374 s/iter, ETA 0:04:43 (D:H:M)

[2023-05-05 03:32:22,415-rk0-train.py#348] Epoch: [14][355/625] lr: 0.000569
	batch_time: 2.335148 (2.385455)	data_time: 0.001429 (0.001433)
	loss_fool: 0.197360 (0.196048)	loss_train_adv: 0.002620 (0.002693)
	cen_loss: 0.611703 (0.613458)	cls_loss: 0.045034 (0.049827)
	loc_loss: 0.180518 (0.179549)	total_loss: 1.198290 (1.201932)

[2023-05-05 03:32:22,415-rk0-log_helper.py#102] Progress: 8480 / 15625 [54%], Speed: 2.385 s/iter, ETA 0:04:44 (D:H:M)

[2023-05-05 03:33:09,783-rk0-train.py#348] Epoch: [14][375/625] lr: 0.000569
	batch_time: 2.464403 (2.385303)	data_time: 0.001217 (0.001584)
	loss_fool: 0.205523 (0.196703)	loss_train_adv: 0.000140 (0.002518)
	cen_loss: 0.613584 (0.613789)	cls_loss: 0.056308 (0.050664)
	loc_loss: 0.191458 (0.180511)	total_loss: 1.244267 (1.205987)

[2023-05-05 03:33:09,784-rk0-log_helper.py#102] Progress: 8500 / 15625 [54%], Speed: 2.385 s/iter, ETA 0:04:43 (D:H:M)

[2023-05-05 03:33:57,338-rk0-train.py#348] Epoch: [14][395/625] lr: 0.000569
	batch_time: 2.425622 (2.388329)	data_time: 0.001389 (0.002164)
	loss_fool: 0.212314 (0.196321)	loss_train_adv: 0.000571 (0.002577)
	cen_loss: 0.609204 (0.613403)	cls_loss: 0.076752 (0.050978)
	loc_loss: 0.170717 (0.180023)	total_loss: 1.198105 (1.204450)

[2023-05-05 03:33:57,339-rk0-log_helper.py#102] Progress: 8520 / 15625 [54%], Speed: 2.388 s/iter, ETA 0:04:42 (D:H:M)

[2023-05-05 03:34:45,038-rk0-train.py#348] Epoch: [14][415/625] lr: 0.000569
	batch_time: 2.323134 (2.389704)	data_time: 0.001217 (0.002330)
	loss_fool: 0.163472 (0.195419)	loss_train_adv: 0.007841 (0.003028)
	cen_loss: 0.607569 (0.613050)	cls_loss: 0.034319 (0.049717)
	loc_loss: 0.165437 (0.178990)	total_loss: 1.138198 (1.199738)

[2023-05-05 03:34:45,039-rk0-log_helper.py#102] Progress: 8540 / 15625 [54%], Speed: 2.390 s/iter, ETA 0:04:42 (D:H:M)

[2023-05-05 03:35:32,546-rk0-train.py#348] Epoch: [14][435/625] lr: 0.000569
	batch_time: 2.375214 (2.383986)	data_time: 0.001384 (0.002464)
	loss_fool: 0.201501 (0.195492)	loss_train_adv: 0.004912 (0.003234)
	cen_loss: 0.616506 (0.613187)	cls_loss: 0.048546 (0.048876)
	loc_loss: 0.176336 (0.176828)	total_loss: 1.194059 (1.192547)

[2023-05-05 03:35:32,547-rk0-log_helper.py#102] Progress: 8560 / 15625 [54%], Speed: 2.384 s/iter, ETA 0:04:40 (D:H:M)

[2023-05-05 03:36:20,423-rk0-train.py#348] Epoch: [14][455/625] lr: 0.000569
	batch_time: 2.410962 (2.377296)	data_time: 0.001200 (0.002493)
	loss_fool: 0.193707 (0.195390)	loss_train_adv: 0.000573 (0.003363)
	cen_loss: 0.609232 (0.613068)	cls_loss: 0.051990 (0.048771)
	loc_loss: 0.202497 (0.177265)	total_loss: 1.268713 (1.193636)

[2023-05-05 03:36:20,424-rk0-log_helper.py#102] Progress: 8580 / 15625 [54%], Speed: 2.377 s/iter, ETA 0:04:39 (D:H:M)

[2023-05-05 03:37:07,684-rk0-train.py#348] Epoch: [14][475/625] lr: 0.000569
	batch_time: 2.557943 (2.376286)	data_time: 0.001626 (0.002554)
	loss_fool: 0.195524 (0.194642)	loss_train_adv: 0.000544 (0.003563)
	cen_loss: 0.609130 (0.613132)	cls_loss: 0.043839 (0.048951)
	loc_loss: 0.164098 (0.175989)	total_loss: 1.145264 (1.190050)

[2023-05-05 03:37:07,685-rk0-log_helper.py#102] Progress: 8600 / 15625 [55%], Speed: 2.376 s/iter, ETA 0:04:38 (D:H:M)

[2023-05-05 03:37:55,435-rk0-train.py#348] Epoch: [14][495/625] lr: 0.000569
	batch_time: 2.395934 (2.378277)	data_time: 0.001187 (0.002113)
	loss_fool: 0.198629 (0.195086)	loss_train_adv: 0.002948 (0.003306)
	cen_loss: 0.610772 (0.613513)	cls_loss: 0.040981 (0.049271)
	loc_loss: 0.147740 (0.176750)	total_loss: 1.094975 (1.193035)

[2023-05-05 03:37:55,435-rk0-log_helper.py#102] Progress: 8620 / 15625 [55%], Speed: 2.378 s/iter, ETA 0:04:37 (D:H:M)

[2023-05-05 03:38:43,266-rk0-train.py#348] Epoch: [14][515/625] lr: 0.000569
	batch_time: 2.384982 (2.379835)	data_time: 0.001384 (0.001961)
	loss_fool: 0.184153 (0.195888)	loss_train_adv: 0.002774 (0.002881)
	cen_loss: 0.607065 (0.613999)	cls_loss: 0.031534 (0.050914)
	loc_loss: 0.166965 (0.178480)	total_loss: 1.139493 (1.200351)

[2023-05-05 03:38:43,267-rk0-log_helper.py#102] Progress: 8640 / 15625 [55%], Speed: 2.380 s/iter, ETA 0:04:37 (D:H:M)

[2023-05-05 03:39:31,315-rk0-train.py#348] Epoch: [14][535/625] lr: 0.000569
	batch_time: 2.388926 (2.385209)	data_time: 0.001263 (0.001942)
	loss_fool: 0.188374 (0.195982)	loss_train_adv: 0.003826 (0.002520)
	cen_loss: 0.612017 (0.613768)	cls_loss: 0.036856 (0.051661)
	loc_loss: 0.163779 (0.179279)	total_loss: 1.140209 (1.203266)

[2023-05-05 03:39:31,316-rk0-log_helper.py#102] Progress: 8660 / 15625 [55%], Speed: 2.385 s/iter, ETA 0:04:36 (D:H:M)

[2023-05-05 03:40:19,355-rk0-train.py#348] Epoch: [14][555/625] lr: 0.000569
	batch_time: 2.405687 (2.386769)	data_time: 0.001116 (0.001978)
	loss_fool: 0.201462 (0.196336)	loss_train_adv: 0.000849 (0.002404)
	cen_loss: 0.616360 (0.613571)	cls_loss: 0.048430 (0.051190)
	loc_loss: 0.209920 (0.178368)	total_loss: 1.294549 (1.199865)

[2023-05-05 03:40:19,356-rk0-log_helper.py#102] Progress: 8680 / 15625 [55%], Speed: 2.387 s/iter, ETA 0:04:36 (D:H:M)

[2023-05-05 03:41:06,798-rk0-train.py#348] Epoch: [14][575/625] lr: 0.000569
	batch_time: 2.311785 (2.388311)	data_time: 0.001397 (0.001765)
	loss_fool: 0.195013 (0.196868)	loss_train_adv: 0.007577 (0.002283)
	cen_loss: 0.611604 (0.613477)	cls_loss: 0.046597 (0.053163)
	loc_loss: 0.162845 (0.178689)	total_loss: 1.146737 (1.202707)

[2023-05-05 03:41:06,798-rk0-log_helper.py#102] Progress: 8700 / 15625 [55%], Speed: 2.388 s/iter, ETA 0:04:35 (D:H:M)

[2023-05-05 03:41:55,931-rk0-train.py#348] Epoch: [14][595/625] lr: 0.000569
	batch_time: 2.850234 (2.401969)	data_time: 0.001108 (0.001766)
	loss_fool: 0.194225 (0.196395)	loss_train_adv: 0.003135 (0.002442)
	cen_loss: 0.613129 (0.613345)	cls_loss: 0.037892 (0.053759)
	loc_loss: 0.191468 (0.178886)	total_loss: 1.225426 (1.203762)

[2023-05-05 03:41:55,931-rk0-log_helper.py#102] Progress: 8720 / 15625 [55%], Speed: 2.402 s/iter, ETA 0:04:36 (D:H:M)

[2023-05-05 03:42:43,648-rk0-train.py#348] Epoch: [14][615/625] lr: 0.000569
	batch_time: 2.406939 (2.400549)	data_time: 0.001302 (0.001636)
	loss_fool: 0.210999 (0.196642)	loss_train_adv: 0.004923 (0.002386)
	cen_loss: 0.609907 (0.612857)	cls_loss: 0.050634 (0.052429)
	loc_loss: 0.187616 (0.177669)	total_loss: 1.223389 (1.198294)

[2023-05-05 03:42:43,648-rk0-log_helper.py#102] Progress: 8740 / 15625 [55%], Speed: 2.401 s/iter, ETA 0:04:35 (D:H:M)

[2023-05-05 03:43:08,833-rk0-train.py#235] epoch: 15
[2023-05-05 03:43:08,833-rk0-train.py#240] epoch 15 lr 5.039727429425672e-05
[2023-05-05 03:43:08,834-rk0-train.py#240] epoch 15 lr 0.0005039727429425672
[2023-05-05 03:43:08,834-rk0-train.py#240] epoch 15 lr 0.0016799091431418903
[2023-05-05 03:43:08,835-rk0-train.py#240] epoch 15 lr 0.0005039727429425672
[2023-05-05 03:43:08,835-rk0-train.py#240] epoch 15 lr 0.0005039727429425672
[2023-05-05 03:43:32,569-rk0-train.py#348] Epoch: [15][10/625] lr: 0.000504
	batch_time: 2.369934 (2.409424)	data_time: 0.001144 (0.015728)
	loss_fool: 0.183690 (0.196366)	loss_train_adv: 0.004306 (0.002535)
	cen_loss: 0.614711 (0.612894)	cls_loss: 0.046125 (0.052247)
	loc_loss: 0.181689 (0.177575)	total_loss: 1.205904 (1.197865)

[2023-05-05 03:43:32,569-rk0-log_helper.py#102] Progress: 8760 / 15625 [56%], Speed: 2.409 s/iter, ETA 0:04:35 (D:H:M)

[2023-05-05 03:44:22,791-rk0-train.py#348] Epoch: [15][30/625] lr: 0.000504
	batch_time: 2.942689 (2.431246)	data_time: 0.002368 (0.016186)
	loss_fool: 0.199137 (0.195488)	loss_train_adv: 0.003531 (0.002806)
	cen_loss: 0.619780 (0.613381)	cls_loss: 0.053093 (0.052522)
	loc_loss: 0.185133 (0.177548)	total_loss: 1.228273 (1.198546)

[2023-05-05 03:44:22,792-rk0-log_helper.py#102] Progress: 8780 / 15625 [56%], Speed: 2.431 s/iter, ETA 0:04:37 (D:H:M)

[2023-05-05 03:45:10,869-rk0-train.py#348] Epoch: [15][50/625] lr: 0.000504
	batch_time: 2.372017 (2.437715)	data_time: 0.001144 (0.016279)
	loss_fool: 0.206660 (0.196006)	loss_train_adv: 0.000130 (0.003038)
	cen_loss: 0.612563 (0.613572)	cls_loss: 0.037999 (0.050769)
	loc_loss: 0.166185 (0.178020)	total_loss: 1.149118 (1.198402)

[2023-05-05 03:45:10,871-rk0-log_helper.py#102] Progress: 8800 / 15625 [56%], Speed: 2.438 s/iter, ETA 0:04:37 (D:H:M)

[2023-05-05 03:45:59,051-rk0-train.py#348] Epoch: [15][70/625] lr: 0.000504
	batch_time: 2.284646 (2.428477)	data_time: 0.001127 (0.016191)
	loss_fool: 0.188350 (0.196012)	loss_train_adv: 0.003730 (0.002709)
	cen_loss: 0.618147 (0.613599)	cls_loss: 0.039349 (0.048973)
	loc_loss: 0.184750 (0.178026)	total_loss: 1.211746 (1.196649)

[2023-05-05 03:45:59,052-rk0-log_helper.py#102] Progress: 8820 / 15625 [56%], Speed: 2.428 s/iter, ETA 0:04:35 (D:H:M)

[2023-05-05 03:46:46,911-rk0-train.py#348] Epoch: [15][90/625] lr: 0.000504
	batch_time: 2.387677 (2.429930)	data_time: 0.001186 (0.016139)
	loss_fool: 0.189733 (0.196076)	loss_train_adv: 0.000448 (0.002639)
	cen_loss: 0.615485 (0.613221)	cls_loss: 0.042750 (0.049827)
	loc_loss: 0.175619 (0.178630)	total_loss: 1.185093 (1.198939)

[2023-05-05 03:46:46,912-rk0-log_helper.py#102] Progress: 8840 / 15625 [56%], Speed: 2.430 s/iter, ETA 0:04:34 (D:H:M)

[2023-05-05 03:47:33,922-rk0-train.py#348] Epoch: [15][110/625] lr: 0.000504
	batch_time: 2.275854 (2.410834)	data_time: 0.001261 (0.002017)
	loss_fool: 0.193560 (0.196380)	loss_train_adv: 0.000841 (0.002536)
	cen_loss: 0.612331 (0.613268)	cls_loss: 0.040799 (0.049473)
	loc_loss: 0.182161 (0.178991)	total_loss: 1.199612 (1.199713)

[2023-05-05 03:47:33,923-rk0-log_helper.py#102] Progress: 8860 / 15625 [56%], Speed: 2.411 s/iter, ETA 0:04:31 (D:H:M)

[2023-05-05 03:48:21,383-rk0-train.py#348] Epoch: [15][130/625] lr: 0.000504
	batch_time: 2.467157 (2.383071)	data_time: 0.001246 (0.001883)
	loss_fool: 0.199737 (0.196893)	loss_train_adv: 0.006449 (0.002469)
	cen_loss: 0.613608 (0.612986)	cls_loss: 0.058054 (0.049811)
	loc_loss: 0.207617 (0.178033)	total_loss: 1.294512 (1.196896)

[2023-05-05 03:48:21,383-rk0-log_helper.py#102] Progress: 8880 / 15625 [56%], Speed: 2.383 s/iter, ETA 0:04:27 (D:H:M)

[2023-05-05 03:49:08,720-rk0-train.py#348] Epoch: [15][150/625] lr: 0.000504
	batch_time: 2.311158 (2.375586)	data_time: 0.001286 (0.001995)
	loss_fool: 0.198088 (0.196768)	loss_train_adv: 0.000309 (0.002314)
	cen_loss: 0.606745 (0.613003)	cls_loss: 0.043855 (0.048447)
	loc_loss: 0.169391 (0.176609)	total_loss: 1.158772 (1.191279)

[2023-05-05 03:49:08,721-rk0-log_helper.py#102] Progress: 8900 / 15625 [56%], Speed: 2.376 s/iter, ETA 0:04:26 (D:H:M)

[2023-05-05 03:49:56,763-rk0-train.py#348] Epoch: [15][170/625] lr: 0.000504
	batch_time: 2.522480 (2.373993)	data_time: 0.001546 (0.001964)
	loss_fool: 0.194584 (0.196561)	loss_train_adv: 0.000341 (0.002529)
	cen_loss: 0.612211 (0.612830)	cls_loss: 0.047232 (0.048503)
	loc_loss: 0.170337 (0.175653)	total_loss: 1.170453 (1.188292)

[2023-05-05 03:49:56,764-rk0-log_helper.py#102] Progress: 8920 / 15625 [57%], Speed: 2.374 s/iter, ETA 0:04:25 (D:H:M)

[2023-05-05 03:50:45,410-rk0-train.py#348] Epoch: [15][190/625] lr: 0.000504
	batch_time: 2.316638 (2.382050)	data_time: 0.001390 (0.002101)
	loss_fool: 0.191276 (0.196770)	loss_train_adv: 0.002455 (0.002498)
	cen_loss: 0.610025 (0.613287)	cls_loss: 0.031779 (0.049358)
	loc_loss: 0.170452 (0.174278)	total_loss: 1.153161 (1.185478)

[2023-05-05 03:50:45,410-rk0-log_helper.py#102] Progress: 8940 / 15625 [57%], Speed: 2.382 s/iter, ETA 0:04:25 (D:H:M)

[2023-05-05 03:51:32,853-rk0-train.py#348] Epoch: [15][210/625] lr: 0.000504
	batch_time: 2.428670 (2.386245)	data_time: 0.000603 (0.002507)
	loss_fool: 0.187829 (0.196576)	loss_train_adv: 0.001569 (0.002591)
	cen_loss: 0.616312 (0.613432)	cls_loss: 0.043011 (0.051280)
	loc_loss: 0.151962 (0.175559)	total_loss: 1.115209 (1.191389)

[2023-05-05 03:51:32,854-rk0-log_helper.py#102] Progress: 8960 / 15625 [57%], Speed: 2.386 s/iter, ETA 0:04:25 (D:H:M)

[2023-05-05 03:52:20,407-rk0-train.py#348] Epoch: [15][230/625] lr: 0.000504
	batch_time: 2.373781 (2.387125)	data_time: 0.001316 (0.002336)
	loss_fool: 0.197739 (0.196435)	loss_train_adv: 0.002810 (0.002709)
	cen_loss: 0.620914 (0.613699)	cls_loss: 0.036983 (0.050754)
	loc_loss: 0.173376 (0.177340)	total_loss: 1.178025 (1.196474)

[2023-05-05 03:52:20,409-rk0-log_helper.py#102] Progress: 8980 / 15625 [57%], Speed: 2.387 s/iter, ETA 0:04:24 (D:H:M)

[2023-05-05 03:53:08,265-rk0-train.py#348] Epoch: [15][250/625] lr: 0.000504
	batch_time: 2.781083 (2.392315)	data_time: 0.002459 (0.002321)
	loss_fool: 0.192921 (0.195563)	loss_train_adv: 0.003588 (0.003099)
	cen_loss: 0.614063 (0.613544)	cls_loss: 0.054400 (0.051469)
	loc_loss: 0.181323 (0.177049)	total_loss: 1.212432 (1.196161)

[2023-05-05 03:53:08,265-rk0-log_helper.py#102] Progress: 9000 / 15625 [57%], Speed: 2.392 s/iter, ETA 0:04:24 (D:H:M)

[2023-05-05 03:53:55,459-rk0-train.py#348] Epoch: [15][270/625] lr: 0.000504
	batch_time: 2.309700 (2.383698)	data_time: 0.001189 (0.002409)
	loss_fool: 0.198685 (0.194763)	loss_train_adv: 0.001816 (0.003496)
	cen_loss: 0.613713 (0.613719)	cls_loss: 0.042690 (0.051786)
	loc_loss: 0.174941 (0.176863)	total_loss: 1.181227 (1.196094)

[2023-05-05 03:53:55,459-rk0-log_helper.py#102] Progress: 9020 / 15625 [57%], Speed: 2.384 s/iter, ETA 0:04:22 (D:H:M)

[2023-05-05 03:54:42,735-rk0-train.py#348] Epoch: [15][290/625] lr: 0.000504
	batch_time: 2.415189 (2.369991)	data_time: 0.001184 (0.002324)
	loss_fool: 0.194343 (0.194293)	loss_train_adv: 0.003065 (0.003745)
	cen_loss: 0.618514 (0.613998)	cls_loss: 0.046283 (0.051384)
	loc_loss: 0.173611 (0.177659)	total_loss: 1.185629 (1.198358)

[2023-05-05 03:54:42,736-rk0-log_helper.py#102] Progress: 9040 / 15625 [57%], Speed: 2.370 s/iter, ETA 0:04:20 (D:H:M)

[2023-05-05 03:55:30,449-rk0-train.py#348] Epoch: [15][310/625] lr: 0.000504
	batch_time: 2.325629 (2.372543)	data_time: 0.001199 (0.001891)
	loss_fool: 0.191635 (0.194483)	loss_train_adv: 0.001804 (0.003658)
	cen_loss: 0.609188 (0.613739)	cls_loss: 0.049454 (0.049589)
	loc_loss: 0.155151 (0.177540)	total_loss: 1.124094 (1.195949)

[2023-05-05 03:55:30,450-rk0-log_helper.py#102] Progress: 9060 / 15625 [57%], Speed: 2.373 s/iter, ETA 0:04:19 (D:H:M)

[2023-05-05 03:56:17,643-rk0-train.py#348] Epoch: [15][330/625] lr: 0.000504
	batch_time: 2.377711 (2.369200)	data_time: 0.001170 (0.001692)
	loss_fool: 0.193236 (0.194786)	loss_train_adv: 0.000699 (0.003443)
	cen_loss: 0.606614 (0.613288)	cls_loss: 0.047463 (0.050087)
	loc_loss: 0.177274 (0.175825)	total_loss: 1.185900 (1.190850)

[2023-05-05 03:56:17,644-rk0-log_helper.py#102] Progress: 9080 / 15625 [58%], Speed: 2.369 s/iter, ETA 0:04:18 (D:H:M)

[2023-05-05 03:57:05,972-rk0-train.py#348] Epoch: [15][350/625] lr: 0.000504
	batch_time: 2.435301 (2.373743)	data_time: 0.000623 (0.001578)
	loss_fool: 0.194855 (0.195204)	loss_train_adv: 0.003543 (0.002953)
	cen_loss: 0.612575 (0.613001)	cls_loss: 0.046228 (0.050018)
	loc_loss: 0.180325 (0.176379)	total_loss: 1.199777 (1.192155)

[2023-05-05 03:57:05,973-rk0-log_helper.py#102] Progress: 9100 / 15625 [58%], Speed: 2.374 s/iter, ETA 0:04:18 (D:H:M)

[2023-05-05 03:57:53,627-rk0-train.py#348] Epoch: [15][370/625] lr: 0.000504
	batch_time: 2.337876 (2.378218)	data_time: 0.001186 (0.001522)
	loss_fool: 0.198820 (0.196529)	loss_train_adv: 0.001693 (0.002334)
	cen_loss: 0.606656 (0.613174)	cls_loss: 0.062391 (0.051385)
	loc_loss: 0.154052 (0.178276)	total_loss: 1.131203 (1.199385)

[2023-05-05 03:57:53,628-rk0-log_helper.py#102] Progress: 9120 / 15625 [58%], Speed: 2.378 s/iter, ETA 0:04:17 (D:H:M)

[2023-05-05 03:58:41,328-rk0-train.py#348] Epoch: [15][390/625] lr: 0.000504
	batch_time: 2.414797 (2.382331)	data_time: 0.001153 (0.001622)
	loss_fool: 0.193668 (0.196966)	loss_train_adv: 0.003722 (0.002216)
	cen_loss: 0.615889 (0.613044)	cls_loss: 0.050807 (0.051526)
	loc_loss: 0.191725 (0.179458)	total_loss: 1.241871 (1.202945)

[2023-05-05 03:58:41,328-rk0-log_helper.py#102] Progress: 9140 / 15625 [58%], Speed: 2.382 s/iter, ETA 0:04:17 (D:H:M)

[2023-05-05 03:59:29,247-rk0-train.py#348] Epoch: [15][410/625] lr: 0.000504
	batch_time: 2.424925 (2.384668)	data_time: 0.001207 (0.001745)
	loss_fool: 0.194405 (0.196877)	loss_train_adv: 0.001227 (0.002243)
	cen_loss: 0.608443 (0.612944)	cls_loss: 0.043602 (0.051390)
	loc_loss: 0.187532 (0.177982)	total_loss: 1.214639 (1.198280)

[2023-05-05 03:59:29,248-rk0-log_helper.py#102] Progress: 9160 / 15625 [58%], Speed: 2.385 s/iter, ETA 0:04:16 (D:H:M)

[2023-05-05 04:00:17,787-rk0-train.py#348] Epoch: [15][430/625] lr: 0.000504
	batch_time: 2.514356 (2.398178)	data_time: 0.001084 (0.001828)
	loss_fool: 0.198963 (0.196405)	loss_train_adv: 0.001645 (0.002234)
	cen_loss: 0.608364 (0.612970)	cls_loss: 0.049841 (0.050740)
	loc_loss: 0.192963 (0.178055)	total_loss: 1.237094 (1.197874)

[2023-05-05 04:00:17,787-rk0-log_helper.py#102] Progress: 9180 / 15625 [58%], Speed: 2.398 s/iter, ETA 0:04:17 (D:H:M)

[2023-05-05 04:01:06,518-rk0-train.py#348] Epoch: [15][450/625] lr: 0.000504
	batch_time: 2.346008 (2.402475)	data_time: 0.001243 (0.001753)
	loss_fool: 0.195263 (0.197005)	loss_train_adv: 0.000253 (0.002292)
	cen_loss: 0.616403 (0.613141)	cls_loss: 0.049418 (0.050327)
	loc_loss: 0.175419 (0.177521)	total_loss: 1.192078 (1.196030)

[2023-05-05 04:01:06,519-rk0-log_helper.py#102] Progress: 9200 / 15625 [58%], Speed: 2.402 s/iter, ETA 0:04:17 (D:H:M)

[2023-05-05 04:01:54,404-rk0-train.py#348] Epoch: [15][470/625] lr: 0.000504
	batch_time: 2.294360 (2.405142)	data_time: 0.001175 (0.001764)
	loss_fool: 0.201288 (0.196305)	loss_train_adv: 0.001046 (0.002595)
	cen_loss: 0.614036 (0.613024)	cls_loss: 0.053477 (0.048844)
	loc_loss: 0.189474 (0.176048)	total_loss: 1.235937 (1.190013)

[2023-05-05 04:01:54,405-rk0-log_helper.py#102] Progress: 9220 / 15625 [59%], Speed: 2.405 s/iter, ETA 0:04:16 (D:H:M)

[2023-05-05 04:02:42,272-rk0-train.py#348] Epoch: [15][490/625] lr: 0.000504
	batch_time: 2.447748 (2.406787)	data_time: 0.001010 (0.001915)
	loss_fool: 0.191048 (0.195380)	loss_train_adv: 0.006651 (0.002801)
	cen_loss: 0.614710 (0.612940)	cls_loss: 0.034399 (0.048312)
	loc_loss: 0.145173 (0.175460)	total_loss: 1.084627 (1.187633)

[2023-05-05 04:02:42,273-rk0-log_helper.py#102] Progress: 9240 / 15625 [59%], Speed: 2.407 s/iter, ETA 0:04:16 (D:H:M)

[2023-05-05 04:03:30,448-rk0-train.py#348] Epoch: [15][510/625] lr: 0.000504
	batch_time: 2.463152 (2.409062)	data_time: 0.001193 (0.001920)
	loss_fool: 0.209333 (0.195667)	loss_train_adv: 0.005591 (0.003105)
	cen_loss: 0.611820 (0.612997)	cls_loss: 0.129472 (0.051267)
	loc_loss: 0.176183 (0.176098)	total_loss: 1.269841 (1.192557)

[2023-05-05 04:03:30,449-rk0-log_helper.py#102] Progress: 9260 / 15625 [59%], Speed: 2.409 s/iter, ETA 0:04:15 (D:H:M)

[2023-05-05 04:04:18,338-rk0-train.py#348] Epoch: [15][530/625] lr: 0.000504
	batch_time: 2.365587 (2.402270)	data_time: 0.001327 (0.002050)
	loss_fool: 0.189439 (0.195250)	loss_train_adv: 0.005013 (0.003280)
	cen_loss: 0.601348 (0.613042)	cls_loss: 0.040746 (0.051193)
	loc_loss: 0.145781 (0.176203)	total_loss: 1.079437 (1.192843)

[2023-05-05 04:04:18,339-rk0-log_helper.py#102] Progress: 9280 / 15625 [59%], Speed: 2.402 s/iter, ETA 0:04:14 (D:H:M)

[2023-05-05 04:05:05,587-rk0-train.py#348] Epoch: [15][550/625] lr: 0.000504
	batch_time: 2.423609 (2.387593)	data_time: 0.001531 (0.002046)
	loss_fool: 0.195292 (0.195424)	loss_train_adv: 0.001393 (0.003218)
	cen_loss: 0.609197 (0.613144)	cls_loss: 0.082984 (0.051933)
	loc_loss: 0.198884 (0.175694)	total_loss: 1.288832 (1.192158)

[2023-05-05 04:05:05,587-rk0-log_helper.py#102] Progress: 9300 / 15625 [59%], Speed: 2.388 s/iter, ETA 0:04:11 (D:H:M)

[2023-05-05 04:05:53,632-rk0-train.py#348] Epoch: [15][570/625] lr: 0.000504
	batch_time: 2.418353 (2.388734)	data_time: 0.001640 (0.002188)
	loss_fool: 0.188938 (0.195618)	loss_train_adv: 0.001400 (0.003009)
	cen_loss: 0.610855 (0.612925)	cls_loss: 0.035514 (0.051579)
	loc_loss: 0.164549 (0.172707)	total_loss: 1.140015 (1.182624)

[2023-05-05 04:05:53,633-rk0-log_helper.py#102] Progress: 9320 / 15625 [59%], Speed: 2.389 s/iter, ETA 0:04:11 (D:H:M)

[2023-05-05 04:06:41,946-rk0-train.py#348] Epoch: [15][590/625] lr: 0.000504
	batch_time: 2.505330 (2.393224)	data_time: 0.015407 (0.002024)
	loss_fool: 0.195403 (0.196581)	loss_train_adv: 0.000452 (0.002615)
	cen_loss: 0.614632 (0.612959)	cls_loss: 0.050794 (0.051830)
	loc_loss: 0.173593 (0.172663)	total_loss: 1.186205 (1.182778)

[2023-05-05 04:06:41,947-rk0-log_helper.py#102] Progress: 9340 / 15625 [59%], Speed: 2.393 s/iter, ETA 0:04:10 (D:H:M)

[2023-05-05 04:07:29,111-rk0-train.py#348] Epoch: [15][610/625] lr: 0.000504
	batch_time: 2.337617 (2.383199)	data_time: 0.001118 (0.001795)
	loss_fool: 0.182550 (0.196588)	loss_train_adv: 0.006450 (0.002356)
	cen_loss: 0.607055 (0.613174)	cls_loss: 0.039453 (0.049574)
	loc_loss: 0.177888 (0.172432)	total_loss: 1.180171 (1.180044)

[2023-05-05 04:07:29,112-rk0-log_helper.py#102] Progress: 9360 / 15625 [59%], Speed: 2.383 s/iter, ETA 0:04:08 (D:H:M)

[2023-05-05 04:08:06,521-rk0-train.py#235] epoch: 16
[2023-05-05 04:08:06,522-rk0-train.py#240] epoch 16 lr 4.4645271624469794e-05
[2023-05-05 04:08:06,522-rk0-train.py#240] epoch 16 lr 0.0004464527162446979
[2023-05-05 04:08:06,523-rk0-train.py#240] epoch 16 lr 0.0014881757208156598
[2023-05-05 04:08:06,523-rk0-train.py#240] epoch 16 lr 0.0004464527162446979
[2023-05-05 04:08:06,524-rk0-train.py#240] epoch 16 lr 0.0004464527162446979
[2023-05-05 04:08:18,349-rk0-train.py#348] Epoch: [16][5/625] lr: 0.000446
	batch_time: 2.342561 (2.396848)	data_time: 0.001190 (0.015705)
	loss_fool: 0.204020 (0.197225)	loss_train_adv: 0.002553 (0.002155)
	cen_loss: 0.617541 (0.613216)	cls_loss: 0.059128 (0.050351)
	loc_loss: 0.177091 (0.173499)	total_loss: 1.207941 (1.184063)

[2023-05-05 04:08:18,350-rk0-log_helper.py#102] Progress: 9380 / 15625 [60%], Speed: 2.397 s/iter, ETA 0:04:09 (D:H:M)

[2023-05-05 04:09:06,851-rk0-train.py#348] Epoch: [16][25/625] lr: 0.000446
	batch_time: 2.417956 (2.408776)	data_time: 0.001289 (0.015859)
	loss_fool: 0.194100 (0.196693)	loss_train_adv: 0.000169 (0.002196)
	cen_loss: 0.619003 (0.613205)	cls_loss: 0.037603 (0.049328)
	loc_loss: 0.180551 (0.175214)	total_loss: 1.198258 (1.188174)

[2023-05-05 04:09:06,852-rk0-log_helper.py#102] Progress: 9400 / 15625 [60%], Speed: 2.409 s/iter, ETA 0:04:09 (D:H:M)

[2023-05-05 04:09:53,959-rk0-train.py#348] Epoch: [16][45/625] lr: 0.000446
	batch_time: 2.318197 (2.399652)	data_time: 0.001255 (0.015756)
	loss_fool: 0.189306 (0.196659)	loss_train_adv: 0.003674 (0.002209)
	cen_loss: 0.613868 (0.613540)	cls_loss: 0.039973 (0.050292)
	loc_loss: 0.176282 (0.177733)	total_loss: 1.182688 (1.197032)

[2023-05-05 04:09:53,960-rk0-log_helper.py#102] Progress: 9420 / 15625 [60%], Speed: 2.400 s/iter, ETA 0:04:08 (D:H:M)

[2023-05-05 04:10:41,658-rk0-train.py#348] Epoch: [16][65/625] lr: 0.000446
	batch_time: 2.336146 (2.393309)	data_time: 0.001603 (0.015710)
	loss_fool: 0.196342 (0.197071)	loss_train_adv: 0.002070 (0.002235)
	cen_loss: 0.610909 (0.613356)	cls_loss: 0.029538 (0.049545)
	loc_loss: 0.168145 (0.177091)	total_loss: 1.144881 (1.194172)

[2023-05-05 04:10:41,658-rk0-log_helper.py#102] Progress: 9440 / 15625 [60%], Speed: 2.393 s/iter, ETA 0:04:06 (D:H:M)

[2023-05-05 04:11:29,503-rk0-train.py#348] Epoch: [16][85/625] lr: 0.000446
	batch_time: 2.446751 (2.400352)	data_time: 0.001319 (0.015805)
	loss_fool: 0.201238 (0.196903)	loss_train_adv: 0.000405 (0.002048)
	cen_loss: 0.608762 (0.613100)	cls_loss: 0.039186 (0.049179)
	loc_loss: 0.141090 (0.175953)	total_loss: 1.071217 (1.190136)

[2023-05-05 04:11:29,504-rk0-log_helper.py#102] Progress: 9460 / 15625 [60%], Speed: 2.400 s/iter, ETA 0:04:06 (D:H:M)

[2023-05-05 04:12:16,700-rk0-train.py#348] Epoch: [16][105/625] lr: 0.000446
	batch_time: 2.307924 (2.379847)	data_time: 0.001289 (0.001666)
	loss_fool: 0.190512 (0.196886)	loss_train_adv: 0.000424 (0.002050)
	cen_loss: 0.614460 (0.613153)	cls_loss: 0.038525 (0.047901)
	loc_loss: 0.162151 (0.174919)	total_loss: 1.139438 (1.185811)

[2023-05-05 04:12:16,701-rk0-log_helper.py#102] Progress: 9480 / 15625 [60%], Speed: 2.380 s/iter, ETA 0:04:03 (D:H:M)

[2023-05-05 04:13:03,692-rk0-train.py#348] Epoch: [16][125/625] lr: 0.000446
	batch_time: 2.370591 (2.365158)	data_time: 0.001261 (0.001521)
	loss_fool: 0.185940 (0.196757)	loss_train_adv: 0.001036 (0.002171)
	cen_loss: 0.612006 (0.613262)	cls_loss: 0.050261 (0.048585)
	loc_loss: 0.173530 (0.174576)	total_loss: 1.182859 (1.185574)

[2023-05-05 04:13:03,693-rk0-log_helper.py#102] Progress: 9500 / 15625 [60%], Speed: 2.365 s/iter, ETA 0:04:01 (D:H:M)

[2023-05-05 04:13:51,696-rk0-train.py#348] Epoch: [16][145/625] lr: 0.000446
	batch_time: 2.415837 (2.373946)	data_time: 0.001116 (0.001601)
	loss_fool: 0.202268 (0.197564)	loss_train_adv: 0.000280 (0.001905)
	cen_loss: 0.615137 (0.612789)	cls_loss: 0.043468 (0.049357)
	loc_loss: 0.180553 (0.175405)	total_loss: 1.200265 (1.188362)

[2023-05-05 04:13:51,697-rk0-log_helper.py#102] Progress: 9520 / 15625 [60%], Speed: 2.374 s/iter, ETA 0:04:01 (D:H:M)

[2023-05-05 04:14:39,299-rk0-train.py#348] Epoch: [16][165/625] lr: 0.000446
	batch_time: 2.381608 (2.373269)	data_time: 0.001406 (0.001718)
	loss_fool: 0.193295 (0.196887)	loss_train_adv: 0.013890 (0.002096)
	cen_loss: 0.615786 (0.613386)	cls_loss: 0.047401 (0.050436)
	loc_loss: 0.168826 (0.176896)	total_loss: 1.169665 (1.194510)

[2023-05-05 04:14:39,300-rk0-log_helper.py#102] Progress: 9540 / 15625 [61%], Speed: 2.373 s/iter, ETA 0:04:00 (D:H:M)

[2023-05-05 04:15:27,053-rk0-train.py#348] Epoch: [16][185/625] lr: 0.000446
	batch_time: 2.347461 (2.372003)	data_time: 0.001260 (0.001790)
	loss_fool: 0.196476 (0.196960)	loss_train_adv: 0.000993 (0.002280)
	cen_loss: 0.609122 (0.613234)	cls_loss: 0.052229 (0.049659)
	loc_loss: 0.167522 (0.176538)	total_loss: 1.163917 (1.192509)

[2023-05-05 04:15:27,054-rk0-log_helper.py#102] Progress: 9560 / 15625 [61%], Speed: 2.372 s/iter, ETA 0:03:59 (D:H:M)

[2023-05-05 04:16:16,692-rk0-train.py#348] Epoch: [16][205/625] lr: 0.000446
	batch_time: 2.326222 (2.396566)	data_time: 0.001384 (0.001840)
	loss_fool: 0.202646 (0.196762)	loss_train_adv: 0.000155 (0.002210)
	cen_loss: 0.610767 (0.613412)	cls_loss: 0.033897 (0.049523)
	loc_loss: 0.149679 (0.175389)	total_loss: 1.093700 (1.189101)

[2023-05-05 04:16:16,693-rk0-log_helper.py#102] Progress: 9580 / 15625 [61%], Speed: 2.397 s/iter, ETA 0:04:01 (D:H:M)

[2023-05-05 04:17:03,972-rk0-train.py#348] Epoch: [16][225/625] lr: 0.000446
	batch_time: 2.435333 (2.399439)	data_time: 0.001157 (0.002160)
	loss_fool: 0.188520 (0.197321)	loss_train_adv: 0.008443 (0.001952)
	cen_loss: 0.611760 (0.613056)	cls_loss: 0.058514 (0.049044)
	loc_loss: 0.208716 (0.173868)	total_loss: 1.296421 (1.183704)

[2023-05-05 04:17:03,973-rk0-log_helper.py#102] Progress: 9600 / 15625 [61%], Speed: 2.399 s/iter, ETA 0:04:00 (D:H:M)

[2023-05-05 04:17:51,805-rk0-train.py#348] Epoch: [16][245/625] lr: 0.000446
	batch_time: 2.413333 (2.398003)	data_time: 0.001445 (0.002056)
	loss_fool: 0.200725 (0.196840)	loss_train_adv: 0.001354 (0.002384)
	cen_loss: 0.614032 (0.613295)	cls_loss: 0.042269 (0.048795)
	loc_loss: 0.186956 (0.174180)	total_loss: 1.217168 (1.184630)

[2023-05-05 04:17:51,806-rk0-log_helper.py#102] Progress: 9620 / 15625 [61%], Speed: 2.398 s/iter, ETA 0:04:00 (D:H:M)

[2023-05-05 04:18:39,685-rk0-train.py#348] Epoch: [16][265/625] lr: 0.000446
	batch_time: 2.496783 (2.400623)	data_time: 0.001140 (0.001937)
	loss_fool: 0.192733 (0.196688)	loss_train_adv: 0.002913 (0.002253)
	cen_loss: 0.613449 (0.612837)	cls_loss: 0.038061 (0.047987)
	loc_loss: 0.161371 (0.172893)	total_loss: 1.135624 (1.179502)

[2023-05-05 04:18:39,686-rk0-log_helper.py#102] Progress: 9640 / 15625 [61%], Speed: 2.401 s/iter, ETA 0:03:59 (D:H:M)

[2023-05-05 04:19:27,563-rk0-train.py#348] Epoch: [16][285/625] lr: 0.000446
	batch_time: 2.374634 (2.402099)	data_time: 0.011817 (0.001940)
	loss_fool: 0.202919 (0.197001)	loss_train_adv: 0.001214 (0.002083)
	cen_loss: 0.610757 (0.613014)	cls_loss: 0.055716 (0.050233)
	loc_loss: 0.177724 (0.174879)	total_loss: 1.199646 (1.187884)

[2023-05-05 04:19:27,564-rk0-log_helper.py#102] Progress: 9660 / 15625 [61%], Speed: 2.402 s/iter, ETA 0:03:58 (D:H:M)

[2023-05-05 04:20:15,059-rk0-train.py#348] Epoch: [16][305/625] lr: 0.000446
	batch_time: 2.422252 (2.380434)	data_time: 0.001716 (0.001914)
	loss_fool: 0.192922 (0.197324)	loss_train_adv: 0.003458 (0.002073)
	cen_loss: 0.615871 (0.612635)	cls_loss: 0.035142 (0.051835)
	loc_loss: 0.147754 (0.175883)	total_loss: 1.094275 (1.192118)

[2023-05-05 04:20:15,060-rk0-log_helper.py#102] Progress: 9680 / 15625 [61%], Speed: 2.380 s/iter, ETA 0:03:55 (D:H:M)

[2023-05-05 04:21:02,911-rk0-train.py#348] Epoch: [16][325/625] lr: 0.000446
	batch_time: 2.368433 (2.386003)	data_time: 0.001428 (0.001643)
	loss_fool: 0.201306 (0.196884)	loss_train_adv: 0.001120 (0.002145)
	cen_loss: 0.617585 (0.612802)	cls_loss: 0.037961 (0.051226)
	loc_loss: 0.187100 (0.176767)	total_loss: 1.216847 (1.194329)

[2023-05-05 04:21:02,912-rk0-log_helper.py#102] Progress: 9700 / 15625 [62%], Speed: 2.386 s/iter, ETA 0:03:55 (D:H:M)

[2023-05-05 04:21:50,546-rk0-train.py#348] Epoch: [16][345/625] lr: 0.000446
	batch_time: 2.396016 (2.384069)	data_time: 0.001250 (0.001633)
	loss_fool: 0.201694 (0.197280)	loss_train_adv: 0.000079 (0.001742)
	cen_loss: 0.616397 (0.612438)	cls_loss: 0.033798 (0.050880)
	loc_loss: 0.165812 (0.174717)	total_loss: 1.147630 (1.187471)

[2023-05-05 04:21:50,547-rk0-log_helper.py#102] Progress: 9720 / 15625 [62%], Speed: 2.384 s/iter, ETA 0:03:54 (D:H:M)

[2023-05-05 04:22:37,973-rk0-train.py#348] Epoch: [16][365/625] lr: 0.000446
	batch_time: 2.298138 (2.379425)	data_time: 0.001197 (0.001752)
	loss_fool: 0.192661 (0.197506)	loss_train_adv: 0.000862 (0.001700)
	cen_loss: 0.615447 (0.612268)	cls_loss: 0.052683 (0.051329)
	loc_loss: 0.195225 (0.174740)	total_loss: 1.253805 (1.187818)

[2023-05-05 04:22:37,974-rk0-log_helper.py#102] Progress: 9740 / 15625 [62%], Speed: 2.379 s/iter, ETA 0:03:53 (D:H:M)

[2023-05-05 04:23:25,806-rk0-train.py#348] Epoch: [16][385/625] lr: 0.000446
	batch_time: 2.439173 (2.378600)	data_time: 0.001166 (0.001608)
	loss_fool: 0.195786 (0.196697)	loss_train_adv: 0.000211 (0.001943)
	cen_loss: 0.607273 (0.612091)	cls_loss: 0.043251 (0.048803)
	loc_loss: 0.168169 (0.171101)	total_loss: 1.155030 (1.174196)

[2023-05-05 04:23:25,807-rk0-log_helper.py#102] Progress: 9760 / 15625 [62%], Speed: 2.379 s/iter, ETA 0:03:52 (D:H:M)

[2023-05-05 04:24:13,427-rk0-train.py#348] Epoch: [16][405/625] lr: 0.000446
	batch_time: 2.375668 (2.380007)	data_time: 0.001407 (0.001588)
	loss_fool: 0.186893 (0.197224)	loss_train_adv: 0.003053 (0.002000)
	cen_loss: 0.613972 (0.612385)	cls_loss: 0.035792 (0.047849)
	loc_loss: 0.171264 (0.170732)	total_loss: 1.163556 (1.172430)

[2023-05-05 04:24:13,428-rk0-log_helper.py#102] Progress: 9780 / 15625 [62%], Speed: 2.380 s/iter, ETA 0:03:51 (D:H:M)

[2023-05-05 04:25:02,019-rk0-train.py#348] Epoch: [16][425/625] lr: 0.000446
	batch_time: 2.406572 (2.387514)	data_time: 0.001192 (0.001902)
	loss_fool: 0.208312 (0.197271)	loss_train_adv: 0.004798 (0.002096)
	cen_loss: 0.606638 (0.612656)	cls_loss: 0.036206 (0.050592)
	loc_loss: 0.170253 (0.172172)	total_loss: 1.153602 (1.179764)

[2023-05-05 04:25:02,019-rk0-log_helper.py#102] Progress: 9800 / 15625 [62%], Speed: 2.388 s/iter, ETA 0:03:51 (D:H:M)

[2023-05-05 04:25:49,844-rk0-train.py#348] Epoch: [16][445/625] lr: 0.000446
	batch_time: 2.377602 (2.389338)	data_time: 0.001141 (0.002033)
	loss_fool: 0.196749 (0.196882)	loss_train_adv: 0.000588 (0.002171)
	cen_loss: 0.613410 (0.612756)	cls_loss: 0.038901 (0.049775)
	loc_loss: 0.176971 (0.173310)	total_loss: 1.183226 (1.182461)

[2023-05-05 04:25:49,845-rk0-log_helper.py#102] Progress: 9820 / 15625 [62%], Speed: 2.389 s/iter, ETA 0:03:51 (D:H:M)

[2023-05-05 04:26:36,929-rk0-train.py#348] Epoch: [16][465/625] lr: 0.000446
	batch_time: 2.400778 (2.386090)	data_time: 0.001179 (0.001803)
	loss_fool: 0.206417 (0.197141)	loss_train_adv: 0.000741 (0.002113)
	cen_loss: 0.615381 (0.613071)	cls_loss: 0.062789 (0.048933)
	loc_loss: 0.206767 (0.173475)	total_loss: 1.298471 (1.182430)

[2023-05-05 04:26:36,930-rk0-log_helper.py#102] Progress: 9840 / 15625 [62%], Speed: 2.386 s/iter, ETA 0:03:50 (D:H:M)

[2023-05-05 04:27:24,391-rk0-train.py#348] Epoch: [16][485/625] lr: 0.000446
	batch_time: 2.312952 (2.382647)	data_time: 0.001316 (0.002003)
	loss_fool: 0.192539 (0.197406)	loss_train_adv: 0.000178 (0.001980)
	cen_loss: 0.606626 (0.613493)	cls_loss: 0.045519 (0.050423)
	loc_loss: 0.169974 (0.176813)	total_loss: 1.162068 (1.194357)

[2023-05-05 04:27:24,391-rk0-log_helper.py#102] Progress: 9860 / 15625 [63%], Speed: 2.383 s/iter, ETA 0:03:48 (D:H:M)

[2023-05-05 04:28:11,752-rk0-train.py#348] Epoch: [16][505/625] lr: 0.000446
	batch_time: 2.480447 (2.380228)	data_time: 0.001315 (0.002005)
	loss_fool: 0.198209 (0.196844)	loss_train_adv: 0.002795 (0.001997)
	cen_loss: 0.613855 (0.613281)	cls_loss: 0.039537 (0.051075)
	loc_loss: 0.146503 (0.177528)	total_loss: 1.092903 (1.196940)

[2023-05-05 04:28:11,757-rk0-log_helper.py#102] Progress: 9880 / 15625 [63%], Speed: 2.380 s/iter, ETA 0:03:47 (D:H:M)

[2023-05-05 04:28:59,297-rk0-train.py#348] Epoch: [16][525/625] lr: 0.000446
	batch_time: 2.345309 (2.369808)	data_time: 0.001460 (0.001642)
	loss_fool: 0.194754 (0.196993)	loss_train_adv: 0.000646 (0.001914)
	cen_loss: 0.612026 (0.612890)	cls_loss: 0.032915 (0.048578)
	loc_loss: 0.143537 (0.175713)	total_loss: 1.075553 (1.188608)

[2023-05-05 04:28:59,298-rk0-log_helper.py#102] Progress: 9900 / 15625 [63%], Speed: 2.370 s/iter, ETA 0:03:46 (D:H:M)

[2023-05-05 04:29:47,250-rk0-train.py#348] Epoch: [16][545/625] lr: 0.000446
	batch_time: 2.545751 (2.371092)	data_time: 0.001200 (0.001584)
	loss_fool: 0.204899 (0.196805)	loss_train_adv: 0.001603 (0.002050)
	cen_loss: 0.611309 (0.613206)	cls_loss: 0.032484 (0.049053)
	loc_loss: 0.146712 (0.175471)	total_loss: 1.083930 (1.188670)

[2023-05-05 04:29:47,250-rk0-log_helper.py#102] Progress: 9920 / 15625 [63%], Speed: 2.371 s/iter, ETA 0:03:45 (D:H:M)

[2023-05-05 04:30:34,555-rk0-train.py#348] Epoch: [16][565/625] lr: 0.000446
	batch_time: 2.386037 (2.373162)	data_time: 0.001135 (0.001594)
	loss_fool: 0.210540 (0.196162)	loss_train_adv: 0.000656 (0.002289)
	cen_loss: 0.614085 (0.613266)	cls_loss: 0.074285 (0.049659)
	loc_loss: 0.191739 (0.175879)	total_loss: 1.263588 (1.190563)

[2023-05-05 04:30:34,555-rk0-log_helper.py#102] Progress: 9940 / 15625 [63%], Speed: 2.373 s/iter, ETA 0:03:44 (D:H:M)

[2023-05-05 04:31:22,097-rk0-train.py#348] Epoch: [16][585/625] lr: 0.000446
	batch_time: 2.381683 (2.373921)	data_time: 0.001276 (0.001492)
	loss_fool: 0.194923 (0.196753)	loss_train_adv: 0.001233 (0.002179)
	cen_loss: 0.617942 (0.613135)	cls_loss: 0.050683 (0.050443)
	loc_loss: 0.180418 (0.175591)	total_loss: 1.209878 (1.190351)

[2023-05-05 04:31:22,098-rk0-log_helper.py#102] Progress: 9960 / 15625 [63%], Speed: 2.374 s/iter, ETA 0:03:44 (D:H:M)

[2023-05-05 04:32:10,757-rk0-train.py#348] Epoch: [16][605/625] lr: 0.000446
	batch_time: 2.418726 (2.386704)	data_time: 0.001203 (0.002126)
	loss_fool: 0.202147 (0.196662)	loss_train_adv: 0.000598 (0.002278)
	cen_loss: 0.615487 (0.613699)	cls_loss: 0.054002 (0.051348)
	loc_loss: 0.179432 (0.176825)	total_loss: 1.207786 (1.195521)

[2023-05-05 04:32:10,758-rk0-log_helper.py#102] Progress: 9980 / 15625 [63%], Speed: 2.387 s/iter, ETA 0:03:44 (D:H:M)

[2023-05-05 04:32:58,265-rk0-train.py#348] Epoch: [16][0/625] lr: 0.000446
	batch_time: 2.334469 (2.386336)	data_time: 0.001357 (0.002280)
	loss_fool: 0.195039 (0.196745)	loss_train_adv: 0.003604 (0.002442)
	cen_loss: 0.612987 (0.613801)	cls_loss: 0.063737 (0.051414)
	loc_loss: 0.192957 (0.177164)	total_loss: 1.255595 (1.196706)

[2023-05-05 04:32:58,266-rk0-log_helper.py#102] Progress: 10000 / 15625 [64%], Speed: 2.386 s/iter, ETA 0:03:43 (D:H:M)

[2023-05-05 04:32:59,503-rk0-train.py#235] epoch: 17
[2023-05-05 04:32:59,504-rk0-train.py#240] epoch 17 lr 3.954976348095537e-05
[2023-05-05 04:32:59,504-rk0-train.py#240] epoch 17 lr 0.0003954976348095537
[2023-05-05 04:32:59,505-rk0-train.py#240] epoch 17 lr 0.001318325449365179
[2023-05-05 04:32:59,505-rk0-train.py#240] epoch 17 lr 0.0003954976348095537
[2023-05-05 04:32:59,506-rk0-train.py#240] epoch 17 lr 0.0003954976348095537
[2023-05-05 04:33:48,618-rk0-train.py#348] Epoch: [17][20/625] lr: 0.000395
	batch_time: 4.061418 (2.410327)	data_time: 0.001396 (0.014518)
	loss_fool: 0.197258 (0.196283)	loss_train_adv: 0.000228 (0.002580)
	cen_loss: 0.613184 (0.613889)	cls_loss: 0.044493 (0.051430)
	loc_loss: 0.172708 (0.177319)	total_loss: 1.175801 (1.197278)

[2023-05-05 04:33:48,618-rk0-log_helper.py#102] Progress: 10020 / 15625 [64%], Speed: 2.410 s/iter, ETA 0:03:45 (D:H:M)

[2023-05-05 04:34:35,936-rk0-train.py#348] Epoch: [17][40/625] lr: 0.000395
	batch_time: 2.292393 (2.410729)	data_time: 0.001523 (0.014800)
	loss_fool: 0.200261 (0.196778)	loss_train_adv: 0.003226 (0.002521)
	cen_loss: 0.609867 (0.613703)	cls_loss: 0.037226 (0.050815)
	loc_loss: 0.145430 (0.176463)	total_loss: 1.083382 (1.193907)

[2023-05-05 04:34:35,936-rk0-log_helper.py#102] Progress: 10040 / 15625 [64%], Speed: 2.411 s/iter, ETA 0:03:44 (D:H:M)

[2023-05-05 04:35:24,465-rk0-train.py#348] Epoch: [17][60/625] lr: 0.000395
	batch_time: 2.424126 (2.420529)	data_time: 0.001417 (0.014774)
	loss_fool: 0.195752 (0.196448)	loss_train_adv: 0.000759 (0.002472)
	cen_loss: 0.607319 (0.613781)	cls_loss: 0.048039 (0.050230)
	loc_loss: 0.154925 (0.176370)	total_loss: 1.120133 (1.193120)

[2023-05-05 04:35:24,466-rk0-log_helper.py#102] Progress: 10060 / 15625 [64%], Speed: 2.421 s/iter, ETA 0:03:44 (D:H:M)

[2023-05-05 04:36:11,669-rk0-train.py#348] Epoch: [17][80/625] lr: 0.000395
	batch_time: 2.357199 (2.405898)	data_time: 0.001290 (0.014200)
	loss_fool: 0.201563 (0.196757)	loss_train_adv: 0.000573 (0.002349)
	cen_loss: 0.611704 (0.612898)	cls_loss: 0.046531 (0.048957)
	loc_loss: 0.160993 (0.175347)	total_loss: 1.141213 (1.187898)

[2023-05-05 04:36:11,669-rk0-log_helper.py#102] Progress: 10080 / 15625 [64%], Speed: 2.406 s/iter, ETA 0:03:42 (D:H:M)

[2023-05-05 04:36:59,185-rk0-train.py#348] Epoch: [17][100/625] lr: 0.000395
	batch_time: 2.403395 (2.406088)	data_time: 0.001109 (0.014050)
	loss_fool: 0.188833 (0.196585)	loss_train_adv: 0.003060 (0.002064)
	cen_loss: 0.617198 (0.612916)	cls_loss: 0.060983 (0.049705)
	loc_loss: 0.200158 (0.176191)	total_loss: 1.278655 (1.191193)

[2023-05-05 04:36:59,185-rk0-log_helper.py#102] Progress: 10100 / 15625 [64%], Speed: 2.406 s/iter, ETA 0:03:41 (D:H:M)

[2023-05-05 04:37:46,764-rk0-train.py#348] Epoch: [17][120/625] lr: 0.000395
	batch_time: 2.455310 (2.378306)	data_time: 0.001461 (0.001850)
	loss_fool: 0.193238 (0.197462)	loss_train_adv: 0.005646 (0.001750)
	cen_loss: 0.610687 (0.612732)	cls_loss: 0.040084 (0.049038)
	loc_loss: 0.166264 (0.175438)	total_loss: 1.149564 (1.188084)

[2023-05-05 04:37:46,764-rk0-log_helper.py#102] Progress: 10120 / 15625 [64%], Speed: 2.378 s/iter, ETA 0:03:38 (D:H:M)

[2023-05-05 04:38:34,238-rk0-train.py#348] Epoch: [17][140/625] lr: 0.000395
	batch_time: 2.344653 (2.379692)	data_time: 0.001456 (0.001855)
	loss_fool: 0.191830 (0.197746)	loss_train_adv: 0.005147 (0.001626)
	cen_loss: 0.611070 (0.612470)	cls_loss: 0.037077 (0.049661)
	loc_loss: 0.161870 (0.176293)	total_loss: 1.133758 (1.191009)

[2023-05-05 04:38:34,239-rk0-log_helper.py#102] Progress: 10140 / 15625 [64%], Speed: 2.380 s/iter, ETA 0:03:37 (D:H:M)

[2023-05-05 04:39:21,407-rk0-train.py#348] Epoch: [17][160/625] lr: 0.000395
	batch_time: 2.387463 (2.366112)	data_time: 0.001566 (0.001778)
	loss_fool: 0.198567 (0.197425)	loss_train_adv: 0.002080 (0.001821)
	cen_loss: 0.616650 (0.612227)	cls_loss: 0.047206 (0.048643)
	loc_loss: 0.187504 (0.175032)	total_loss: 1.226367 (1.185966)

[2023-05-05 04:39:21,408-rk0-log_helper.py#102] Progress: 10160 / 15625 [65%], Speed: 2.366 s/iter, ETA 0:03:35 (D:H:M)

[2023-05-05 04:40:08,657-rk0-train.py#348] Epoch: [17][180/625] lr: 0.000395
	batch_time: 2.347321 (2.366582)	data_time: 0.001169 (0.002021)
	loss_fool: 0.196505 (0.197231)	loss_train_adv: 0.000269 (0.001911)
	cen_loss: 0.614367 (0.612508)	cls_loss: 0.048825 (0.047822)
	loc_loss: 0.183043 (0.174093)	total_loss: 1.212323 (1.182609)

[2023-05-05 04:40:08,662-rk0-log_helper.py#102] Progress: 10180 / 15625 [65%], Speed: 2.367 s/iter, ETA 0:03:34 (D:H:M)

[2023-05-05 04:40:57,447-rk0-train.py#348] Epoch: [17][200/625] lr: 0.000395
	batch_time: 2.487903 (2.379293)	data_time: 0.001134 (0.001994)
	loss_fool: 0.194825 (0.197178)	loss_train_adv: 0.002758 (0.001983)
	cen_loss: 0.617175 (0.612908)	cls_loss: 0.048138 (0.047991)
	loc_loss: 0.192653 (0.173841)	total_loss: 1.243271 (1.182423)

[2023-05-05 04:40:57,448-rk0-log_helper.py#102] Progress: 10200 / 15625 [65%], Speed: 2.379 s/iter, ETA 0:03:35 (D:H:M)

[2023-05-05 04:41:44,907-rk0-train.py#348] Epoch: [17][220/625] lr: 0.000395
	batch_time: 2.346953 (2.378077)	data_time: 0.001166 (0.001840)
	loss_fool: 0.198303 (0.196764)	loss_train_adv: 0.004528 (0.002261)
	cen_loss: 0.610548 (0.613232)	cls_loss: 0.049478 (0.047663)
	loc_loss: 0.166840 (0.174130)	total_loss: 1.160546 (1.183285)

[2023-05-05 04:41:44,908-rk0-log_helper.py#102] Progress: 10220 / 15625 [65%], Speed: 2.378 s/iter, ETA 0:03:34 (D:H:M)

[2023-05-05 04:42:32,199-rk0-train.py#348] Epoch: [17][240/625] lr: 0.000395
	batch_time: 2.473555 (2.376241)	data_time: 0.001028 (0.002238)
	loss_fool: 0.191494 (0.196499)	loss_train_adv: 0.000807 (0.002209)
	cen_loss: 0.619934 (0.613644)	cls_loss: 0.034673 (0.047036)
	loc_loss: 0.197481 (0.174000)	total_loss: 1.247049 (1.182681)

[2023-05-05 04:42:32,199-rk0-log_helper.py#102] Progress: 10240 / 15625 [65%], Speed: 2.376 s/iter, ETA 0:03:33 (D:H:M)

[2023-05-05 04:43:19,578-rk0-train.py#348] Epoch: [17][260/625] lr: 0.000395
	batch_time: 2.337697 (2.378458)	data_time: 0.001276 (0.002301)
	loss_fool: 0.197407 (0.196958)	loss_train_adv: 0.000259 (0.001971)
	cen_loss: 0.613586 (0.613720)	cls_loss: 0.068977 (0.046735)
	loc_loss: 0.185645 (0.173900)	total_loss: 1.239498 (1.182153)

[2023-05-05 04:43:19,579-rk0-log_helper.py#102] Progress: 10260 / 15625 [65%], Speed: 2.378 s/iter, ETA 0:03:32 (D:H:M)

[2023-05-05 04:44:07,104-rk0-train.py#348] Epoch: [17][280/625] lr: 0.000395
	batch_time: 2.379001 (2.381333)	data_time: 0.001893 (0.002168)
	loss_fool: 0.210107 (0.197170)	loss_train_adv: 0.000323 (0.001823)
	cen_loss: 0.610563 (0.613714)	cls_loss: 0.034244 (0.046227)
	loc_loss: 0.149211 (0.173197)	total_loss: 1.092439 (1.179531)

[2023-05-05 04:44:07,104-rk0-log_helper.py#102] Progress: 10280 / 15625 [65%], Speed: 2.381 s/iter, ETA 0:03:32 (D:H:M)

[2023-05-05 04:44:54,567-rk0-train.py#348] Epoch: [17][300/625] lr: 0.000395
	batch_time: 2.342405 (2.367855)	data_time: 0.001141 (0.002329)
	loss_fool: 0.194883 (0.197178)	loss_train_adv: 0.002475 (0.001923)
	cen_loss: 0.610358 (0.613006)	cls_loss: 0.067968 (0.047401)
	loc_loss: 0.191489 (0.172581)	total_loss: 1.252792 (1.178151)

[2023-05-05 04:44:54,567-rk0-log_helper.py#102] Progress: 10300 / 15625 [65%], Speed: 2.368 s/iter, ETA 0:03:30 (D:H:M)

[2023-05-05 04:45:41,731-rk0-train.py#348] Epoch: [17][320/625] lr: 0.000395
	batch_time: 2.403747 (2.365017)	data_time: 0.001410 (0.002449)
	loss_fool: 0.214494 (0.197085)	loss_train_adv: 0.002603 (0.002129)
	cen_loss: 0.613522 (0.612359)	cls_loss: 0.056850 (0.047929)
	loc_loss: 0.182121 (0.172352)	total_loss: 1.216737 (1.177343)

[2023-05-05 04:45:41,732-rk0-log_helper.py#102] Progress: 10320 / 15625 [66%], Speed: 2.365 s/iter, ETA 0:03:29 (D:H:M)

[2023-05-05 04:46:29,287-rk0-train.py#348] Epoch: [17][340/625] lr: 0.000395
	batch_time: 2.365174 (2.367961)	data_time: 0.001091 (0.001819)
	loss_fool: 0.206426 (0.196174)	loss_train_adv: 0.005848 (0.002853)
	cen_loss: 0.613792 (0.612338)	cls_loss: 0.043341 (0.050164)
	loc_loss: 0.174229 (0.173894)	total_loss: 1.179819 (1.184183)

[2023-05-05 04:46:29,288-rk0-log_helper.py#102] Progress: 10340 / 15625 [66%], Speed: 2.368 s/iter, ETA 0:03:28 (D:H:M)

[2023-05-05 04:47:17,067-rk0-train.py#348] Epoch: [17][360/625] lr: 0.000395
	batch_time: 2.388955 (2.371990)	data_time: 0.001173 (0.001763)
	loss_fool: 0.177801 (0.195169)	loss_train_adv: 0.003170 (0.003349)
	cen_loss: 0.619099 (0.612268)	cls_loss: 0.037800 (0.049996)
	loc_loss: 0.178668 (0.174568)	total_loss: 1.192902 (1.185969)

[2023-05-05 04:47:17,067-rk0-log_helper.py#102] Progress: 10360 / 15625 [66%], Speed: 2.372 s/iter, ETA 0:03:28 (D:H:M)

[2023-05-05 04:48:04,858-rk0-train.py#348] Epoch: [17][380/625] lr: 0.000395
	batch_time: 2.338161 (2.374634)	data_time: 0.001267 (0.001698)
	loss_fool: 0.194510 (0.194912)	loss_train_adv: 0.004979 (0.003603)
	cen_loss: 0.615095 (0.612488)	cls_loss: 0.038652 (0.050858)
	loc_loss: 0.172819 (0.176062)	total_loss: 1.172204 (1.191534)

[2023-05-05 04:48:04,858-rk0-log_helper.py#102] Progress: 10380 / 15625 [66%], Speed: 2.375 s/iter, ETA 0:03:27 (D:H:M)

[2023-05-05 04:48:52,586-rk0-train.py#348] Epoch: [17][400/625] lr: 0.000395
	batch_time: 2.332572 (2.377487)	data_time: 0.001398 (0.001805)
	loss_fool: 0.202494 (0.195438)	loss_train_adv: 0.000110 (0.003441)
	cen_loss: 0.609328 (0.612959)	cls_loss: 0.064612 (0.049591)
	loc_loss: 0.169524 (0.175549)	total_loss: 1.182514 (1.189198)

[2023-05-05 04:48:52,586-rk0-log_helper.py#102] Progress: 10400 / 15625 [66%], Speed: 2.377 s/iter, ETA 0:03:27 (D:H:M)

[2023-05-05 04:49:40,167-rk0-train.py#348] Epoch: [17][420/625] lr: 0.000395
	batch_time: 2.330489 (2.381319)	data_time: 0.002590 (0.001803)
	loss_fool: 0.196583 (0.195943)	loss_train_adv: 0.000178 (0.002861)
	cen_loss: 0.600455 (0.612972)	cls_loss: 0.027935 (0.048721)
	loc_loss: 0.116592 (0.175366)	total_loss: 0.978168 (1.187790)

[2023-05-05 04:49:40,167-rk0-log_helper.py#102] Progress: 10420 / 15625 [66%], Speed: 2.381 s/iter, ETA 0:03:26 (D:H:M)

[2023-05-05 04:50:28,797-rk0-train.py#348] Epoch: [17][440/625] lr: 0.000395
	batch_time: 2.284371 (2.391781)	data_time: 0.001154 (0.001868)
	loss_fool: 0.201227 (0.197020)	loss_train_adv: 0.000935 (0.002084)
	cen_loss: 0.615083 (0.612696)	cls_loss: 0.050265 (0.046991)
	loc_loss: 0.185617 (0.173702)	total_loss: 1.222198 (1.180794)

[2023-05-05 04:50:28,797-rk0-log_helper.py#102] Progress: 10440 / 15625 [66%], Speed: 2.392 s/iter, ETA 0:03:26 (D:H:M)

[2023-05-05 04:51:16,412-rk0-train.py#348] Epoch: [17][460/625] lr: 0.000395
	batch_time: 2.299942 (2.390054)	data_time: 0.001163 (0.002012)
	loss_fool: 0.195124 (0.197929)	loss_train_adv: 0.003293 (0.001713)
	cen_loss: 0.614487 (0.612961)	cls_loss: 0.062409 (0.047854)
	loc_loss: 0.215802 (0.174082)	total_loss: 1.324301 (1.183062)

[2023-05-05 04:51:16,413-rk0-log_helper.py#102] Progress: 10460 / 15625 [66%], Speed: 2.390 s/iter, ETA 0:03:25 (D:H:M)

[2023-05-05 04:52:04,708-rk0-train.py#348] Epoch: [17][480/625] lr: 0.000395
	batch_time: 2.379743 (2.395110)	data_time: 0.001364 (0.002131)
	loss_fool: 0.194987 (0.197744)	loss_train_adv: 0.004519 (0.001733)
	cen_loss: 0.616450 (0.613002)	cls_loss: 0.058838 (0.047158)
	loc_loss: 0.186766 (0.172991)	total_loss: 1.235587 (1.179132)

[2023-05-05 04:52:04,708-rk0-log_helper.py#102] Progress: 10480 / 15625 [67%], Speed: 2.395 s/iter, ETA 0:03:25 (D:H:M)

[2023-05-05 04:52:51,906-rk0-train.py#348] Epoch: [17][500/625] lr: 0.000395
	batch_time: 2.268979 (2.389637)	data_time: 0.001394 (0.001928)
	loss_fool: 0.200360 (0.197164)	loss_train_adv: 0.001218 (0.001902)
	cen_loss: 0.610803 (0.613077)	cls_loss: 0.066309 (0.046809)
	loc_loss: 0.211970 (0.174111)	total_loss: 1.313022 (1.182221)

[2023-05-05 04:52:51,907-rk0-log_helper.py#102] Progress: 10500 / 15625 [67%], Speed: 2.390 s/iter, ETA 0:03:24 (D:H:M)

[2023-05-05 04:53:39,300-rk0-train.py#348] Epoch: [17][520/625] lr: 0.000395
	batch_time: 2.383082 (2.388060)	data_time: 0.000597 (0.001948)
	loss_fool: 0.200717 (0.196775)	loss_train_adv: 0.000442 (0.002317)
	cen_loss: 0.614603 (0.613351)	cls_loss: 0.099213 (0.048164)
	loc_loss: 0.211237 (0.175191)	total_loss: 1.347528 (1.187089)

[2023-05-05 04:53:39,301-rk0-log_helper.py#102] Progress: 10520 / 15625 [67%], Speed: 2.388 s/iter, ETA 0:03:23 (D:H:M)

[2023-05-05 04:54:27,335-rk0-train.py#348] Epoch: [17][540/625] lr: 0.000395
	batch_time: 2.377825 (2.382304)	data_time: 0.001160 (0.001840)
	loss_fool: 0.193754 (0.196823)	loss_train_adv: 0.000668 (0.002330)
	cen_loss: 0.621514 (0.613902)	cls_loss: 0.087739 (0.048274)
	loc_loss: 0.200071 (0.175305)	total_loss: 1.309467 (1.188092)

[2023-05-05 04:54:27,335-rk0-log_helper.py#102] Progress: 10540 / 15625 [67%], Speed: 2.382 s/iter, ETA 0:03:21 (D:H:M)

[2023-05-05 04:55:14,551-rk0-train.py#348] Epoch: [17][560/625] lr: 0.000395
	batch_time: 2.316879 (2.378261)	data_time: 0.001244 (0.001719)
	loss_fool: 0.191213 (0.196372)	loss_train_adv: 0.003238 (0.002391)
	cen_loss: 0.619456 (0.614033)	cls_loss: 0.078696 (0.048754)
	loc_loss: 0.203480 (0.174857)	total_loss: 1.308592 (1.187357)

[2023-05-05 04:55:14,551-rk0-log_helper.py#102] Progress: 10560 / 15625 [67%], Speed: 2.378 s/iter, ETA 0:03:20 (D:H:M)

[2023-05-05 04:56:01,765-rk0-train.py#348] Epoch: [17][580/625] lr: 0.000395
	batch_time: 2.346744 (2.367402)	data_time: 0.008600 (0.001568)
	loss_fool: 0.199933 (0.196956)	loss_train_adv: 0.001120 (0.002020)
	cen_loss: 0.614509 (0.613883)	cls_loss: 0.044728 (0.049720)
	loc_loss: 0.196745 (0.175671)	total_loss: 1.249473 (1.190616)

[2023-05-05 04:56:01,766-rk0-log_helper.py#102] Progress: 10580 / 15625 [67%], Speed: 2.367 s/iter, ETA 0:03:19 (D:H:M)

[2023-05-05 04:56:49,421-rk0-train.py#348] Epoch: [17][600/625] lr: 0.000395
	batch_time: 2.396830 (2.372132)	data_time: 0.001526 (0.001934)
	loss_fool: 0.200374 (0.197452)	loss_train_adv: 0.000076 (0.001750)
	cen_loss: 0.609028 (0.613861)	cls_loss: 0.054467 (0.049386)
	loc_loss: 0.185098 (0.174370)	total_loss: 1.218789 (1.186357)

[2023-05-05 04:56:49,422-rk0-log_helper.py#102] Progress: 10600 / 15625 [67%], Speed: 2.372 s/iter, ETA 0:03:18 (D:H:M)

[2023-05-05 04:57:36,900-rk0-train.py#348] Epoch: [17][620/625] lr: 0.000395
	batch_time: 2.395723 (2.372903)	data_time: 0.001165 (0.001943)
	loss_fool: 0.200182 (0.197720)	loss_train_adv: 0.003809 (0.001501)
	cen_loss: 0.618783 (0.614221)	cls_loss: 0.077135 (0.049019)
	loc_loss: 0.198821 (0.173153)	total_loss: 1.292382 (1.182700)

[2023-05-05 04:57:36,901-rk0-log_helper.py#102] Progress: 10620 / 15625 [67%], Speed: 2.373 s/iter, ETA 0:03:17 (D:H:M)

[2023-05-05 04:57:50,018-rk0-train.py#235] epoch: 18
[2023-05-05 04:57:50,019-rk0-train.py#240] epoch 18 lr 3.503582203635182e-05
[2023-05-05 04:57:50,019-rk0-train.py#240] epoch 18 lr 0.00035035822036351817
[2023-05-05 04:57:50,020-rk0-train.py#240] epoch 18 lr 0.0011678607345450606
[2023-05-05 04:57:50,020-rk0-train.py#240] epoch 18 lr 0.00035035822036351817
[2023-05-05 04:57:50,021-rk0-train.py#240] epoch 18 lr 0.00035035822036351817
[2023-05-05 04:58:25,816-rk0-train.py#348] Epoch: [18][15/625] lr: 0.000350
	batch_time: 2.361378 (2.381553)	data_time: 0.001305 (0.015063)
	loss_fool: 0.183196 (0.197305)	loss_train_adv: 0.001824 (0.001628)
	cen_loss: 0.611594 (0.613690)	cls_loss: 0.033648 (0.049035)
	loc_loss: 0.173112 (0.172446)	total_loss: 1.164579 (1.180063)

[2023-05-05 04:58:25,817-rk0-log_helper.py#102] Progress: 10640 / 15625 [68%], Speed: 2.382 s/iter, ETA 0:03:17 (D:H:M)

[2023-05-05 04:59:15,077-rk0-train.py#348] Epoch: [18][35/625] lr: 0.000350
	batch_time: 2.345239 (2.402256)	data_time: 0.001161 (0.015209)
	loss_fool: 0.202036 (0.198038)	loss_train_adv: 0.000512 (0.001455)
	cen_loss: 0.615342 (0.613151)	cls_loss: 0.085211 (0.048044)
	loc_loss: 0.179161 (0.173212)	total_loss: 1.238034 (1.180831)

[2023-05-05 04:59:15,078-rk0-log_helper.py#102] Progress: 10660 / 15625 [68%], Speed: 2.402 s/iter, ETA 0:03:18 (D:H:M)

[2023-05-05 05:00:02,096-rk0-train.py#348] Epoch: [18][55/625] lr: 0.000350
	batch_time: 2.315662 (2.400182)	data_time: 0.001107 (0.015243)
	loss_fool: 0.197352 (0.197576)	loss_train_adv: 0.001239 (0.001794)
	cen_loss: 0.613577 (0.613110)	cls_loss: 0.045105 (0.048261)
	loc_loss: 0.181675 (0.173125)	total_loss: 1.203707 (1.180745)

[2023-05-05 05:00:02,097-rk0-log_helper.py#102] Progress: 10680 / 15625 [68%], Speed: 2.400 s/iter, ETA 0:03:17 (D:H:M)

[2023-05-05 05:00:49,695-rk0-train.py#348] Epoch: [18][75/625] lr: 0.000350
	batch_time: 2.366270 (2.399245)	data_time: 0.001149 (0.015312)
	loss_fool: 0.203591 (0.197194)	loss_train_adv: 0.002210 (0.001917)
	cen_loss: 0.617112 (0.612861)	cls_loss: 0.081308 (0.048163)
	loc_loss: 0.216151 (0.173240)	total_loss: 1.346873 (1.180745)

[2023-05-05 05:00:49,696-rk0-log_helper.py#102] Progress: 10700 / 15625 [68%], Speed: 2.399 s/iter, ETA 0:03:16 (D:H:M)

[2023-05-05 05:01:37,130-rk0-train.py#348] Epoch: [18][95/625] lr: 0.000350
	batch_time: 2.318089 (2.398637)	data_time: 0.001620 (0.015204)
	loss_fool: 0.201983 (0.197523)	loss_train_adv: 0.001708 (0.001784)
	cen_loss: 0.612849 (0.612593)	cls_loss: 0.048371 (0.048824)
	loc_loss: 0.162990 (0.174889)	total_loss: 1.150189 (1.186083)

[2023-05-05 05:01:37,131-rk0-log_helper.py#102] Progress: 10720 / 15625 [68%], Speed: 2.399 s/iter, ETA 0:03:16 (D:H:M)

[2023-05-05 05:02:24,806-rk0-train.py#348] Epoch: [18][115/625] lr: 0.000350
	batch_time: 2.252777 (2.386121)	data_time: 0.001063 (0.002197)
	loss_fool: 0.200355 (0.197704)	loss_train_adv: 0.001275 (0.001652)
	cen_loss: 0.614170 (0.612661)	cls_loss: 0.054683 (0.047841)
	loc_loss: 0.145875 (0.172869)	total_loss: 1.106479 (1.179110)

[2023-05-05 05:02:24,806-rk0-log_helper.py#102] Progress: 10740 / 15625 [68%], Speed: 2.386 s/iter, ETA 0:03:14 (D:H:M)

[2023-05-05 05:03:11,867-rk0-train.py#348] Epoch: [18][135/625] lr: 0.000350
	batch_time: 2.313698 (2.363879)	data_time: 0.023039 (0.002386)
	loss_fool: 0.194758 (0.197324)	loss_train_adv: 0.000478 (0.001824)
	cen_loss: 0.611650 (0.613303)	cls_loss: 0.045033 (0.048698)
	loc_loss: 0.163744 (0.172660)	total_loss: 1.147916 (1.179982)

[2023-05-05 05:03:11,868-rk0-log_helper.py#102] Progress: 10760 / 15625 [68%], Speed: 2.364 s/iter, ETA 0:03:11 (D:H:M)

[2023-05-05 05:03:59,660-rk0-train.py#348] Epoch: [18][155/625] lr: 0.000350
	batch_time: 2.781534 (2.371718)	data_time: 0.001215 (0.002278)
	loss_fool: 0.191733 (0.197140)	loss_train_adv: 0.000839 (0.001811)
	cen_loss: 0.610222 (0.613085)	cls_loss: 0.029652 (0.048775)
	loc_loss: 0.165823 (0.172096)	total_loss: 1.137342 (1.178147)

[2023-05-05 05:03:59,661-rk0-log_helper.py#102] Progress: 10780 / 15625 [68%], Speed: 2.372 s/iter, ETA 0:03:11 (D:H:M)

[2023-05-05 05:04:47,574-rk0-train.py#348] Epoch: [18][175/625] lr: 0.000350
	batch_time: 2.332324 (2.374883)	data_time: 0.001184 (0.001793)
	loss_fool: 0.196383 (0.197091)	loss_train_adv: 0.002258 (0.001876)
	cen_loss: 0.607573 (0.612914)	cls_loss: 0.088951 (0.050786)
	loc_loss: 0.162004 (0.173293)	total_loss: 1.182537 (1.183579)

[2023-05-05 05:04:47,575-rk0-log_helper.py#102] Progress: 10800 / 15625 [69%], Speed: 2.375 s/iter, ETA 0:03:10 (D:H:M)

[2023-05-05 05:05:34,810-rk0-train.py#348] Epoch: [18][195/625] lr: 0.000350
	batch_time: 2.341974 (2.373150)	data_time: 0.012574 (0.001918)
	loss_fool: 0.190598 (0.196581)	loss_train_adv: 0.000607 (0.002042)
	cen_loss: 0.617620 (0.612755)	cls_loss: 0.048460 (0.050660)
	loc_loss: 0.174514 (0.172360)	total_loss: 1.189622 (1.180494)

[2023-05-05 05:05:34,810-rk0-log_helper.py#102] Progress: 10820 / 15625 [69%], Speed: 2.373 s/iter, ETA 0:03:10 (D:H:M)

[2023-05-05 05:06:22,644-rk0-train.py#348] Epoch: [18][215/625] lr: 0.000350
	batch_time: 2.357562 (2.374693)	data_time: 0.001140 (0.001916)
	loss_fool: 0.204026 (0.196865)	loss_train_adv: 0.000281 (0.002101)
	cen_loss: 0.616462 (0.612926)	cls_loss: 0.040263 (0.051306)
	loc_loss: 0.144144 (0.174453)	total_loss: 1.089157 (1.187591)

[2023-05-05 05:06:22,644-rk0-log_helper.py#102] Progress: 10840 / 15625 [69%], Speed: 2.375 s/iter, ETA 0:03:09 (D:H:M)

[2023-05-05 05:07:10,442-rk0-train.py#348] Epoch: [18][235/625] lr: 0.000350
	batch_time: 2.349452 (2.382169)	data_time: 0.000678 (0.001652)
	loss_fool: 0.193249 (0.196552)	loss_train_adv: 0.003765 (0.002081)
	cen_loss: 0.615049 (0.612638)	cls_loss: 0.050266 (0.053324)
	loc_loss: 0.215292 (0.174772)	total_loss: 1.311192 (1.190279)

[2023-05-05 05:07:10,443-rk0-log_helper.py#102] Progress: 10860 / 15625 [69%], Speed: 2.382 s/iter, ETA 0:03:09 (D:H:M)

[2023-05-05 05:07:57,683-rk0-train.py#348] Epoch: [18][255/625] lr: 0.000350
	batch_time: 2.400278 (2.376672)	data_time: 0.001295 (0.001647)
	loss_fool: 0.192326 (0.196965)	loss_train_adv: 0.000594 (0.002020)
	cen_loss: 0.616779 (0.613077)	cls_loss: 0.042358 (0.052932)
	loc_loss: 0.184819 (0.175165)	total_loss: 1.213594 (1.191503)

[2023-05-05 05:07:57,684-rk0-log_helper.py#102] Progress: 10880 / 15625 [69%], Speed: 2.377 s/iter, ETA 0:03:07 (D:H:M)

[2023-05-05 05:08:47,254-rk0-train.py#348] Epoch: [18][275/625] lr: 0.000350
	batch_time: 2.417755 (2.393688)	data_time: 0.007787 (0.001935)
	loss_fool: 0.196483 (0.197027)	loss_train_adv: 0.000834 (0.001952)
	cen_loss: 0.612359 (0.613378)	cls_loss: 0.039322 (0.051742)
	loc_loss: 0.160161 (0.175461)	total_loss: 1.132165 (1.191504)

[2023-05-05 05:08:47,255-rk0-log_helper.py#102] Progress: 10900 / 15625 [69%], Speed: 2.394 s/iter, ETA 0:03:08 (D:H:M)

[2023-05-05 05:09:34,551-rk0-train.py#348] Epoch: [18][295/625] lr: 0.000350
	batch_time: 2.361542 (2.394356)	data_time: 0.001364 (0.001856)
	loss_fool: 0.201010 (0.197120)	loss_train_adv: 0.000306 (0.001960)
	cen_loss: 0.611677 (0.613395)	cls_loss: 0.055487 (0.052012)
	loc_loss: 0.166357 (0.175626)	total_loss: 1.166234 (1.192286)

[2023-05-05 05:09:34,551-rk0-log_helper.py#102] Progress: 10920 / 15625 [69%], Speed: 2.394 s/iter, ETA 0:03:07 (D:H:M)

[2023-05-05 05:10:22,047-rk0-train.py#348] Epoch: [18][315/625] lr: 0.000350
	batch_time: 2.311058 (2.390842)	data_time: 0.001242 (0.001923)
	loss_fool: 0.207894 (0.197229)	loss_train_adv: 0.000811 (0.001955)
	cen_loss: 0.617155 (0.613394)	cls_loss: 0.063371 (0.053440)
	loc_loss: 0.194013 (0.176768)	total_loss: 1.262566 (1.197137)

[2023-05-05 05:10:22,048-rk0-log_helper.py#102] Progress: 10940 / 15625 [70%], Speed: 2.391 s/iter, ETA 0:03:06 (D:H:M)

[2023-05-05 05:11:09,468-rk0-train.py#348] Epoch: [18][335/625] lr: 0.000350
	batch_time: 2.385806 (2.387184)	data_time: 0.001127 (0.001797)
	loss_fool: 0.202126 (0.197267)	loss_train_adv: 0.006884 (0.002133)
	cen_loss: 0.617249 (0.613276)	cls_loss: 0.058736 (0.051664)
	loc_loss: 0.204189 (0.176514)	total_loss: 1.288551 (1.194482)

[2023-05-05 05:11:09,469-rk0-log_helper.py#102] Progress: 10960 / 15625 [70%], Speed: 2.387 s/iter, ETA 0:03:05 (D:H:M)

[2023-05-05 05:11:56,999-rk0-train.py#348] Epoch: [18][355/625] lr: 0.000350
	batch_time: 2.334393 (2.389948)	data_time: 0.001124 (0.002027)
	loss_fool: 0.187699 (0.197060)	loss_train_adv: 0.000243 (0.002064)
	cen_loss: 0.620178 (0.613088)	cls_loss: 0.034160 (0.050420)
	loc_loss: 0.176307 (0.176152)	total_loss: 1.183258 (1.191965)

[2023-05-05 05:11:56,999-rk0-log_helper.py#102] Progress: 10980 / 15625 [70%], Speed: 2.390 s/iter, ETA 0:03:05 (D:H:M)

[2023-05-05 05:12:44,311-rk0-train.py#348] Epoch: [18][375/625] lr: 0.000350
	batch_time: 2.486105 (2.367211)	data_time: 0.001167 (0.002163)
	loss_fool: 0.193533 (0.196934)	loss_train_adv: 0.001088 (0.002109)
	cen_loss: 0.612199 (0.612928)	cls_loss: 0.047017 (0.049678)
	loc_loss: 0.184989 (0.175329)	total_loss: 1.214185 (1.188594)

[2023-05-05 05:12:44,311-rk0-log_helper.py#102] Progress: 11000 / 15625 [70%], Speed: 2.367 s/iter, ETA 0:03:02 (D:H:M)

[2023-05-05 05:13:31,186-rk0-train.py#348] Epoch: [18][395/625] lr: 0.000350
	batch_time: 2.356102 (2.362978)	data_time: 0.001135 (0.002351)
	loss_fool: 0.201241 (0.197081)	loss_train_adv: 0.001764 (0.002004)
	cen_loss: 0.614151 (0.613215)	cls_loss: 0.047451 (0.048962)
	loc_loss: 0.150679 (0.174329)	total_loss: 1.113638 (1.185165)

[2023-05-05 05:13:31,186-rk0-log_helper.py#102] Progress: 11020 / 15625 [70%], Speed: 2.363 s/iter, ETA 0:03:01 (D:H:M)

[2023-05-05 05:14:18,865-rk0-train.py#348] Epoch: [18][415/625] lr: 0.000350
	batch_time: 2.317779 (2.365187)	data_time: 0.001116 (0.002269)
	loss_fool: 0.198689 (0.196750)	loss_train_adv: 0.000077 (0.002054)
	cen_loss: 0.612872 (0.613023)	cls_loss: 0.043391 (0.046855)
	loc_loss: 0.176799 (0.173850)	total_loss: 1.186659 (1.181429)

[2023-05-05 05:14:18,866-rk0-log_helper.py#102] Progress: 11040 / 15625 [70%], Speed: 2.365 s/iter, ETA 0:03:00 (D:H:M)

[2023-05-05 05:15:05,762-rk0-train.py#348] Epoch: [18][435/625] lr: 0.000350
	batch_time: 2.429029 (2.359607)	data_time: 0.011838 (0.002460)
	loss_fool: 0.195952 (0.197306)	loss_train_adv: 0.003187 (0.001810)
	cen_loss: 0.609677 (0.612877)	cls_loss: 0.035877 (0.045283)
	loc_loss: 0.175756 (0.172156)	total_loss: 1.172824 (1.174627)

[2023-05-05 05:15:05,763-rk0-log_helper.py#102] Progress: 11060 / 15625 [70%], Speed: 2.360 s/iter, ETA 0:02:59 (D:H:M)

[2023-05-05 05:15:53,279-rk0-train.py#348] Epoch: [18][455/625] lr: 0.000350
	batch_time: 2.329654 (2.359646)	data_time: 0.001314 (0.002438)
	loss_fool: 0.187692 (0.197016)	loss_train_adv: 0.015369 (0.002073)
	cen_loss: 0.607662 (0.612757)	cls_loss: 0.061128 (0.046591)
	loc_loss: 0.174970 (0.172047)	total_loss: 1.193699 (1.175490)

[2023-05-05 05:15:53,280-rk0-log_helper.py#102] Progress: 11080 / 15625 [70%], Speed: 2.360 s/iter, ETA 0:02:58 (D:H:M)

[2023-05-05 05:16:40,758-rk0-train.py#348] Epoch: [18][475/625] lr: 0.000350
	batch_time: 2.395985 (2.361449)	data_time: 0.001212 (0.002333)
	loss_fool: 0.200160 (0.196685)	loss_train_adv: 0.000389 (0.002225)
	cen_loss: 0.614722 (0.613200)	cls_loss: 0.036051 (0.047383)
	loc_loss: 0.173669 (0.173363)	total_loss: 1.171779 (1.180671)

[2023-05-05 05:16:40,758-rk0-log_helper.py#102] Progress: 11100 / 15625 [71%], Speed: 2.361 s/iter, ETA 0:02:58 (D:H:M)

[2023-05-05 05:17:29,746-rk0-train.py#348] Epoch: [18][495/625] lr: 0.000350
	batch_time: 2.430771 (2.382688)	data_time: 0.001467 (0.002211)
	loss_fool: 0.200082 (0.196581)	loss_train_adv: 0.000126 (0.002227)
	cen_loss: 0.617239 (0.612691)	cls_loss: 0.040472 (0.046921)
	loc_loss: 0.161365 (0.173386)	total_loss: 1.141808 (1.179770)

[2023-05-05 05:17:29,748-rk0-log_helper.py#102] Progress: 11120 / 15625 [71%], Speed: 2.383 s/iter, ETA 0:02:58 (D:H:M)

[2023-05-05 05:18:16,695-rk0-train.py#348] Epoch: [18][515/625] lr: 0.000350
	batch_time: 2.274664 (2.375377)	data_time: 0.001180 (0.002137)
	loss_fool: 0.201022 (0.197117)	loss_train_adv: 0.000066 (0.002003)
	cen_loss: 0.615292 (0.613048)	cls_loss: 0.038412 (0.047983)
	loc_loss: 0.164821 (0.173520)	total_loss: 1.148167 (1.181592)

[2023-05-05 05:18:16,696-rk0-log_helper.py#102] Progress: 11140 / 15625 [71%], Speed: 2.375 s/iter, ETA 0:02:57 (D:H:M)

[2023-05-05 05:19:03,398-rk0-train.py#348] Epoch: [18][535/625] lr: 0.000350
	batch_time: 2.276992 (2.373811)	data_time: 0.001146 (0.002183)
	loss_fool: 0.193284 (0.196664)	loss_train_adv: 0.000244 (0.002098)
	cen_loss: 0.609518 (0.613637)	cls_loss: 0.034603 (0.049032)
	loc_loss: 0.158585 (0.173600)	total_loss: 1.119876 (1.183468)

[2023-05-05 05:19:03,399-rk0-log_helper.py#102] Progress: 11160 / 15625 [71%], Speed: 2.374 s/iter, ETA 0:02:56 (D:H:M)

[2023-05-05 05:19:49,054-rk0-train.py#348] Epoch: [18][555/625] lr: 0.000350
	batch_time: 2.336179 (2.355448)	data_time: 0.001899 (0.002105)
	loss_fool: 0.191968 (0.196747)	loss_train_adv: 0.006703 (0.001841)
	cen_loss: 0.606192 (0.613400)	cls_loss: 0.037338 (0.047851)
	loc_loss: 0.170849 (0.172813)	total_loss: 1.156077 (1.179689)

[2023-05-05 05:19:49,055-rk0-log_helper.py#102] Progress: 11180 / 15625 [71%], Speed: 2.355 s/iter, ETA 0:02:54 (D:H:M)

[2023-05-05 05:20:33,992-rk0-train.py#348] Epoch: [18][575/625] lr: 0.000350
	batch_time: 2.109980 (2.330165)	data_time: 0.000574 (0.001790)
	loss_fool: 0.196937 (0.197475)	loss_train_adv: 0.003096 (0.001722)
	cen_loss: 0.615552 (0.612821)	cls_loss: 0.040152 (0.047591)
	loc_loss: 0.152736 (0.171824)	total_loss: 1.113911 (1.175883)

[2023-05-05 05:20:33,993-rk0-log_helper.py#102] Progress: 11200 / 15625 [71%], Speed: 2.330 s/iter, ETA 0:02:51 (D:H:M)

[2023-05-05 05:21:16,494-rk0-train.py#348] Epoch: [18][595/625] lr: 0.000350
	batch_time: 2.098216 (2.265518)	data_time: 0.000890 (0.001526)
	loss_fool: 0.184193 (0.197030)	loss_train_adv: 0.001578 (0.001925)
	cen_loss: 0.617209 (0.613456)	cls_loss: 0.058815 (0.048250)
	loc_loss: 0.215878 (0.172322)	total_loss: 1.323658 (1.178673)

[2023-05-05 05:21:16,495-rk0-log_helper.py#102] Progress: 11220 / 15625 [71%], Speed: 2.266 s/iter, ETA 0:02:46 (D:H:M)

[2023-05-05 05:21:58,792-rk0-train.py#348] Epoch: [18][615/625] lr: 0.000350
	batch_time: 2.110474 (2.219280)	data_time: 0.000519 (0.001372)
	loss_fool: 0.204921 (0.196841)	loss_train_adv: 0.000903 (0.002130)
	cen_loss: 0.611859 (0.613133)	cls_loss: 0.047897 (0.048740)
	loc_loss: 0.176045 (0.171380)	total_loss: 1.187890 (1.176014)

[2023-05-05 05:21:58,794-rk0-log_helper.py#102] Progress: 11240 / 15625 [71%], Speed: 2.219 s/iter, ETA 0:02:42 (D:H:M)

[2023-05-05 05:22:21,099-rk0-train.py#235] epoch: 19
[2023-05-05 05:22:21,099-rk0-train.py#240] epoch 19 lr 3.103707121672185e-05
[2023-05-05 05:22:21,100-rk0-train.py#240] epoch 19 lr 0.0003103707121672185
[2023-05-05 05:22:21,100-rk0-train.py#240] epoch 19 lr 0.001034569040557395
[2023-05-05 05:22:21,101-rk0-train.py#240] epoch 19 lr 0.0003103707121672185
[2023-05-05 05:22:21,101-rk0-train.py#240] epoch 19 lr 0.0003103707121672185
[2023-05-05 05:22:42,228-rk0-train.py#348] Epoch: [19][10/625] lr: 0.000310
	batch_time: 2.103931 (2.186774)	data_time: 0.000532 (0.012497)
	loss_fool: 0.206484 (0.197173)	loss_train_adv: 0.001399 (0.002026)
	cen_loss: 0.614562 (0.612601)	cls_loss: 0.068969 (0.047883)
	loc_loss: 0.193308 (0.171396)	total_loss: 1.263456 (1.174671)

[2023-05-05 05:22:42,229-rk0-log_helper.py#102] Progress: 11260 / 15625 [72%], Speed: 2.187 s/iter, ETA 0:02:39 (D:H:M)

[2023-05-05 05:23:24,429-rk0-train.py#348] Epoch: [19][30/625] lr: 0.000310
	batch_time: 2.108025 (2.152292)	data_time: 0.000523 (0.012235)
	loss_fool: 0.194089 (0.197533)	loss_train_adv: 0.004755 (0.001969)
	cen_loss: 0.596356 (0.612674)	cls_loss: 0.050198 (0.049600)
	loc_loss: 0.149392 (0.173237)	total_loss: 1.094731 (1.181986)

[2023-05-05 05:23:24,430-rk0-log_helper.py#102] Progress: 11280 / 15625 [72%], Speed: 2.152 s/iter, ETA 0:02:35 (D:H:M)

[2023-05-05 05:24:08,027-rk0-train.py#348] Epoch: [19][50/625] lr: 0.000310
	batch_time: 2.111980 (2.138932)	data_time: 0.000571 (0.012109)
	loss_fool: 0.201046 (0.197126)	loss_train_adv: 0.000276 (0.001987)
	cen_loss: 0.610833 (0.612787)	cls_loss: 0.041472 (0.049747)
	loc_loss: 0.157490 (0.172588)	total_loss: 1.124775 (1.180298)

[2023-05-05 05:24:08,028-rk0-log_helper.py#102] Progress: 11300 / 15625 [72%], Speed: 2.139 s/iter, ETA 0:02:34 (D:H:M)

[2023-05-05 05:24:50,194-rk0-train.py#348] Epoch: [19][70/625] lr: 0.000310
	batch_time: 2.095026 (2.135573)	data_time: 0.000548 (0.012037)
	loss_fool: 0.198372 (0.197730)	loss_train_adv: 0.000727 (0.001837)
	cen_loss: 0.602085 (0.612635)	cls_loss: 0.035584 (0.049461)
	loc_loss: 0.123775 (0.172112)	total_loss: 1.008995 (1.178431)

[2023-05-05 05:24:50,195-rk0-log_helper.py#102] Progress: 11320 / 15625 [72%], Speed: 2.136 s/iter, ETA 0:02:33 (D:H:M)

[2023-05-05 05:25:32,145-rk0-train.py#348] Epoch: [19][90/625] lr: 0.000310
	batch_time: 2.074914 (2.132113)	data_time: 0.000470 (0.012030)
	loss_fool: 0.198657 (0.197629)	loss_train_adv: 0.000582 (0.001818)
	cen_loss: 0.611353 (0.612585)	cls_loss: 0.033788 (0.050600)
	loc_loss: 0.135448 (0.172285)	total_loss: 1.051484 (1.180039)

[2023-05-05 05:25:32,146-rk0-log_helper.py#102] Progress: 11340 / 15625 [72%], Speed: 2.132 s/iter, ETA 0:02:32 (D:H:M)

[2023-05-05 05:26:13,854-rk0-train.py#348] Epoch: [19][110/625] lr: 0.000310
	batch_time: 2.078340 (2.114898)	data_time: 0.000457 (0.000554)
	loss_fool: 0.196751 (0.197484)	loss_train_adv: 0.002789 (0.002000)
	cen_loss: 0.618629 (0.612843)	cls_loss: 0.043328 (0.050717)
	loc_loss: 0.193594 (0.173248)	total_loss: 1.242739 (1.183303)

[2023-05-05 05:26:13,855-rk0-log_helper.py#102] Progress: 11360 / 15625 [72%], Speed: 2.115 s/iter, ETA 0:02:30 (D:H:M)

[2023-05-05 05:26:55,518-rk0-train.py#348] Epoch: [19][130/625] lr: 0.000310
	batch_time: 2.130253 (2.109595)	data_time: 0.000613 (0.000561)
	loss_fool: 0.195206 (0.196915)	loss_train_adv: 0.004275 (0.002080)
	cen_loss: 0.612912 (0.613302)	cls_loss: 0.034923 (0.049032)
	loc_loss: 0.175839 (0.172072)	total_loss: 1.175352 (1.178551)

[2023-05-05 05:26:55,519-rk0-log_helper.py#102] Progress: 11380 / 15625 [72%], Speed: 2.110 s/iter, ETA 0:02:29 (D:H:M)

[2023-05-05 05:27:37,093-rk0-train.py#348] Epoch: [19][150/625] lr: 0.000310
	batch_time: 2.067960 (2.089425)	data_time: 0.000628 (0.000551)
	loss_fool: 0.199864 (0.197253)	loss_train_adv: 0.000624 (0.002196)
	cen_loss: 0.619718 (0.613188)	cls_loss: 0.039419 (0.048243)
	loc_loss: 0.157781 (0.171368)	total_loss: 1.132479 (1.175535)

[2023-05-05 05:27:37,094-rk0-log_helper.py#102] Progress: 11400 / 15625 [72%], Speed: 2.089 s/iter, ETA 0:02:27 (D:H:M)

[2023-05-05 05:28:18,719-rk0-train.py#348] Epoch: [19][170/625] lr: 0.000310
	batch_time: 2.081817 (2.084078)	data_time: 0.000702 (0.000560)
	loss_fool: 0.198104 (0.196843)	loss_train_adv: 0.002806 (0.002222)
	cen_loss: 0.618408 (0.613241)	cls_loss: 0.040098 (0.048849)
	loc_loss: 0.166799 (0.172728)	total_loss: 1.158901 (1.180274)

[2023-05-05 05:28:18,720-rk0-log_helper.py#102] Progress: 11420 / 15625 [73%], Speed: 2.084 s/iter, ETA 0:02:26 (D:H:M)

[2023-05-05 05:29:00,303-rk0-train.py#348] Epoch: [19][190/625] lr: 0.000310
	batch_time: 2.079113 (2.080449)	data_time: 0.000477 (0.000542)
	loss_fool: 0.200308 (0.197040)	loss_train_adv: 0.003268 (0.002031)
	cen_loss: 0.603657 (0.613387)	cls_loss: 0.027983 (0.047901)
	loc_loss: 0.121860 (0.172757)	total_loss: 0.997219 (1.179559)

[2023-05-05 05:29:00,303-rk0-log_helper.py#102] Progress: 11440 / 15625 [73%], Speed: 2.080 s/iter, ETA 0:02:25 (D:H:M)

[2023-05-05 05:29:41,947-rk0-train.py#348] Epoch: [19][210/625] lr: 0.000310
	batch_time: 2.088261 (2.079814)	data_time: 0.000670 (0.000533)
	loss_fool: 0.199415 (0.196589)	loss_train_adv: 0.003729 (0.002231)
	cen_loss: 0.622991 (0.613126)	cls_loss: 0.048942 (0.047921)
	loc_loss: 0.186599 (0.172164)	total_loss: 1.231729 (1.177540)

[2023-05-05 05:29:41,948-rk0-log_helper.py#102] Progress: 11460 / 15625 [73%], Speed: 2.080 s/iter, ETA 0:02:24 (D:H:M)

[2023-05-05 05:30:23,545-rk0-train.py#348] Epoch: [19][230/625] lr: 0.000310
	batch_time: 2.075966 (2.079143)	data_time: 0.000681 (0.000526)
	loss_fool: 0.199889 (0.197127)	loss_train_adv: 0.000157 (0.002259)
	cen_loss: 0.613703 (0.613095)	cls_loss: 0.044332 (0.049275)
	loc_loss: 0.162263 (0.173318)	total_loss: 1.144823 (1.182325)

[2023-05-05 05:30:23,545-rk0-log_helper.py#102] Progress: 11480 / 15625 [73%], Speed: 2.079 s/iter, ETA 0:02:23 (D:H:M)

[2023-05-05 05:31:05,280-rk0-train.py#348] Epoch: [19][250/625] lr: 0.000310
	batch_time: 2.078218 (2.080728)	data_time: 0.000364 (0.000529)
	loss_fool: 0.197148 (0.196059)	loss_train_adv: 0.000725 (0.002477)
	cen_loss: 0.612959 (0.613173)	cls_loss: 0.039792 (0.049260)
	loc_loss: 0.158883 (0.174618)	total_loss: 1.129401 (1.186288)

[2023-05-05 05:31:05,281-rk0-log_helper.py#102] Progress: 11500 / 15625 [73%], Speed: 2.081 s/iter, ETA 0:02:23 (D:H:M)

[2023-05-05 05:31:48,073-rk0-train.py#348] Epoch: [19][270/625] lr: 0.000310
	batch_time: 2.087119 (2.092400)	data_time: 0.000563 (0.000505)
	loss_fool: 0.197708 (0.196579)	loss_train_adv: 0.000958 (0.002520)
	cen_loss: 0.606175 (0.612847)	cls_loss: 0.045574 (0.048329)
	loc_loss: 0.160155 (0.173601)	total_loss: 1.132214 (1.181980)

[2023-05-05 05:31:48,075-rk0-log_helper.py#102] Progress: 11520 / 15625 [73%], Speed: 2.092 s/iter, ETA 0:02:23 (D:H:M)

[2023-05-05 05:32:29,598-rk0-train.py#348] Epoch: [19][290/625] lr: 0.000310
	batch_time: 2.061719 (2.091809)	data_time: 0.000138 (0.000499)
	loss_fool: 0.202520 (0.196228)	loss_train_adv: 0.000136 (0.002584)
	cen_loss: 0.621055 (0.612693)	cls_loss: 0.044454 (0.046471)
	loc_loss: 0.205007 (0.173775)	total_loss: 1.280529 (1.180488)

[2023-05-05 05:32:29,598-rk0-log_helper.py#102] Progress: 11540 / 15625 [73%], Speed: 2.092 s/iter, ETA 0:02:22 (D:H:M)

[2023-05-05 05:33:11,308-rk0-train.py#348] Epoch: [19][310/625] lr: 0.000310
	batch_time: 2.092508 (2.092459)	data_time: 0.000709 (0.000527)
	loss_fool: 0.195273 (0.197041)	loss_train_adv: 0.001275 (0.002101)
	cen_loss: 0.605778 (0.612923)	cls_loss: 0.045409 (0.046683)
	loc_loss: 0.168298 (0.174503)	total_loss: 1.156081 (1.183116)

[2023-05-05 05:33:11,310-rk0-log_helper.py#102] Progress: 11560 / 15625 [73%], Speed: 2.092 s/iter, ETA 0:02:21 (D:H:M)

[2023-05-05 05:33:52,928-rk0-train.py#348] Epoch: [19][330/625] lr: 0.000310
	batch_time: 2.093517 (2.092670)	data_time: 0.001255 (0.000533)
	loss_fool: 0.196000 (0.197114)	loss_train_adv: 0.001844 (0.001976)
	cen_loss: 0.622315 (0.613023)	cls_loss: 0.071549 (0.046726)
	loc_loss: 0.200081 (0.174014)	total_loss: 1.294109 (1.181791)

[2023-05-05 05:33:52,928-rk0-log_helper.py#102] Progress: 11580 / 15625 [74%], Speed: 2.093 s/iter, ETA 0:02:21 (D:H:M)

[2023-05-05 05:34:34,561-rk0-train.py#348] Epoch: [19][350/625] lr: 0.000310
	batch_time: 2.077067 (2.091668)	data_time: 0.000335 (0.000526)
	loss_fool: 0.197531 (0.198049)	loss_train_adv: 0.000547 (0.001518)
	cen_loss: 0.612849 (0.612840)	cls_loss: 0.049919 (0.047227)
	loc_loss: 0.165885 (0.173483)	total_loss: 1.160423 (1.180517)

[2023-05-05 05:34:34,562-rk0-log_helper.py#102] Progress: 11600 / 15625 [74%], Speed: 2.092 s/iter, ETA 0:02:20 (D:H:M)

[2023-05-05 05:35:16,243-rk0-train.py#348] Epoch: [19][370/625] lr: 0.000310
	batch_time: 2.085167 (2.080563)	data_time: 0.000652 (0.000535)
	loss_fool: 0.200817 (0.197959)	loss_train_adv: 0.006683 (0.001465)
	cen_loss: 0.617947 (0.612982)	cls_loss: 0.049111 (0.047002)
	loc_loss: 0.209141 (0.173069)	total_loss: 1.294482 (1.179190)

[2023-05-05 05:35:16,244-rk0-log_helper.py#102] Progress: 11620 / 15625 [74%], Speed: 2.081 s/iter, ETA 0:02:18 (D:H:M)

[2023-05-05 05:35:57,973-rk0-train.py#348] Epoch: [19][390/625] lr: 0.000310
	batch_time: 2.074354 (2.082601)	data_time: 0.000595 (0.000575)
	loss_fool: 0.199288 (0.197777)	loss_train_adv: 0.000542 (0.001590)
	cen_loss: 0.607073 (0.613008)	cls_loss: 0.033547 (0.047504)
	loc_loss: 0.146813 (0.172622)	total_loss: 1.081058 (1.178377)

[2023-05-05 05:35:57,974-rk0-log_helper.py#102] Progress: 11640 / 15625 [74%], Speed: 2.083 s/iter, ETA 0:02:18 (D:H:M)

[2023-05-05 05:36:39,597-rk0-train.py#348] Epoch: [19][410/625] lr: 0.000310
	batch_time: 2.077244 (2.081737)	data_time: 0.000342 (0.000556)
	loss_fool: 0.191359 (0.197544)	loss_train_adv: 0.004424 (0.001781)
	cen_loss: 0.617506 (0.613234)	cls_loss: 0.080607 (0.047983)
	loc_loss: 0.190371 (0.172796)	total_loss: 1.269226 (1.179605)

[2023-05-05 05:36:39,598-rk0-log_helper.py#102] Progress: 11660 / 15625 [74%], Speed: 2.082 s/iter, ETA 0:02:17 (D:H:M)

[2023-05-05 05:37:21,206-rk0-train.py#348] Epoch: [19][430/625] lr: 0.000310
	batch_time: 2.069927 (2.081632)	data_time: 0.000557 (0.000551)
	loss_fool: 0.201441 (0.197474)	loss_train_adv: 0.002243 (0.001704)
	cen_loss: 0.613048 (0.613073)	cls_loss: 0.069757 (0.048131)
	loc_loss: 0.177985 (0.173486)	total_loss: 1.216759 (1.181661)

[2023-05-05 05:37:21,207-rk0-log_helper.py#102] Progress: 11680 / 15625 [74%], Speed: 2.082 s/iter, ETA 0:02:16 (D:H:M)

[2023-05-05 05:38:03,897-rk0-train.py#348] Epoch: [19][450/625] lr: 0.000310
	batch_time: 2.097042 (2.092195)	data_time: 0.000707 (0.000549)
	loss_fool: 0.197967 (0.197595)	loss_train_adv: 0.000101 (0.001763)
	cen_loss: 0.609960 (0.613507)	cls_loss: 0.049543 (0.048307)
	loc_loss: 0.177010 (0.173979)	total_loss: 1.190535 (1.183751)

[2023-05-05 05:38:03,897-rk0-log_helper.py#102] Progress: 11700 / 15625 [74%], Speed: 2.092 s/iter, ETA 0:02:16 (D:H:M)

[2023-05-05 05:38:45,556-rk0-train.py#348] Epoch: [19][470/625] lr: 0.000310
	batch_time: 2.084749 (2.091961)	data_time: 0.000673 (0.000566)
	loss_fool: 0.197428 (0.197625)	loss_train_adv: 0.000557 (0.001595)
	cen_loss: 0.612571 (0.613232)	cls_loss: 0.040015 (0.047532)
	loc_loss: 0.144806 (0.173308)	total_loss: 1.087005 (1.180690)

[2023-05-05 05:38:45,558-rk0-log_helper.py#102] Progress: 11720 / 15625 [75%], Speed: 2.092 s/iter, ETA 0:02:16 (D:H:M)

[2023-05-05 05:39:27,228-rk0-train.py#348] Epoch: [19][490/625] lr: 0.000310
	batch_time: 2.071478 (2.091372)	data_time: 0.000640 (0.000573)
	loss_fool: 0.197122 (0.197673)	loss_train_adv: 0.006238 (0.001701)
	cen_loss: 0.614482 (0.612902)	cls_loss: 0.046016 (0.047201)
	loc_loss: 0.192878 (0.173724)	total_loss: 1.239130 (1.181274)

[2023-05-05 05:39:27,228-rk0-log_helper.py#102] Progress: 11740 / 15625 [75%], Speed: 2.091 s/iter, ETA 0:02:15 (D:H:M)

[2023-05-05 05:40:08,849-rk0-train.py#348] Epoch: [19][510/625] lr: 0.000310
	batch_time: 2.068307 (2.091358)	data_time: 0.000372 (0.000570)
	loss_fool: 0.190290 (0.196914)	loss_train_adv: 0.002299 (0.002141)
	cen_loss: 0.609739 (0.612381)	cls_loss: 0.070489 (0.046470)
	loc_loss: 0.205646 (0.173497)	total_loss: 1.297165 (1.179341)

[2023-05-05 05:40:08,850-rk0-log_helper.py#102] Progress: 11760 / 15625 [75%], Speed: 2.091 s/iter, ETA 0:02:14 (D:H:M)

[2023-05-05 05:40:50,600-rk0-train.py#348] Epoch: [19][530/625] lr: 0.000310
	batch_time: 2.097718 (2.092796)	data_time: 0.000273 (0.000610)
	loss_fool: 0.196519 (0.196804)	loss_train_adv: 0.000252 (0.002365)
	cen_loss: 0.618493 (0.612352)	cls_loss: 0.075264 (0.046092)
	loc_loss: 0.204740 (0.171474)	total_loss: 1.307977 (1.172866)

[2023-05-05 05:40:50,601-rk0-log_helper.py#102] Progress: 11780 / 15625 [75%], Speed: 2.093 s/iter, ETA 0:02:14 (D:H:M)

[2023-05-05 05:41:32,238-rk0-train.py#348] Epoch: [19][550/625] lr: 0.000310
	batch_time: 2.063019 (2.082284)	data_time: 0.000422 (0.000618)
	loss_fool: 0.197817 (0.196611)	loss_train_adv: 0.000331 (0.002366)
	cen_loss: 0.614689 (0.612214)	cls_loss: 0.057427 (0.045266)
	loc_loss: 0.186187 (0.170305)	total_loss: 1.230676 (1.168394)

[2023-05-05 05:41:32,239-rk0-log_helper.py#102] Progress: 11800 / 15625 [75%], Speed: 2.082 s/iter, ETA 0:02:12 (D:H:M)

[2023-05-05 05:42:13,728-rk0-train.py#348] Epoch: [19][570/625] lr: 0.000310
	batch_time: 2.090375 (2.080576)	data_time: 0.000295 (0.000583)
	loss_fool: 0.208927 (0.196485)	loss_train_adv: 0.000171 (0.002562)
	cen_loss: 0.613877 (0.612610)	cls_loss: 0.037926 (0.046307)
	loc_loss: 0.152608 (0.171168)	total_loss: 1.109628 (1.172420)

[2023-05-05 05:42:13,730-rk0-log_helper.py#102] Progress: 11820 / 15625 [75%], Speed: 2.081 s/iter, ETA 0:02:11 (D:H:M)

[2023-05-05 05:42:55,392-rk0-train.py#348] Epoch: [19][590/625] lr: 0.000310
	batch_time: 2.081526 (2.080485)	data_time: 0.000171 (0.000538)
	loss_fool: 0.200100 (0.196699)	loss_train_adv: 0.000594 (0.002464)
	cen_loss: 0.612605 (0.613053)	cls_loss: 0.037462 (0.047196)
	loc_loss: 0.179852 (0.171413)	total_loss: 1.189623 (1.174488)

[2023-05-05 05:42:55,394-rk0-log_helper.py#102] Progress: 11840 / 15625 [75%], Speed: 2.080 s/iter, ETA 0:02:11 (D:H:M)

[2023-05-05 05:43:36,965-rk0-train.py#348] Epoch: [19][610/625] lr: 0.000310
	batch_time: 2.079826 (2.079911)	data_time: 0.000137 (0.000521)
	loss_fool: 0.201782 (0.197400)	loss_train_adv: 0.002876 (0.001964)
	cen_loss: 0.614002 (0.613426)	cls_loss: 0.041389 (0.047559)
	loc_loss: 0.187546 (0.170072)	total_loss: 1.218030 (1.171202)

[2023-05-05 05:43:36,965-rk0-log_helper.py#102] Progress: 11860 / 15625 [75%], Speed: 2.080 s/iter, ETA 0:02:10 (D:H:M)

[2023-05-05 05:44:09,883-rk0-train.py#235] epoch: 20
[2023-05-05 05:44:09,883-rk0-train.py#240] epoch 20 lr 2.7494710662486532e-05
[2023-05-05 05:44:09,884-rk0-train.py#240] epoch 20 lr 0.00027494710662486534
[2023-05-05 05:44:09,884-rk0-train.py#240] epoch 20 lr 0.0009164903554162178
[2023-05-05 05:44:09,884-rk0-train.py#240] epoch 20 lr 0.00027494710662486534
[2023-05-05 05:44:09,884-rk0-train.py#240] epoch 20 lr 0.00027494710662486534
[2023-05-05 05:44:20,291-rk0-train.py#348] Epoch: [20][5/625] lr: 0.000275
	batch_time: 2.088740 (2.095640)	data_time: 0.001298 (0.007838)
	loss_fool: 0.190013 (0.197680)	loss_train_adv: 0.003066 (0.001729)
	cen_loss: 0.617397 (0.613547)	cls_loss: 0.036237 (0.048260)
	loc_loss: 0.150351 (0.170422)	total_loss: 1.104687 (1.173073)

[2023-05-05 05:44:20,292-rk0-log_helper.py#102] Progress: 11880 / 15625 [76%], Speed: 2.096 s/iter, ETA 0:02:10 (D:H:M)

[2023-05-05 05:45:02,019-rk0-train.py#348] Epoch: [20][25/625] lr: 0.000275
	batch_time: 2.082700 (2.096514)	data_time: 0.000491 (0.007810)
	loss_fool: 0.200937 (0.197878)	loss_train_adv: 0.000216 (0.001713)
	cen_loss: 0.615078 (0.613716)	cls_loss: 0.045573 (0.049092)
	loc_loss: 0.196307 (0.171369)	total_loss: 1.249573 (1.176915)

[2023-05-05 05:45:02,021-rk0-log_helper.py#102] Progress: 11900 / 15625 [76%], Speed: 2.097 s/iter, ETA 0:02:10 (D:H:M)

[2023-05-05 05:45:43,718-rk0-train.py#348] Epoch: [20][45/625] lr: 0.000275
	batch_time: 2.069638 (2.098589)	data_time: 0.000537 (0.007813)
	loss_fool: 0.192894 (0.197906)	loss_train_adv: 0.006903 (0.001706)
	cen_loss: 0.609554 (0.613105)	cls_loss: 0.032316 (0.049339)
	loc_loss: 0.161451 (0.172278)	total_loss: 1.126223 (1.179278)

[2023-05-05 05:45:43,718-rk0-log_helper.py#102] Progress: 11920 / 15625 [76%], Speed: 2.099 s/iter, ETA 0:02:09 (D:H:M)

[2023-05-05 05:46:25,430-rk0-train.py#348] Epoch: [20][65/625] lr: 0.000275
	batch_time: 2.090336 (2.099085)	data_time: 0.000774 (0.007827)
	loss_fool: 0.193657 (0.196968)	loss_train_adv: 0.000780 (0.001889)
	cen_loss: 0.614727 (0.613336)	cls_loss: 0.053620 (0.048523)
	loc_loss: 0.166338 (0.171143)	total_loss: 1.167361 (1.175288)

[2023-05-05 05:46:25,430-rk0-log_helper.py#102] Progress: 11940 / 15625 [76%], Speed: 2.099 s/iter, ETA 0:02:08 (D:H:M)

[2023-05-05 05:47:07,147-rk0-train.py#348] Epoch: [20][85/625] lr: 0.000275
	batch_time: 2.087923 (2.100616)	data_time: 0.000689 (0.007849)
	loss_fool: 0.199014 (0.196976)	loss_train_adv: 0.002230 (0.001950)
	cen_loss: 0.619887 (0.613198)	cls_loss: 0.036595 (0.048654)
	loc_loss: 0.168920 (0.172473)	total_loss: 1.163241 (1.179271)

[2023-05-05 05:47:07,149-rk0-log_helper.py#102] Progress: 11960 / 15625 [76%], Speed: 2.101 s/iter, ETA 0:02:08 (D:H:M)

[2023-05-05 05:47:48,818-rk0-train.py#348] Epoch: [20][105/625] lr: 0.000275
	batch_time: 2.092578 (2.084056)	data_time: 0.000695 (0.000471)
	loss_fool: 0.201222 (0.197103)	loss_train_adv: 0.003676 (0.002130)
	cen_loss: 0.621086 (0.613110)	cls_loss: 0.039547 (0.048524)
	loc_loss: 0.178802 (0.172944)	total_loss: 1.197038 (1.180467)

[2023-05-05 05:47:48,820-rk0-log_helper.py#102] Progress: 11980 / 15625 [76%], Speed: 2.084 s/iter, ETA 0:02:06 (D:H:M)

[2023-05-05 05:48:30,557-rk0-train.py#348] Epoch: [20][125/625] lr: 0.000275
	batch_time: 2.091480 (2.084154)	data_time: 0.000664 (0.000494)
	loss_fool: 0.199949 (0.196861)	loss_train_adv: 0.000364 (0.002137)
	cen_loss: 0.614113 (0.612974)	cls_loss: 0.051627 (0.047775)
	loc_loss: 0.179559 (0.172829)	total_loss: 1.204417 (1.179236)

[2023-05-05 05:48:30,559-rk0-log_helper.py#102] Progress: 12000 / 15625 [76%], Speed: 2.084 s/iter, ETA 0:02:05 (D:H:M)

[2023-05-05 05:49:12,141-rk0-train.py#348] Epoch: [20][145/625] lr: 0.000275
	batch_time: 2.084574 (2.083027)	data_time: 0.000636 (0.000521)
	loss_fool: 0.192828 (0.196970)	loss_train_adv: 0.000730 (0.001922)
	cen_loss: 0.597899 (0.613580)	cls_loss: 0.034167 (0.048147)
	loc_loss: 0.165170 (0.171804)	total_loss: 1.127576 (1.177138)

[2023-05-05 05:49:12,143-rk0-log_helper.py#102] Progress: 12020 / 15625 [76%], Speed: 2.083 s/iter, ETA 0:02:05 (D:H:M)

[2023-05-05 05:49:53,741-rk0-train.py#348] Epoch: [20][165/625] lr: 0.000275
	batch_time: 2.087846 (2.081885)	data_time: 0.000151 (0.000502)
	loss_fool: 0.203731 (0.198034)	loss_train_adv: 0.000082 (0.001584)
	cen_loss: 0.614201 (0.613113)	cls_loss: 0.049475 (0.047685)
	loc_loss: 0.178493 (0.172172)	total_loss: 1.199154 (1.177315)

[2023-05-05 05:49:53,742-rk0-log_helper.py#102] Progress: 12040 / 15625 [77%], Speed: 2.082 s/iter, ETA 0:02:04 (D:H:M)

[2023-05-05 05:50:35,481-rk0-train.py#348] Epoch: [20][185/625] lr: 0.000275
	batch_time: 2.085710 (2.082101)	data_time: 0.000505 (0.000483)
	loss_fool: 0.194464 (0.197600)	loss_train_adv: 0.002053 (0.001551)
	cen_loss: 0.616390 (0.613157)	cls_loss: 0.027948 (0.047619)
	loc_loss: 0.150835 (0.172473)	total_loss: 1.096843 (1.178195)

[2023-05-05 05:50:35,482-rk0-log_helper.py#102] Progress: 12060 / 15625 [77%], Speed: 2.082 s/iter, ETA 0:02:03 (D:H:M)

[2023-05-05 05:51:17,184-rk0-train.py#348] Epoch: [20][205/625] lr: 0.000275
	batch_time: 2.089641 (2.082414)	data_time: 0.000691 (0.000494)
	loss_fool: 0.203131 (0.197838)	loss_train_adv: 0.001323 (0.001375)
	cen_loss: 0.604539 (0.613204)	cls_loss: 0.034948 (0.046399)
	loc_loss: 0.157554 (0.171301)	total_loss: 1.112150 (1.173505)

[2023-05-05 05:51:17,184-rk0-log_helper.py#102] Progress: 12080 / 15625 [77%], Speed: 2.082 s/iter, ETA 0:02:03 (D:H:M)

[2023-05-05 05:52:00,185-rk0-train.py#348] Epoch: [20][225/625] lr: 0.000275
	batch_time: 2.082884 (2.095048)	data_time: 0.000321 (0.000483)
	loss_fool: 0.200935 (0.198020)	loss_train_adv: 0.001476 (0.001282)
	cen_loss: 0.607839 (0.613255)	cls_loss: 0.077291 (0.046790)
	loc_loss: 0.166977 (0.171013)	total_loss: 1.186062 (1.173084)

[2023-05-05 05:52:00,187-rk0-log_helper.py#102] Progress: 12100 / 15625 [77%], Speed: 2.095 s/iter, ETA 0:02:03 (D:H:M)

[2023-05-05 05:52:41,910-rk0-train.py#348] Epoch: [20][245/625] lr: 0.000275
	batch_time: 2.079714 (2.096436)	data_time: 0.000305 (0.000453)
	loss_fool: 0.202294 (0.197918)	loss_train_adv: 0.000100 (0.001424)
	cen_loss: 0.610726 (0.613165)	cls_loss: 0.047886 (0.047297)
	loc_loss: 0.157498 (0.172192)	total_loss: 1.131105 (1.177037)

[2023-05-05 05:52:41,911-rk0-log_helper.py#102] Progress: 12120 / 15625 [77%], Speed: 2.096 s/iter, ETA 0:02:02 (D:H:M)

[2023-05-05 05:53:23,578-rk0-train.py#348] Epoch: [20][265/625] lr: 0.000275
	batch_time: 2.067183 (2.097150)	data_time: 0.000590 (0.000489)
	loss_fool: 0.202172 (0.197790)	loss_train_adv: 0.000967 (0.001523)
	cen_loss: 0.615640 (0.613408)	cls_loss: 0.042837 (0.048504)
	loc_loss: 0.166663 (0.173045)	total_loss: 1.158468 (1.181047)

[2023-05-05 05:53:23,579-rk0-log_helper.py#102] Progress: 12140 / 15625 [77%], Speed: 2.097 s/iter, ETA 0:02:01 (D:H:M)

[2023-05-05 05:54:05,201-rk0-train.py#348] Epoch: [20][285/625] lr: 0.000275
	batch_time: 2.074075 (2.095980)	data_time: 0.000625 (0.000511)
	loss_fool: 0.197892 (0.198107)	loss_train_adv: 0.001685 (0.001566)
	cen_loss: 0.613894 (0.613256)	cls_loss: 0.038104 (0.048676)
	loc_loss: 0.167333 (0.173371)	total_loss: 1.153995 (1.182045)

[2023-05-05 05:54:05,201-rk0-log_helper.py#102] Progress: 12160 / 15625 [77%], Speed: 2.096 s/iter, ETA 0:02:01 (D:H:M)

[2023-05-05 05:54:46,929-rk0-train.py#348] Epoch: [20][305/625] lr: 0.000275
	batch_time: 2.087562 (2.096264)	data_time: 0.000698 (0.000523)
	loss_fool: 0.195634 (0.197620)	loss_train_adv: 0.000112 (0.001648)
	cen_loss: 0.603506 (0.612949)	cls_loss: 0.052320 (0.048616)
	loc_loss: 0.171921 (0.174201)	total_loss: 1.171587 (1.184167)

[2023-05-05 05:54:46,930-rk0-log_helper.py#102] Progress: 12180 / 15625 [77%], Speed: 2.096 s/iter, ETA 0:02:00 (D:H:M)

[2023-05-05 05:55:28,635-rk0-train.py#348] Epoch: [20][325/625] lr: 0.000275
	batch_time: 2.122899 (2.083289)	data_time: 0.000667 (0.000518)
	loss_fool: 0.198004 (0.197543)	loss_train_adv: 0.005919 (0.001672)
	cen_loss: 0.614044 (0.612898)	cls_loss: 0.079521 (0.049574)
	loc_loss: 0.211059 (0.174871)	total_loss: 1.326743 (1.187083)

[2023-05-05 05:55:28,637-rk0-log_helper.py#102] Progress: 12200 / 15625 [78%], Speed: 2.083 s/iter, ETA 0:01:58 (D:H:M)

[2023-05-05 05:56:10,324-rk0-train.py#348] Epoch: [20][345/625] lr: 0.000275
	batch_time: 2.086801 (2.082942)	data_time: 0.000581 (0.000550)
	loss_fool: 0.205353 (0.197828)	loss_train_adv: 0.000487 (0.001588)
	cen_loss: 0.618396 (0.612738)	cls_loss: 0.033194 (0.048096)
	loc_loss: 0.168013 (0.173409)	total_loss: 1.155628 (1.181060)

[2023-05-05 05:56:10,326-rk0-log_helper.py#102] Progress: 12220 / 15625 [78%], Speed: 2.083 s/iter, ETA 0:01:58 (D:H:M)

[2023-05-05 05:56:52,101-rk0-train.py#348] Epoch: [20][365/625] lr: 0.000275
	batch_time: 2.074684 (2.084015)	data_time: 0.000146 (0.000536)
	loss_fool: 0.198459 (0.197627)	loss_train_adv: 0.000057 (0.001607)
	cen_loss: 0.606775 (0.612811)	cls_loss: 0.040252 (0.047764)
	loc_loss: 0.167749 (0.172413)	total_loss: 1.150274 (1.177815)

[2023-05-05 05:56:52,103-rk0-log_helper.py#102] Progress: 12240 / 15625 [78%], Speed: 2.084 s/iter, ETA 0:01:57 (D:H:M)

[2023-05-05 05:57:33,818-rk0-train.py#348] Epoch: [20][385/625] lr: 0.000275
	batch_time: 2.082606 (2.084945)	data_time: 0.000152 (0.000490)
	loss_fool: 0.202651 (0.197993)	loss_train_adv: 0.000097 (0.001407)
	cen_loss: 0.609963 (0.612466)	cls_loss: 0.061852 (0.048694)
	loc_loss: 0.173314 (0.172224)	total_loss: 1.191758 (1.177831)

[2023-05-05 05:57:33,820-rk0-log_helper.py#102] Progress: 12260 / 15625 [78%], Speed: 2.085 s/iter, ETA 0:01:56 (D:H:M)

[2023-05-05 05:58:15,592-rk0-train.py#348] Epoch: [20][405/625] lr: 0.000275
	batch_time: 2.078056 (2.085332)	data_time: 0.000144 (0.000440)
	loss_fool: 0.196772 (0.198028)	loss_train_adv: 0.002992 (0.001399)
	cen_loss: 0.614745 (0.612358)	cls_loss: 0.060679 (0.048496)
	loc_loss: 0.174410 (0.171143)	total_loss: 1.198653 (1.174284)

[2023-05-05 05:58:15,592-rk0-log_helper.py#102] Progress: 12280 / 15625 [78%], Speed: 2.085 s/iter, ETA 0:01:56 (D:H:M)

[2023-05-05 05:58:57,316-rk0-train.py#348] Epoch: [20][425/625] lr: 0.000275
	batch_time: 2.071671 (2.085538)	data_time: 0.000152 (0.000424)
	loss_fool: 0.193903 (0.198055)	loss_train_adv: 0.001394 (0.001387)
	cen_loss: 0.613609 (0.612299)	cls_loss: 0.033577 (0.047345)
	loc_loss: 0.156960 (0.170198)	total_loss: 1.118067 (1.170238)

[2023-05-05 05:58:57,318-rk0-log_helper.py#102] Progress: 12300 / 15625 [78%], Speed: 2.086 s/iter, ETA 0:01:55 (D:H:M)

[2023-05-05 05:59:40,156-rk0-train.py#348] Epoch: [20][445/625] lr: 0.000275
	batch_time: 2.084625 (2.097048)	data_time: 0.000625 (0.000368)
	loss_fool: 0.198073 (0.197887)	loss_train_adv: 0.001021 (0.001376)
	cen_loss: 0.609516 (0.612031)	cls_loss: 0.039267 (0.048101)
	loc_loss: 0.178093 (0.170741)	total_loss: 1.183060 (1.172356)

[2023-05-05 05:59:40,157-rk0-log_helper.py#102] Progress: 12320 / 15625 [78%], Speed: 2.097 s/iter, ETA 0:01:55 (D:H:M)

[2023-05-05 06:00:21,908-rk0-train.py#348] Epoch: [20][465/625] lr: 0.000275
	batch_time: 2.117621 (2.096792)	data_time: 0.000154 (0.000350)
	loss_fool: 0.198337 (0.198342)	loss_train_adv: 0.000042 (0.001148)
	cen_loss: 0.617156 (0.611804)	cls_loss: 0.085704 (0.048761)
	loc_loss: 0.210669 (0.171601)	total_loss: 1.334866 (1.175369)

[2023-05-05 06:00:21,909-rk0-log_helper.py#102] Progress: 12340 / 15625 [78%], Speed: 2.097 s/iter, ETA 0:01:54 (D:H:M)

[2023-05-05 06:01:03,548-rk0-train.py#348] Epoch: [20][485/625] lr: 0.000275
	batch_time: 2.079742 (2.096038)	data_time: 0.000143 (0.000316)
	loss_fool: 0.195099 (0.198307)	loss_train_adv: 0.000095 (0.001142)
	cen_loss: 0.614202 (0.612319)	cls_loss: 0.051376 (0.047377)
	loc_loss: 0.182672 (0.170453)	total_loss: 1.213595 (1.171054)

[2023-05-05 06:01:03,549-rk0-log_helper.py#102] Progress: 12360 / 15625 [79%], Speed: 2.096 s/iter, ETA 0:01:54 (D:H:M)

[2023-05-05 06:01:45,274-rk0-train.py#348] Epoch: [20][505/625] lr: 0.000275
	batch_time: 2.098194 (2.095622)	data_time: 0.000477 (0.000327)
	loss_fool: 0.200302 (0.198394)	loss_train_adv: 0.000052 (0.001141)
	cen_loss: 0.611220 (0.612733)	cls_loss: 0.049080 (0.048844)
	loc_loss: 0.163800 (0.172315)	total_loss: 1.151699 (1.178522)

[2023-05-05 06:01:45,275-rk0-log_helper.py#102] Progress: 12380 / 15625 [79%], Speed: 2.096 s/iter, ETA 0:01:53 (D:H:M)

[2023-05-05 06:02:27,003-rk0-train.py#348] Epoch: [20][525/625] lr: 0.000275
	batch_time: 2.089181 (2.095650)	data_time: 0.000607 (0.000318)
	loss_fool: 0.193710 (0.198324)	loss_train_adv: 0.000829 (0.001318)
	cen_loss: 0.609459 (0.612815)	cls_loss: 0.054952 (0.049593)
	loc_loss: 0.181683 (0.172891)	total_loss: 1.209461 (1.181081)

[2023-05-05 06:02:27,004-rk0-log_helper.py#102] Progress: 12400 / 15625 [79%], Speed: 2.096 s/iter, ETA 0:01:52 (D:H:M)

[2023-05-05 06:03:08,776-rk0-train.py#348] Epoch: [20][545/625] lr: 0.000275
	batch_time: 2.077281 (2.084970)	data_time: 0.000161 (0.000300)
	loss_fool: 0.198185 (0.198291)	loss_train_adv: 0.000509 (0.001235)
	cen_loss: 0.613264 (0.613319)	cls_loss: 0.036653 (0.049368)
	loc_loss: 0.168925 (0.172449)	total_loss: 1.156693 (1.180033)

[2023-05-05 06:03:08,778-rk0-log_helper.py#102] Progress: 12420 / 15625 [79%], Speed: 2.085 s/iter, ETA 0:01:51 (D:H:M)

[2023-05-05 06:03:50,451-rk0-train.py#348] Epoch: [20][565/625] lr: 0.000275
	batch_time: 2.083985 (2.084199)	data_time: 0.000287 (0.000257)
	loss_fool: 0.195136 (0.198249)	loss_train_adv: 0.000347 (0.001457)
	cen_loss: 0.618105 (0.613617)	cls_loss: 0.043848 (0.048138)
	loc_loss: 0.161441 (0.170952)	total_loss: 1.146277 (1.174610)

[2023-05-05 06:03:50,452-rk0-log_helper.py#102] Progress: 12440 / 15625 [79%], Speed: 2.084 s/iter, ETA 0:01:50 (D:H:M)

[2023-05-05 06:04:32,198-rk0-train.py#348] Epoch: [20][585/625] lr: 0.000275
	batch_time: 2.098727 (2.085260)	data_time: 0.000176 (0.000292)
	loss_fool: 0.199730 (0.197894)	loss_train_adv: 0.004079 (0.001645)
	cen_loss: 0.614771 (0.613258)	cls_loss: 0.049215 (0.048081)
	loc_loss: 0.202377 (0.170195)	total_loss: 1.271117 (1.171922)

[2023-05-05 06:04:32,201-rk0-log_helper.py#102] Progress: 12460 / 15625 [79%], Speed: 2.085 s/iter, ETA 0:01:49 (D:H:M)

[2023-05-05 06:05:13,930-rk0-train.py#348] Epoch: [20][605/625] lr: 0.000275
	batch_time: 2.083453 (2.085294)	data_time: 0.000920 (0.000328)
	loss_fool: 0.182654 (0.197676)	loss_train_adv: 0.005128 (0.001593)
	cen_loss: 0.614268 (0.613355)	cls_loss: 0.043788 (0.048000)
	loc_loss: 0.167406 (0.170972)	total_loss: 1.160273 (1.174271)

[2023-05-05 06:05:13,931-rk0-log_helper.py#102] Progress: 12480 / 15625 [79%], Speed: 2.085 s/iter, ETA 0:01:49 (D:H:M)

[2023-05-05 06:05:56,817-rk0-train.py#348] Epoch: [20][0/625] lr: 0.000275
	batch_time: 2.076900 (2.096911)	data_time: 0.000459 (0.000358)
	loss_fool: 0.192174 (0.197769)	loss_train_adv: 0.006767 (0.001563)
	cen_loss: 0.610996 (0.613214)	cls_loss: 0.058572 (0.047074)
	loc_loss: 0.174037 (0.170638)	total_loss: 1.191679 (1.172203)

[2023-05-05 06:05:56,817-rk0-log_helper.py#102] Progress: 12500 / 15625 [80%], Speed: 2.097 s/iter, ETA 0:01:49 (D:H:M)

[2023-05-05 06:05:57,498-rk0-train.py#235] epoch: 21
[2023-05-05 06:05:57,499-rk0-train.py#240] epoch 21 lr 2.4356651087830818e-05
[2023-05-05 06:05:57,499-rk0-train.py#240] epoch 21 lr 0.00024356651087830813
[2023-05-05 06:05:57,499-rk0-train.py#240] epoch 21 lr 0.0008118883695943605
[2023-05-05 06:05:57,499-rk0-train.py#240] epoch 21 lr 0.00024356651087830813
[2023-05-05 06:05:57,500-rk0-train.py#240] epoch 21 lr 0.00024356651087830813
[2023-05-05 06:06:39,046-rk0-train.py#348] Epoch: [21][20/625] lr: 0.000244
	batch_time: 2.084189 (2.101497)	data_time: 0.001315 (0.007232)
	loss_fool: 0.211513 (0.196974)	loss_train_adv: 0.000405 (0.002449)
	cen_loss: 0.618308 (0.613309)	cls_loss: 0.057437 (0.046849)
	loc_loss: 0.165966 (0.169737)	total_loss: 1.173643 (1.169370)

[2023-05-05 06:06:39,047-rk0-log_helper.py#102] Progress: 12520 / 15625 [80%], Speed: 2.101 s/iter, ETA 0:01:48 (D:H:M)

[2023-05-05 06:07:20,700-rk0-train.py#348] Epoch: [21][40/625] lr: 0.000244
	batch_time: 2.084180 (2.101302)	data_time: 0.000378 (0.007299)
	loss_fool: 0.203772 (0.196922)	loss_train_adv: 0.001155 (0.002352)
	cen_loss: 0.610886 (0.612941)	cls_loss: 0.049281 (0.047907)
	loc_loss: 0.183839 (0.171232)	total_loss: 1.211685 (1.174543)

[2023-05-05 06:07:20,701-rk0-log_helper.py#102] Progress: 12540 / 15625 [80%], Speed: 2.101 s/iter, ETA 0:01:48 (D:H:M)

[2023-05-05 06:08:02,309-rk0-train.py#348] Epoch: [21][60/625] lr: 0.000244
	batch_time: 2.091554 (2.099942)	data_time: 0.000469 (0.007330)
	loss_fool: 0.205449 (0.196760)	loss_train_adv: 0.000160 (0.002386)
	cen_loss: 0.605829 (0.612982)	cls_loss: 0.064585 (0.047164)
	loc_loss: 0.174208 (0.171628)	total_loss: 1.193036 (1.175030)

[2023-05-05 06:08:02,310-rk0-log_helper.py#102] Progress: 12560 / 15625 [80%], Speed: 2.100 s/iter, ETA 0:01:47 (D:H:M)

[2023-05-05 06:08:43,991-rk0-train.py#348] Epoch: [21][80/625] lr: 0.000244
	batch_time: 2.069113 (2.099458)	data_time: 0.000687 (0.007355)
	loss_fool: 0.194828 (0.196674)	loss_train_adv: 0.003502 (0.002655)
	cen_loss: 0.614814 (0.612569)	cls_loss: 0.041512 (0.046509)
	loc_loss: 0.164902 (0.170473)	total_loss: 1.151032 (1.170496)

[2023-05-05 06:08:43,993-rk0-log_helper.py#102] Progress: 12580 / 15625 [80%], Speed: 2.099 s/iter, ETA 0:01:46 (D:H:M)

[2023-05-05 06:09:25,751-rk0-train.py#348] Epoch: [21][100/625] lr: 0.000244
	batch_time: 2.077343 (2.088159)	data_time: 0.000629 (0.007369)
	loss_fool: 0.199530 (0.196112)	loss_train_adv: 0.004655 (0.002868)
	cen_loss: 0.606302 (0.612734)	cls_loss: 0.042433 (0.047403)
	loc_loss: 0.143502 (0.170778)	total_loss: 1.079242 (1.172470)

[2023-05-05 06:09:25,753-rk0-log_helper.py#102] Progress: 12600 / 15625 [80%], Speed: 2.088 s/iter, ETA 0:01:45 (D:H:M)

[2023-05-05 06:10:07,368-rk0-train.py#348] Epoch: [21][120/625] lr: 0.000244
	batch_time: 2.073212 (2.082024)	data_time: 0.000556 (0.000547)
	loss_fool: 0.184987 (0.196470)	loss_train_adv: 0.000988 (0.002343)
	cen_loss: 0.612565 (0.612444)	cls_loss: 0.051688 (0.047486)
	loc_loss: 0.217312 (0.171727)	total_loss: 1.316189 (1.175110)

[2023-05-05 06:10:07,369-rk0-log_helper.py#102] Progress: 12620 / 15625 [80%], Speed: 2.082 s/iter, ETA 0:01:44 (D:H:M)

[2023-05-05 06:10:49,043-rk0-train.py#348] Epoch: [21][140/625] lr: 0.000244
	batch_time: 2.071669 (2.082223)	data_time: 0.001349 (0.000528)
	loss_fool: 0.195204 (0.196440)	loss_train_adv: 0.000204 (0.002380)
	cen_loss: 0.611916 (0.612717)	cls_loss: 0.041101 (0.047279)
	loc_loss: 0.161171 (0.171470)	total_loss: 1.136530 (1.174405)

[2023-05-05 06:10:49,044-rk0-log_helper.py#102] Progress: 12640 / 15625 [80%], Speed: 2.082 s/iter, ETA 0:01:43 (D:H:M)

[2023-05-05 06:11:30,693-rk0-train.py#348] Epoch: [21][160/625] lr: 0.000244
	batch_time: 2.081634 (2.082609)	data_time: 0.000602 (0.000528)
	loss_fool: 0.198703 (0.196922)	loss_train_adv: 0.000289 (0.002159)
	cen_loss: 0.611614 (0.612785)	cls_loss: 0.034724 (0.049174)
	loc_loss: 0.153947 (0.172171)	total_loss: 1.108180 (1.178471)

[2023-05-05 06:11:30,694-rk0-log_helper.py#102] Progress: 12660 / 15625 [81%], Speed: 2.083 s/iter, ETA 0:01:42 (D:H:M)

[2023-05-05 06:12:12,489-rk0-train.py#348] Epoch: [21][180/625] lr: 0.000244
	batch_time: 2.073690 (2.083765)	data_time: 0.000384 (0.000500)
	loss_fool: 0.176026 (0.196436)	loss_train_adv: 0.006749 (0.002069)
	cen_loss: 0.614626 (0.612589)	cls_loss: 0.041481 (0.049446)
	loc_loss: 0.167413 (0.171793)	total_loss: 1.158344 (1.177414)

[2023-05-05 06:12:12,490-rk0-log_helper.py#102] Progress: 12680 / 15625 [81%], Speed: 2.084 s/iter, ETA 0:01:42 (D:H:M)

[2023-05-05 06:12:54,149-rk0-train.py#348] Epoch: [21][200/625] lr: 0.000244
	batch_time: 2.086207 (2.082789)	data_time: 0.000126 (0.000497)
	loss_fool: 0.185658 (0.194390)	loss_train_adv: 0.002090 (0.004127)
	cen_loss: 0.613274 (0.612466)	cls_loss: 0.038799 (0.047680)
	loc_loss: 0.178222 (0.169296)	total_loss: 1.186737 (1.168036)

[2023-05-05 06:12:54,150-rk0-log_helper.py#102] Progress: 12700 / 15625 [81%], Speed: 2.083 s/iter, ETA 0:01:41 (D:H:M)

[2023-05-05 06:13:36,967-rk0-train.py#348] Epoch: [21][220/625] lr: 0.000244
	batch_time: 2.080366 (2.094814)	data_time: 0.000275 (0.000506)
	loss_fool: 0.194698 (0.195025)	loss_train_adv: 0.000319 (0.004034)
	cen_loss: 0.610951 (0.612518)	cls_loss: 0.077410 (0.049894)
	loc_loss: 0.191861 (0.170410)	total_loss: 1.263946 (1.173642)

[2023-05-05 06:13:36,967-rk0-log_helper.py#102] Progress: 12720 / 15625 [81%], Speed: 2.095 s/iter, ETA 0:01:41 (D:H:M)

[2023-05-05 06:14:18,615-rk0-train.py#348] Epoch: [21][240/625] lr: 0.000244
	batch_time: 2.085914 (2.094561)	data_time: 0.000628 (0.000536)
	loss_fool: 0.195648 (0.194787)	loss_train_adv: 0.001180 (0.004063)
	cen_loss: 0.603802 (0.612039)	cls_loss: 0.045096 (0.050018)
	loc_loss: 0.150946 (0.170064)	total_loss: 1.101736 (1.172250)

[2023-05-05 06:14:18,616-rk0-log_helper.py#102] Progress: 12740 / 15625 [81%], Speed: 2.095 s/iter, ETA 0:01:40 (D:H:M)

[2023-05-05 06:15:00,265-rk0-train.py#348] Epoch: [21][260/625] lr: 0.000244
	batch_time: 2.067992 (2.094576)	data_time: 0.000417 (0.000538)
	loss_fool: 0.191797 (0.194640)	loss_train_adv: 0.000778 (0.004236)
	cen_loss: 0.615772 (0.612208)	cls_loss: 0.034470 (0.050151)
	loc_loss: 0.165028 (0.171114)	total_loss: 1.145327 (1.175701)

[2023-05-05 06:15:00,266-rk0-log_helper.py#102] Progress: 12760 / 15625 [81%], Speed: 2.095 s/iter, ETA 0:01:40 (D:H:M)

[2023-05-05 06:15:41,867-rk0-train.py#348] Epoch: [21][280/625] lr: 0.000244
	batch_time: 2.069834 (2.092646)	data_time: 0.000567 (0.000561)
	loss_fool: 0.198641 (0.195210)	loss_train_adv: 0.002966 (0.004202)
	cen_loss: 0.611181 (0.612569)	cls_loss: 0.066312 (0.049908)
	loc_loss: 0.198759 (0.171304)	total_loss: 1.273770 (1.176389)

[2023-05-05 06:15:41,868-rk0-log_helper.py#102] Progress: 12780 / 15625 [81%], Speed: 2.093 s/iter, ETA 0:01:39 (D:H:M)

[2023-05-05 06:16:23,699-rk0-train.py#348] Epoch: [21][300/625] lr: 0.000244
	batch_time: 2.088475 (2.094361)	data_time: 0.000392 (0.000560)
	loss_fool: 0.195072 (0.197779)	loss_train_adv: 0.001562 (0.001823)
	cen_loss: 0.613737 (0.612452)	cls_loss: 0.051462 (0.051400)
	loc_loss: 0.190235 (0.174621)	total_loss: 1.235904 (1.187715)

[2023-05-05 06:16:23,700-rk0-log_helper.py#102] Progress: 12800 / 15625 [81%], Speed: 2.094 s/iter, ETA 0:01:38 (D:H:M)

[2023-05-05 06:17:05,428-rk0-train.py#348] Epoch: [21][320/625] lr: 0.000244
	batch_time: 2.075350 (2.083450)	data_time: 0.000693 (0.000575)
	loss_fool: 0.199428 (0.197458)	loss_train_adv: 0.004660 (0.001779)
	cen_loss: 0.614330 (0.612142)	cls_loss: 0.056403 (0.049525)
	loc_loss: 0.173503 (0.174330)	total_loss: 1.191241 (1.184656)

[2023-05-05 06:17:05,428-rk0-log_helper.py#102] Progress: 12820 / 15625 [82%], Speed: 2.083 s/iter, ETA 0:01:37 (D:H:M)

[2023-05-05 06:17:47,122-rk0-train.py#348] Epoch: [21][340/625] lr: 0.000244
	batch_time: 2.079532 (2.083902)	data_time: 0.000376 (0.000551)
	loss_fool: 0.198563 (0.197693)	loss_train_adv: 0.005346 (0.001698)
	cen_loss: 0.620362 (0.612299)	cls_loss: 0.062214 (0.051249)
	loc_loss: 0.171038 (0.175750)	total_loss: 1.195689 (1.190798)

[2023-05-05 06:17:47,123-rk0-log_helper.py#102] Progress: 12840 / 15625 [82%], Speed: 2.084 s/iter, ETA 0:01:36 (D:H:M)

[2023-05-05 06:18:28,938-rk0-train.py#348] Epoch: [21][360/625] lr: 0.000244
	batch_time: 2.091851 (2.085547)	data_time: 0.000630 (0.000569)
	loss_fool: 0.198978 (0.197756)	loss_train_adv: 0.000868 (0.001618)
	cen_loss: 0.618328 (0.612372)	cls_loss: 0.042449 (0.050060)
	loc_loss: 0.194334 (0.174709)	total_loss: 1.243781 (1.186559)

[2023-05-05 06:18:28,939-rk0-log_helper.py#102] Progress: 12860 / 15625 [82%], Speed: 2.086 s/iter, ETA 0:01:36 (D:H:M)

[2023-05-05 06:19:10,616-rk0-train.py#348] Epoch: [21][380/625] lr: 0.000244
	batch_time: 2.079668 (2.086295)	data_time: 0.000635 (0.000545)
	loss_fool: 0.196714 (0.197710)	loss_train_adv: 0.001772 (0.001557)
	cen_loss: 0.612087 (0.612039)	cls_loss: 0.134719 (0.051495)
	loc_loss: 0.171831 (0.175657)	total_loss: 1.262298 (1.190506)

[2023-05-05 06:19:10,617-rk0-log_helper.py#102] Progress: 12880 / 15625 [82%], Speed: 2.086 s/iter, ETA 0:01:35 (D:H:M)

[2023-05-05 06:19:53,507-rk0-train.py#348] Epoch: [21][400/625] lr: 0.000244
	batch_time: 2.075584 (2.096887)	data_time: 0.000482 (0.000541)
	loss_fool: 0.196019 (0.197648)	loss_train_adv: 0.001808 (0.001588)
	cen_loss: 0.610976 (0.612390)	cls_loss: 0.043049 (0.051148)
	loc_loss: 0.173823 (0.173993)	total_loss: 1.175495 (1.185518)

[2023-05-05 06:19:53,508-rk0-log_helper.py#102] Progress: 12900 / 15625 [82%], Speed: 2.097 s/iter, ETA 0:01:35 (D:H:M)

[2023-05-05 06:20:35,154-rk0-train.py#348] Epoch: [21][420/625] lr: 0.000244
	batch_time: 2.077283 (2.096049)	data_time: 0.000644 (0.000537)
	loss_fool: 0.197048 (0.197748)	loss_train_adv: 0.000853 (0.001490)
	cen_loss: 0.609246 (0.612862)	cls_loss: 0.044563 (0.050597)
	loc_loss: 0.166174 (0.173451)	total_loss: 1.152331 (1.183812)

[2023-05-05 06:20:35,156-rk0-log_helper.py#102] Progress: 12920 / 15625 [82%], Speed: 2.096 s/iter, ETA 0:01:34 (D:H:M)

[2023-05-05 06:21:16,831-rk0-train.py#348] Epoch: [21][440/625] lr: 0.000244
	batch_time: 2.083681 (2.095876)	data_time: 0.000647 (0.000553)
	loss_fool: 0.197409 (0.197579)	loss_train_adv: 0.001278 (0.001538)
	cen_loss: 0.612149 (0.613213)	cls_loss: 0.044012 (0.048229)
	loc_loss: 0.154860 (0.172700)	total_loss: 1.120742 (1.179543)

[2023-05-05 06:21:16,832-rk0-log_helper.py#102] Progress: 12940 / 15625 [82%], Speed: 2.096 s/iter, ETA 0:01:33 (D:H:M)

[2023-05-05 06:21:58,494-rk0-train.py#348] Epoch: [21][460/625] lr: 0.000244
	batch_time: 2.102146 (2.094347)	data_time: 0.000646 (0.000529)
	loss_fool: 0.193594 (0.197568)	loss_train_adv: 0.000658 (0.001534)
	cen_loss: 0.619463 (0.613128)	cls_loss: 0.045626 (0.049895)
	loc_loss: 0.173964 (0.174020)	total_loss: 1.186982 (1.185083)

[2023-05-05 06:21:58,494-rk0-log_helper.py#102] Progress: 12960 / 15625 [82%], Speed: 2.094 s/iter, ETA 0:01:33 (D:H:M)

[2023-05-05 06:22:40,070-rk0-train.py#348] Epoch: [21][480/625] lr: 0.000244
	batch_time: 2.097661 (2.093336)	data_time: 0.000577 (0.000541)
	loss_fool: 0.197216 (0.197787)	loss_train_adv: 0.004873 (0.001515)
	cen_loss: 0.608449 (0.613411)	cls_loss: 0.039398 (0.048662)
	loc_loss: 0.163725 (0.173247)	total_loss: 1.139023 (1.181813)

[2023-05-05 06:22:40,071-rk0-log_helper.py#102] Progress: 12980 / 15625 [83%], Speed: 2.093 s/iter, ETA 0:01:32 (D:H:M)

[2023-05-05 06:23:21,782-rk0-train.py#348] Epoch: [21][500/625] lr: 0.000244
	batch_time: 2.080234 (2.081530)	data_time: 0.000634 (0.000796)
	loss_fool: 0.190223 (0.197843)	loss_train_adv: 0.000209 (0.001575)
	cen_loss: 0.616263 (0.613309)	cls_loss: 0.053486 (0.049193)
	loc_loss: 0.186679 (0.173470)	total_loss: 1.229786 (1.182911)

[2023-05-05 06:23:21,782-rk0-log_helper.py#102] Progress: 13000 / 15625 [83%], Speed: 2.082 s/iter, ETA 0:01:31 (D:H:M)

[2023-05-05 06:24:03,411-rk0-train.py#348] Epoch: [21][520/625] lr: 0.000244
	batch_time: 2.081750 (2.081376)	data_time: 0.000705 (0.000796)
	loss_fool: 0.199690 (0.197560)	loss_train_adv: 0.000575 (0.001699)
	cen_loss: 0.603035 (0.612903)	cls_loss: 0.031349 (0.049355)
	loc_loss: 0.133670 (0.174070)	total_loss: 1.035393 (1.184467)

[2023-05-05 06:24:03,412-rk0-log_helper.py#102] Progress: 13020 / 15625 [83%], Speed: 2.081 s/iter, ETA 0:01:30 (D:H:M)

[2023-05-05 06:24:45,170-rk0-train.py#348] Epoch: [21][540/625] lr: 0.000244
	batch_time: 2.075268 (2.082206)	data_time: 0.000543 (0.000805)
	loss_fool: 0.190075 (0.197268)	loss_train_adv: 0.005136 (0.002103)
	cen_loss: 0.610004 (0.612778)	cls_loss: 0.036729 (0.049957)
	loc_loss: 0.159739 (0.174415)	total_loss: 1.125952 (1.185981)

[2023-05-05 06:24:45,171-rk0-log_helper.py#102] Progress: 13040 / 15625 [83%], Speed: 2.082 s/iter, ETA 0:01:29 (D:H:M)

[2023-05-05 06:25:26,955-rk0-train.py#348] Epoch: [21][560/625] lr: 0.000244
	batch_time: 2.082802 (2.083431)	data_time: 0.000608 (0.000813)
	loss_fool: 0.202427 (0.196670)	loss_train_adv: 0.000158 (0.002343)
	cen_loss: 0.615258 (0.613016)	cls_loss: 0.055752 (0.049260)
	loc_loss: 0.168131 (0.174187)	total_loss: 1.175403 (1.184836)

[2023-05-05 06:25:26,955-rk0-log_helper.py#102] Progress: 13060 / 15625 [83%], Speed: 2.083 s/iter, ETA 0:01:29 (D:H:M)

[2023-05-05 06:26:08,666-rk0-train.py#348] Epoch: [21][580/625] lr: 0.000244
	batch_time: 2.085775 (2.084765)	data_time: 0.000627 (0.000805)
	loss_fool: 0.199301 (0.196856)	loss_train_adv: 0.000627 (0.002253)
	cen_loss: 0.608755 (0.613052)	cls_loss: 0.037603 (0.048715)
	loc_loss: 0.130602 (0.173601)	total_loss: 1.038165 (1.182569)

[2023-05-05 06:26:08,666-rk0-log_helper.py#102] Progress: 13080 / 15625 [83%], Speed: 2.085 s/iter, ETA 0:01:28 (D:H:M)

[2023-05-05 06:26:50,353-rk0-train.py#348] Epoch: [21][600/625] lr: 0.000244
	batch_time: 2.068070 (2.084537)	data_time: 0.000623 (0.000553)
	loss_fool: 0.199320 (0.196946)	loss_train_adv: 0.000049 (0.002065)
	cen_loss: 0.603881 (0.612904)	cls_loss: 0.037247 (0.048873)
	loc_loss: 0.157875 (0.173452)	total_loss: 1.114752 (1.182133)

[2023-05-05 06:26:50,355-rk0-log_helper.py#102] Progress: 13100 / 15625 [83%], Speed: 2.085 s/iter, ETA 0:01:27 (D:H:M)

[2023-05-05 06:27:32,066-rk0-train.py#348] Epoch: [21][620/625] lr: 0.000244
	batch_time: 2.084989 (2.085369)	data_time: 0.000685 (0.000538)
	loss_fool: 0.201625 (0.197277)	loss_train_adv: 0.001047 (0.001925)
	cen_loss: 0.609866 (0.612997)	cls_loss: 0.062756 (0.049027)
	loc_loss: 0.167371 (0.172310)	total_loss: 1.174736 (1.178952)

[2023-05-05 06:27:32,068-rk0-log_helper.py#102] Progress: 13120 / 15625 [83%], Speed: 2.085 s/iter, ETA 0:01:27 (D:H:M)

[2023-05-05 06:27:43,146-rk0-train.py#235] epoch: 22
[2023-05-05 06:27:43,146-rk0-train.py#240] epoch 22 lr 2.1576748324314944e-05
[2023-05-05 06:27:43,146-rk0-train.py#240] epoch 22 lr 0.00021576748324314942
[2023-05-05 06:27:43,147-rk0-train.py#240] epoch 22 lr 0.0007192249441438314
[2023-05-05 06:27:43,147-rk0-train.py#240] epoch 22 lr 0.00021576748324314942
[2023-05-05 06:27:43,147-rk0-train.py#240] epoch 22 lr 0.00021576748324314942
[2023-05-05 06:28:17,322-rk0-train.py#348] Epoch: [22][15/625] lr: 0.000216
	batch_time: 2.095041 (2.120332)	data_time: 0.000509 (0.007603)
	loss_fool: 0.194836 (0.197746)	loss_train_adv: 0.006067 (0.001461)
	cen_loss: 0.612781 (0.613048)	cls_loss: 0.045519 (0.047997)
	loc_loss: 0.180367 (0.170808)	total_loss: 1.199402 (1.173470)

[2023-05-05 06:28:17,323-rk0-log_helper.py#102] Progress: 13140 / 15625 [84%], Speed: 2.120 s/iter, ETA 0:01:27 (D:H:M)

[2023-05-05 06:28:58,956-rk0-train.py#348] Epoch: [22][35/625] lr: 0.000216
	batch_time: 2.085925 (2.118835)	data_time: 0.000611 (0.007598)
	loss_fool: 0.199006 (0.198397)	loss_train_adv: 0.000450 (0.001143)
	cen_loss: 0.620605 (0.612807)	cls_loss: 0.048030 (0.047366)
	loc_loss: 0.187670 (0.171131)	total_loss: 1.231644 (1.173565)

[2023-05-05 06:28:58,958-rk0-log_helper.py#102] Progress: 13160 / 15625 [84%], Speed: 2.119 s/iter, ETA 0:01:27 (D:H:M)

[2023-05-05 06:29:40,601-rk0-train.py#348] Epoch: [22][55/625] lr: 0.000216
	batch_time: 2.086410 (2.118175)	data_time: 0.000266 (0.007601)
	loss_fool: 0.196284 (0.198015)	loss_train_adv: 0.000436 (0.001199)
	cen_loss: 0.617290 (0.612856)	cls_loss: 0.046755 (0.047968)
	loc_loss: 0.172258 (0.172159)	total_loss: 1.180820 (1.177300)

[2023-05-05 06:29:40,602-rk0-log_helper.py#102] Progress: 13180 / 15625 [84%], Speed: 2.118 s/iter, ETA 0:01:26 (D:H:M)

[2023-05-05 06:30:22,183-rk0-train.py#348] Epoch: [22][75/625] lr: 0.000216
	batch_time: 2.062224 (2.117114)	data_time: 0.000158 (0.007649)
	loss_fool: 0.199204 (0.198133)	loss_train_adv: 0.003573 (0.001451)
	cen_loss: 0.614088 (0.613101)	cls_loss: 0.048054 (0.047632)
	loc_loss: 0.162117 (0.172884)	total_loss: 1.148495 (1.179386)

[2023-05-05 06:30:22,184-rk0-log_helper.py#102] Progress: 13200 / 15625 [84%], Speed: 2.117 s/iter, ETA 0:01:25 (D:H:M)

[2023-05-05 06:31:03,871-rk0-train.py#348] Epoch: [22][95/625] lr: 0.000216
	batch_time: 2.074303 (2.116882)	data_time: 0.000626 (0.007675)
	loss_fool: 0.197538 (0.197789)	loss_train_adv: 0.000224 (0.001595)
	cen_loss: 0.614887 (0.613508)	cls_loss: 0.042735 (0.047751)
	loc_loss: 0.185414 (0.174068)	total_loss: 1.213864 (1.183464)

[2023-05-05 06:31:03,873-rk0-log_helper.py#102] Progress: 13220 / 15625 [84%], Speed: 2.117 s/iter, ETA 0:01:24 (D:H:M)

[2023-05-05 06:31:45,607-rk0-train.py#348] Epoch: [22][115/625] lr: 0.000216
	batch_time: 2.092406 (2.081675)	data_time: 0.001060 (0.000607)
	loss_fool: 0.197980 (0.197444)	loss_train_adv: 0.000438 (0.001621)
	cen_loss: 0.617142 (0.613376)	cls_loss: 0.048516 (0.048768)
	loc_loss: 0.164987 (0.174741)	total_loss: 1.160619 (1.186366)

[2023-05-05 06:31:45,609-rk0-log_helper.py#102] Progress: 13240 / 15625 [84%], Speed: 2.082 s/iter, ETA 0:01:22 (D:H:M)

[2023-05-05 06:32:27,167-rk0-train.py#348] Epoch: [22][135/625] lr: 0.000216
	batch_time: 2.086417 (2.080927)	data_time: 0.000292 (0.000612)
	loss_fool: 0.188441 (0.197296)	loss_train_adv: 0.004182 (0.001899)
	cen_loss: 0.609524 (0.613439)	cls_loss: 0.037318 (0.047887)
	loc_loss: 0.182009 (0.173218)	total_loss: 1.192869 (1.180979)

[2023-05-05 06:32:27,168-rk0-log_helper.py#102] Progress: 13260 / 15625 [84%], Speed: 2.081 s/iter, ETA 0:01:22 (D:H:M)

[2023-05-05 06:33:08,863-rk0-train.py#348] Epoch: [22][155/625] lr: 0.000216
	batch_time: 2.070510 (2.081443)	data_time: 0.000591 (0.000632)
	loss_fool: 0.187155 (0.196124)	loss_train_adv: 0.000543 (0.002904)
	cen_loss: 0.602273 (0.613501)	cls_loss: 0.045091 (0.048948)
	loc_loss: 0.152575 (0.172975)	total_loss: 1.105089 (1.181375)

[2023-05-05 06:33:08,864-rk0-log_helper.py#102] Progress: 13280 / 15625 [84%], Speed: 2.081 s/iter, ETA 0:01:21 (D:H:M)

[2023-05-05 06:33:50,593-rk0-train.py#348] Epoch: [22][175/625] lr: 0.000216
	batch_time: 2.087039 (2.082917)	data_time: 0.000571 (0.000595)
	loss_fool: 0.195997 (0.196034)	loss_train_adv: 0.001451 (0.002878)
	cen_loss: 0.611303 (0.612896)	cls_loss: 0.036996 (0.048188)
	loc_loss: 0.145290 (0.171086)	total_loss: 1.084168 (1.174343)

[2023-05-05 06:33:50,595-rk0-log_helper.py#102] Progress: 13300 / 15625 [85%], Speed: 2.083 s/iter, ETA 0:01:20 (D:H:M)

[2023-05-05 06:34:33,148-rk0-train.py#348] Epoch: [22][195/625] lr: 0.000216
	batch_time: 2.094309 (2.091573)	data_time: 0.000641 (0.000580)
	loss_fool: 0.195154 (0.196384)	loss_train_adv: 0.002546 (0.002772)
	cen_loss: 0.594257 (0.612450)	cls_loss: 0.045712 (0.046928)
	loc_loss: 0.164635 (0.170540)	total_loss: 1.133875 (1.170999)

[2023-05-05 06:34:33,149-rk0-log_helper.py#102] Progress: 13320 / 15625 [85%], Speed: 2.092 s/iter, ETA 0:01:20 (D:H:M)

[2023-05-05 06:35:14,817-rk0-train.py#348] Epoch: [22][215/625] lr: 0.000216
	batch_time: 2.081836 (2.090903)	data_time: 0.000627 (0.000579)
	loss_fool: 0.201896 (0.196665)	loss_train_adv: 0.000131 (0.002733)
	cen_loss: 0.610918 (0.612688)	cls_loss: 0.045672 (0.046431)
	loc_loss: 0.167414 (0.170958)	total_loss: 1.158832 (1.171993)

[2023-05-05 06:35:14,817-rk0-log_helper.py#102] Progress: 13340 / 15625 [85%], Speed: 2.091 s/iter, ETA 0:01:19 (D:H:M)

[2023-05-05 06:35:56,546-rk0-train.py#348] Epoch: [22][235/625] lr: 0.000216
	batch_time: 2.080156 (2.092587)	data_time: 0.000416 (0.000591)
	loss_fool: 0.196710 (0.196688)	loss_train_adv: 0.002779 (0.002483)
	cen_loss: 0.620270 (0.612966)	cls_loss: 0.053210 (0.047775)
	loc_loss: 0.199282 (0.171596)	total_loss: 1.271327 (1.175528)

[2023-05-05 06:35:56,546-rk0-log_helper.py#102] Progress: 13360 / 15625 [85%], Speed: 2.093 s/iter, ETA 0:01:18 (D:H:M)

[2023-05-05 06:36:38,256-rk0-train.py#348] Epoch: [22][255/625] lr: 0.000216
	batch_time: 2.085860 (2.092736)	data_time: 0.000555 (0.000573)
	loss_fool: 0.196156 (0.198017)	loss_train_adv: 0.003065 (0.001513)
	cen_loss: 0.613418 (0.613172)	cls_loss: 0.057871 (0.046733)
	loc_loss: 0.161619 (0.170547)	total_loss: 1.156146 (1.171545)

[2023-05-05 06:36:38,257-rk0-log_helper.py#102] Progress: 13380 / 15625 [85%], Speed: 2.093 s/iter, ETA 0:01:18 (D:H:M)

[2023-05-05 06:37:19,940-rk0-train.py#348] Epoch: [22][275/625] lr: 0.000216
	batch_time: 2.085032 (2.092271)	data_time: 0.000640 (0.000593)
	loss_fool: 0.191585 (0.197849)	loss_train_adv: 0.003716 (0.001492)
	cen_loss: 0.617443 (0.613613)	cls_loss: 0.043050 (0.046871)
	loc_loss: 0.181749 (0.172494)	total_loss: 1.205741 (1.177966)

[2023-05-05 06:37:19,941-rk0-log_helper.py#102] Progress: 13400 / 15625 [85%], Speed: 2.092 s/iter, ETA 0:01:17 (D:H:M)

[2023-05-05 06:38:01,658-rk0-train.py#348] Epoch: [22][295/625] lr: 0.000216
	batch_time: 2.083195 (2.083913)	data_time: 0.000765 (0.000581)
	loss_fool: 0.200759 (0.197391)	loss_train_adv: 0.002662 (0.001669)
	cen_loss: 0.610233 (0.613900)	cls_loss: 0.047080 (0.047150)
	loc_loss: 0.164147 (0.170708)	total_loss: 1.149756 (1.173174)

[2023-05-05 06:38:01,659-rk0-log_helper.py#102] Progress: 13420 / 15625 [85%], Speed: 2.084 s/iter, ETA 0:01:16 (D:H:M)

[2023-05-05 06:38:43,373-rk0-train.py#348] Epoch: [22][315/625] lr: 0.000216
	batch_time: 2.085116 (2.084359)	data_time: 0.000771 (0.000572)
	loss_fool: 0.202803 (0.197613)	loss_train_adv: 0.000088 (0.001619)
	cen_loss: 0.612199 (0.613821)	cls_loss: 0.038174 (0.046874)
	loc_loss: 0.163846 (0.169225)	total_loss: 1.141910 (1.168370)

[2023-05-05 06:38:43,373-rk0-log_helper.py#102] Progress: 13440 / 15625 [86%], Speed: 2.084 s/iter, ETA 0:01:15 (D:H:M)

[2023-05-05 06:39:24,990-rk0-train.py#348] Epoch: [22][335/625] lr: 0.000216
	batch_time: 2.085015 (2.083242)	data_time: 0.000633 (0.000552)
	loss_fool: 0.198959 (0.197803)	loss_train_adv: 0.003037 (0.001673)
	cen_loss: 0.619573 (0.613750)	cls_loss: 0.046390 (0.046172)
	loc_loss: 0.169871 (0.169367)	total_loss: 1.175575 (1.168024)

[2023-05-05 06:39:24,991-rk0-log_helper.py#102] Progress: 13460 / 15625 [86%], Speed: 2.083 s/iter, ETA 0:01:15 (D:H:M)

[2023-05-05 06:40:06,686-rk0-train.py#348] Epoch: [22][355/625] lr: 0.000216
	batch_time: 2.081955 (2.083087)	data_time: 0.000368 (0.000554)
	loss_fool: 0.199524 (0.197836)	loss_train_adv: 0.000136 (0.001591)
	cen_loss: 0.616660 (0.613389)	cls_loss: 0.038386 (0.045593)
	loc_loss: 0.163476 (0.169265)	total_loss: 1.145475 (1.166777)

[2023-05-05 06:40:06,687-rk0-log_helper.py#102] Progress: 13480 / 15625 [86%], Speed: 2.083 s/iter, ETA 0:01:14 (D:H:M)

[2023-05-05 06:40:48,348-rk0-train.py#348] Epoch: [22][375/625] lr: 0.000216
	batch_time: 2.087007 (2.082834)	data_time: 0.000745 (0.000512)
	loss_fool: 0.199028 (0.197818)	loss_train_adv: 0.001107 (0.001451)
	cen_loss: 0.614280 (0.613404)	cls_loss: 0.055201 (0.046617)
	loc_loss: 0.212059 (0.170377)	total_loss: 1.305658 (1.171153)

[2023-05-05 06:40:48,349-rk0-log_helper.py#102] Progress: 13500 / 15625 [86%], Speed: 2.083 s/iter, ETA 0:01:13 (D:H:M)

[2023-05-05 06:41:30,042-rk0-train.py#348] Epoch: [22][395/625] lr: 0.000216
	batch_time: 2.073300 (2.082581)	data_time: 0.000149 (0.000523)
	loss_fool: 0.205202 (0.198302)	loss_train_adv: 0.000209 (0.001288)
	cen_loss: 0.608349 (0.613329)	cls_loss: 0.041954 (0.047352)
	loc_loss: 0.157014 (0.171012)	total_loss: 1.121347 (1.173717)

[2023-05-05 06:41:30,043-rk0-log_helper.py#102] Progress: 13520 / 15625 [86%], Speed: 2.083 s/iter, ETA 0:01:13 (D:H:M)

[2023-05-05 06:42:11,716-rk0-train.py#348] Epoch: [22][415/625] lr: 0.000216
	batch_time: 2.076911 (2.082191)	data_time: 0.000685 (0.000523)
	loss_fool: 0.196649 (0.198152)	loss_train_adv: 0.001455 (0.001315)
	cen_loss: 0.604730 (0.612911)	cls_loss: 0.033426 (0.047963)
	loc_loss: 0.158569 (0.170698)	total_loss: 1.113863 (1.172969)

[2023-05-05 06:42:11,717-rk0-log_helper.py#102] Progress: 13540 / 15625 [86%], Speed: 2.082 s/iter, ETA 0:01:12 (D:H:M)

[2023-05-05 06:42:54,358-rk0-train.py#348] Epoch: [22][435/625] lr: 0.000216
	batch_time: 2.074093 (2.092456)	data_time: 0.000458 (0.000503)
	loss_fool: 0.194745 (0.198075)	loss_train_adv: 0.001068 (0.001283)
	cen_loss: 0.608800 (0.612686)	cls_loss: 0.053094 (0.048512)
	loc_loss: 0.171834 (0.170313)	total_loss: 1.177396 (1.172139)

[2023-05-05 06:42:54,359-rk0-log_helper.py#102] Progress: 13560 / 15625 [86%], Speed: 2.092 s/iter, ETA 0:01:12 (D:H:M)

[2023-05-05 06:43:36,154-rk0-train.py#348] Epoch: [22][455/625] lr: 0.000216
	batch_time: 2.082142 (2.093448)	data_time: 0.000675 (0.000509)
	loss_fool: 0.200039 (0.198195)	loss_train_adv: 0.000055 (0.001205)
	cen_loss: 0.616350 (0.612660)	cls_loss: 0.032265 (0.049168)
	loc_loss: 0.138169 (0.171338)	total_loss: 1.063121 (1.175841)

[2023-05-05 06:43:36,155-rk0-log_helper.py#102] Progress: 13580 / 15625 [86%], Speed: 2.093 s/iter, ETA 0:01:11 (D:H:M)

[2023-05-05 06:44:17,843-rk0-train.py#348] Epoch: [22][475/625] lr: 0.000216
	batch_time: 2.088544 (2.093757)	data_time: 0.000740 (0.000532)
	loss_fool: 0.204137 (0.198403)	loss_train_adv: 0.002632 (0.001215)
	cen_loss: 0.611843 (0.612264)	cls_loss: 0.045774 (0.048824)
	loc_loss: 0.158355 (0.171079)	total_loss: 1.132681 (1.174324)

[2023-05-05 06:44:17,844-rk0-log_helper.py#102] Progress: 13600 / 15625 [87%], Speed: 2.094 s/iter, ETA 0:01:10 (D:H:M)

[2023-05-05 06:44:59,498-rk0-train.py#348] Epoch: [22][495/625] lr: 0.000216
	batch_time: 2.078746 (2.093371)	data_time: 0.000532 (0.000521)
	loss_fool: 0.199073 (0.198392)	loss_train_adv: 0.001207 (0.001126)
	cen_loss: 0.605412 (0.612201)	cls_loss: 0.072464 (0.048900)
	loc_loss: 0.166973 (0.171110)	total_loss: 1.178794 (1.174430)

[2023-05-05 06:44:59,499-rk0-log_helper.py#102] Progress: 13620 / 15625 [87%], Speed: 2.093 s/iter, ETA 0:01:09 (D:H:M)

[2023-05-05 06:45:41,182-rk0-train.py#348] Epoch: [22][515/625] lr: 0.000216
	batch_time: 2.086593 (2.093469)	data_time: 0.000887 (0.000510)
	loss_fool: 0.197065 (0.198158)	loss_train_adv: 0.003516 (0.001304)
	cen_loss: 0.612683 (0.612576)	cls_loss: 0.094412 (0.048954)
	loc_loss: 0.181968 (0.172608)	total_loss: 1.252999 (1.179353)

[2023-05-05 06:45:41,182-rk0-log_helper.py#102] Progress: 13640 / 15625 [87%], Speed: 2.093 s/iter, ETA 0:01:09 (D:H:M)

[2023-05-05 06:46:22,859-rk0-train.py#348] Epoch: [22][535/625] lr: 0.000216
	batch_time: 2.065655 (2.083798)	data_time: 0.000580 (0.000556)
	loss_fool: 0.199780 (0.198147)	loss_train_adv: 0.000191 (0.001190)
	cen_loss: 0.615941 (0.612301)	cls_loss: 0.056464 (0.048748)
	loc_loss: 0.178009 (0.171272)	total_loss: 1.206434 (1.174866)

[2023-05-05 06:46:22,862-rk0-log_helper.py#102] Progress: 13660 / 15625 [87%], Speed: 2.084 s/iter, ETA 0:01:08 (D:H:M)

[2023-05-05 06:47:04,537-rk0-train.py#348] Epoch: [22][555/625] lr: 0.000216
	batch_time: 2.078526 (2.082614)	data_time: 0.000564 (0.000540)
	loss_fool: 0.199115 (0.198071)	loss_train_adv: 0.000032 (0.001261)
	cen_loss: 0.616154 (0.612562)	cls_loss: 0.056446 (0.049027)
	loc_loss: 0.192012 (0.171208)	total_loss: 1.248636 (1.175213)

[2023-05-05 06:47:04,537-rk0-log_helper.py#102] Progress: 13680 / 15625 [87%], Speed: 2.083 s/iter, ETA 0:01:07 (D:H:M)

[2023-05-05 06:47:46,296-rk0-train.py#348] Epoch: [22][575/625] lr: 0.000216
	batch_time: 2.090259 (2.083313)	data_time: 0.000592 (0.000530)
	loss_fool: 0.201376 (0.198030)	loss_train_adv: 0.002929 (0.001284)
	cen_loss: 0.602155 (0.613137)	cls_loss: 0.034895 (0.048707)
	loc_loss: 0.144709 (0.170068)	total_loss: 1.071178 (1.172048)

[2023-05-05 06:47:46,297-rk0-log_helper.py#102] Progress: 13700 / 15625 [87%], Speed: 2.083 s/iter, ETA 0:01:06 (D:H:M)

[2023-05-05 06:48:28,005-rk0-train.py#348] Epoch: [22][595/625] lr: 0.000216
	batch_time: 2.067438 (2.083874)	data_time: 0.000565 (0.000536)
	loss_fool: 0.187476 (0.197305)	loss_train_adv: 0.007310 (0.001648)
	cen_loss: 0.613412 (0.613176)	cls_loss: 0.032813 (0.049086)
	loc_loss: 0.169171 (0.171163)	total_loss: 1.153737 (1.175751)

[2023-05-05 06:48:28,006-rk0-log_helper.py#102] Progress: 13720 / 15625 [87%], Speed: 2.084 s/iter, ETA 0:01:06 (D:H:M)

[2023-05-05 06:49:09,702-rk0-train.py#348] Epoch: [22][615/625] lr: 0.000216
	batch_time: 2.081980 (2.084002)	data_time: 0.000623 (0.000546)
	loss_fool: 0.201114 (0.197624)	loss_train_adv: 0.000095 (0.001488)
	cen_loss: 0.618517 (0.612972)	cls_loss: 0.046817 (0.048583)
	loc_loss: 0.182145 (0.170749)	total_loss: 1.211770 (1.173802)

[2023-05-05 06:49:09,703-rk0-log_helper.py#102] Progress: 13740 / 15625 [87%], Speed: 2.084 s/iter, ETA 0:01:05 (D:H:M)

[2023-05-05 06:49:31,319-rk0-train.py#235] epoch: 23
[2023-05-05 06:49:31,319-rk0-train.py#240] epoch 23 lr 1.911412478554702e-05
[2023-05-05 06:49:31,319-rk0-train.py#240] epoch 23 lr 0.0001911412478554702
[2023-05-05 06:49:31,320-rk0-train.py#240] epoch 23 lr 0.0006371374928515674
[2023-05-05 06:49:31,320-rk0-train.py#240] epoch 23 lr 0.0001911412478554702
[2023-05-05 06:49:31,320-rk0-train.py#240] epoch 23 lr 0.0001911412478554702
[2023-05-05 06:49:52,093-rk0-train.py#348] Epoch: [23][10/625] lr: 0.000191
	batch_time: 2.070393 (2.091147)	data_time: 0.000395 (0.007769)
	loss_fool: 0.198881 (0.197552)	loss_train_adv: 0.000251 (0.001615)
	cen_loss: 0.610938 (0.613031)	cls_loss: 0.037058 (0.047830)
	loc_loss: 0.134179 (0.170484)	total_loss: 1.050533 (1.172313)

[2023-05-05 06:49:52,093-rk0-log_helper.py#102] Progress: 13760 / 15625 [88%], Speed: 2.091 s/iter, ETA 0:01:04 (D:H:M)

[2023-05-05 06:50:33,787-rk0-train.py#348] Epoch: [23][30/625] lr: 0.000191
	batch_time: 2.104641 (2.091315)	data_time: 0.000920 (0.007788)
	loss_fool: 0.200448 (0.197638)	loss_train_adv: 0.002997 (0.001590)
	cen_loss: 0.620565 (0.613121)	cls_loss: 0.046073 (0.047144)
	loc_loss: 0.160965 (0.171234)	total_loss: 1.149532 (1.173969)

[2023-05-05 06:50:33,789-rk0-log_helper.py#102] Progress: 13780 / 15625 [88%], Speed: 2.091 s/iter, ETA 0:01:04 (D:H:M)

[2023-05-05 06:51:16,427-rk0-train.py#348] Epoch: [23][50/625] lr: 0.000191
	batch_time: 2.091170 (2.100150)	data_time: 0.000289 (0.007786)
	loss_fool: 0.199620 (0.197850)	loss_train_adv: 0.000774 (0.001539)
	cen_loss: 0.607396 (0.612527)	cls_loss: 0.040114 (0.046314)
	loc_loss: 0.163338 (0.170992)	total_loss: 1.137524 (1.171817)

[2023-05-05 06:51:16,429-rk0-log_helper.py#102] Progress: 13800 / 15625 [88%], Speed: 2.100 s/iter, ETA 0:01:03 (D:H:M)

[2023-05-05 06:51:58,100-rk0-train.py#348] Epoch: [23][70/625] lr: 0.000191
	batch_time: 2.079910 (2.099759)	data_time: 0.000630 (0.007783)
	loss_fool: 0.196238 (0.198414)	loss_train_adv: 0.005381 (0.001227)
	cen_loss: 0.607796 (0.612473)	cls_loss: 0.057261 (0.045642)
	loc_loss: 0.149608 (0.170522)	total_loss: 1.113880 (1.169682)

[2023-05-05 06:51:58,101-rk0-log_helper.py#102] Progress: 13820 / 15625 [88%], Speed: 2.100 s/iter, ETA 0:01:03 (D:H:M)

[2023-05-05 06:52:39,813-rk0-train.py#348] Epoch: [23][90/625] lr: 0.000191
	batch_time: 2.077588 (2.099671)	data_time: 0.000710 (0.007786)
	loss_fool: 0.192083 (0.198400)	loss_train_adv: 0.006559 (0.001253)
	cen_loss: 0.612218 (0.612604)	cls_loss: 0.038872 (0.045782)
	loc_loss: 0.178142 (0.169502)	total_loss: 1.185516 (1.166892)

[2023-05-05 06:52:39,813-rk0-log_helper.py#102] Progress: 13840 / 15625 [88%], Speed: 2.100 s/iter, ETA 0:01:02 (D:H:M)

[2023-05-05 06:53:21,480-rk0-train.py#348] Epoch: [23][110/625] lr: 0.000191
	batch_time: 2.081728 (2.092437)	data_time: 0.000632 (0.000551)
	loss_fool: 0.194771 (0.198240)	loss_train_adv: 0.002321 (0.001322)
	cen_loss: 0.618355 (0.612781)	cls_loss: 0.044075 (0.047047)
	loc_loss: 0.164074 (0.170263)	total_loss: 1.154653 (1.170618)

[2023-05-05 06:53:21,481-rk0-log_helper.py#102] Progress: 13860 / 15625 [88%], Speed: 2.092 s/iter, ETA 0:01:01 (D:H:M)

[2023-05-05 06:54:03,213-rk0-train.py#348] Epoch: [23][130/625] lr: 0.000191
	batch_time: 2.086930 (2.092809)	data_time: 0.000646 (0.000539)
	loss_fool: 0.200972 (0.198237)	loss_train_adv: 0.000656 (0.001284)
	cen_loss: 0.616805 (0.612610)	cls_loss: 0.071589 (0.048382)
	loc_loss: 0.193458 (0.170647)	total_loss: 1.268769 (1.172933)

[2023-05-05 06:54:03,213-rk0-log_helper.py#102] Progress: 13880 / 15625 [88%], Speed: 2.093 s/iter, ETA 0:01:00 (D:H:M)

[2023-05-05 06:54:44,967-rk0-train.py#348] Epoch: [23][150/625] lr: 0.000191
	batch_time: 2.090718 (2.083919)	data_time: 0.000638 (0.000555)
	loss_fool: 0.196543 (0.198158)	loss_train_adv: 0.001509 (0.001242)
	cen_loss: 0.612715 (0.612993)	cls_loss: 0.079953 (0.049125)
	loc_loss: 0.175369 (0.169870)	total_loss: 1.218774 (1.171727)

[2023-05-05 06:54:44,968-rk0-log_helper.py#102] Progress: 13900 / 15625 [88%], Speed: 2.084 s/iter, ETA 0:00:59 (D:H:M)

[2023-05-05 06:55:26,672-rk0-train.py#348] Epoch: [23][170/625] lr: 0.000191
	batch_time: 2.083061 (2.084253)	data_time: 0.000596 (0.000567)
	loss_fool: 0.198437 (0.198489)	loss_train_adv: 0.005497 (0.001154)
	cen_loss: 0.618679 (0.613376)	cls_loss: 0.038416 (0.050357)
	loc_loss: 0.177520 (0.170803)	total_loss: 1.189653 (1.176141)

[2023-05-05 06:55:26,673-rk0-log_helper.py#102] Progress: 13920 / 15625 [89%], Speed: 2.084 s/iter, ETA 0:00:59 (D:H:M)

[2023-05-05 06:56:08,400-rk0-train.py#348] Epoch: [23][190/625] lr: 0.000191
	batch_time: 2.075541 (2.084641)	data_time: 0.000260 (0.000563)
	loss_fool: 0.198379 (0.198169)	loss_train_adv: 0.000031 (0.001104)
	cen_loss: 0.609856 (0.613148)	cls_loss: 0.047264 (0.050427)
	loc_loss: 0.168695 (0.171922)	total_loss: 1.163205 (1.179340)

[2023-05-05 06:56:08,402-rk0-log_helper.py#102] Progress: 13940 / 15625 [89%], Speed: 2.085 s/iter, ETA 0:00:58 (D:H:M)

[2023-05-05 06:56:50,172-rk0-train.py#348] Epoch: [23][210/625] lr: 0.000191
	batch_time: 2.074994 (2.085671)	data_time: 0.000601 (0.000562)
	loss_fool: 0.193965 (0.198246)	loss_train_adv: 0.005415 (0.001116)
	cen_loss: 0.612920 (0.612699)	cls_loss: 0.043854 (0.049612)
	loc_loss: 0.177459 (0.172120)	total_loss: 1.189151 (1.178671)

[2023-05-05 06:56:50,173-rk0-log_helper.py#102] Progress: 13960 / 15625 [89%], Speed: 2.086 s/iter, ETA 0:00:57 (D:H:M)

[2023-05-05 06:57:31,799-rk0-train.py#348] Epoch: [23][230/625] lr: 0.000191
	batch_time: 2.066160 (2.084655)	data_time: 0.000632 (0.000547)
	loss_fool: 0.198922 (0.198224)	loss_train_adv: 0.000106 (0.001154)
	cen_loss: 0.606354 (0.612422)	cls_loss: 0.041168 (0.049024)
	loc_loss: 0.167009 (0.171161)	total_loss: 1.148550 (1.174928)

[2023-05-05 06:57:31,800-rk0-log_helper.py#102] Progress: 13980 / 15625 [89%], Speed: 2.085 s/iter, ETA 0:00:57 (D:H:M)

[2023-05-05 06:58:13,495-rk0-train.py#348] Epoch: [23][250/625] lr: 0.000191
	batch_time: 2.078975 (2.084087)	data_time: 0.000638 (0.000536)
	loss_fool: 0.200353 (0.198205)	loss_train_adv: 0.000148 (0.001212)
	cen_loss: 0.613997 (0.612099)	cls_loss: 0.049773 (0.049309)
	loc_loss: 0.152007 (0.170569)	total_loss: 1.119790 (1.173115)

[2023-05-05 06:58:13,496-rk0-log_helper.py#102] Progress: 14000 / 15625 [89%], Speed: 2.084 s/iter, ETA 0:00:56 (D:H:M)

[2023-05-05 06:58:55,131-rk0-train.py#348] Epoch: [23][270/625] lr: 0.000191
	batch_time: 2.087194 (2.083387)	data_time: 0.000642 (0.000535)
	loss_fool: 0.194996 (0.198109)	loss_train_adv: 0.000127 (0.001260)
	cen_loss: 0.613570 (0.611784)	cls_loss: 0.037098 (0.048481)
	loc_loss: 0.143524 (0.169413)	total_loss: 1.081241 (1.168504)

[2023-05-05 06:58:55,132-rk0-log_helper.py#102] Progress: 14020 / 15625 [89%], Speed: 2.083 s/iter, ETA 0:00:55 (D:H:M)

[2023-05-05 06:59:37,891-rk0-train.py#348] Epoch: [23][290/625] lr: 0.000191
	batch_time: 2.080807 (2.093714)	data_time: 0.000302 (0.000537)
	loss_fool: 0.191505 (0.198191)	loss_train_adv: 0.000756 (0.001262)
	cen_loss: 0.614404 (0.612152)	cls_loss: 0.041308 (0.049296)
	loc_loss: 0.165731 (0.169369)	total_loss: 1.152905 (1.169556)

[2023-05-05 06:59:37,892-rk0-log_helper.py#102] Progress: 14040 / 15625 [89%], Speed: 2.094 s/iter, ETA 0:00:55 (D:H:M)

[2023-05-05 07:00:19,530-rk0-train.py#348] Epoch: [23][310/625] lr: 0.000191
	batch_time: 2.084343 (2.092394)	data_time: 0.000295 (0.000508)
	loss_fool: 0.198741 (0.198223)	loss_train_adv: 0.002893 (0.001294)
	cen_loss: 0.621389 (0.612611)	cls_loss: 0.040270 (0.048678)
	loc_loss: 0.192353 (0.169202)	total_loss: 1.238719 (1.168895)

[2023-05-05 07:00:19,531-rk0-log_helper.py#102] Progress: 14060 / 15625 [89%], Speed: 2.092 s/iter, ETA 0:00:54 (D:H:M)

[2023-05-05 07:01:01,149-rk0-train.py#348] Epoch: [23][330/625] lr: 0.000191
	batch_time: 2.066871 (2.092284)	data_time: 0.000604 (0.000527)
	loss_fool: 0.201635 (0.198239)	loss_train_adv: 0.000040 (0.001272)
	cen_loss: 0.616277 (0.612646)	cls_loss: 0.036167 (0.048331)
	loc_loss: 0.190817 (0.168729)	total_loss: 1.224894 (1.167163)

[2023-05-05 07:01:01,149-rk0-log_helper.py#102] Progress: 14080 / 15625 [90%], Speed: 2.092 s/iter, ETA 0:00:53 (D:H:M)

[2023-05-05 07:01:42,798-rk0-train.py#348] Epoch: [23][350/625] lr: 0.000191
	batch_time: 2.076232 (2.091810)	data_time: 0.000845 (0.000543)
	loss_fool: 0.197010 (0.198324)	loss_train_adv: 0.002438 (0.001218)
	cen_loss: 0.617495 (0.613063)	cls_loss: 0.043768 (0.047981)
	loc_loss: 0.177773 (0.169695)	total_loss: 1.194582 (1.170130)

[2023-05-05 07:01:42,799-rk0-log_helper.py#102] Progress: 14100 / 15625 [90%], Speed: 2.092 s/iter, ETA 0:00:53 (D:H:M)

[2023-05-05 07:02:24,557-rk0-train.py#348] Epoch: [23][370/625] lr: 0.000191
	batch_time: 2.076368 (2.093047)	data_time: 0.000284 (0.000531)
	loss_fool: 0.196962 (0.198284)	loss_train_adv: 0.001129 (0.001189)
	cen_loss: 0.611946 (0.613170)	cls_loss: 0.049463 (0.047350)
	loc_loss: 0.203968 (0.170660)	total_loss: 1.273312 (1.172500)

[2023-05-05 07:02:24,559-rk0-log_helper.py#102] Progress: 14120 / 15625 [90%], Speed: 2.093 s/iter, ETA 0:00:52 (D:H:M)

[2023-05-05 07:03:06,327-rk0-train.py#348] Epoch: [23][390/625] lr: 0.000191
	batch_time: 2.079667 (2.083146)	data_time: 0.000666 (0.000547)
	loss_fool: 0.194142 (0.198375)	loss_train_adv: 0.006023 (0.001313)
	cen_loss: 0.610993 (0.613022)	cls_loss: 0.050435 (0.046552)
	loc_loss: 0.175174 (0.170799)	total_loss: 1.186949 (1.171972)

[2023-05-05 07:03:06,328-rk0-log_helper.py#102] Progress: 14140 / 15625 [90%], Speed: 2.083 s/iter, ETA 0:00:51 (D:H:M)

[2023-05-05 07:03:48,016-rk0-train.py#348] Epoch: [23][410/625] lr: 0.000191
	batch_time: 2.072677 (2.083660)	data_time: 0.000631 (0.000569)
	loss_fool: 0.195132 (0.198464)	loss_train_adv: 0.000087 (0.001085)
	cen_loss: 0.614182 (0.613083)	cls_loss: 0.070014 (0.048140)
	loc_loss: 0.198557 (0.171857)	total_loss: 1.279868 (1.176794)

[2023-05-05 07:03:48,018-rk0-log_helper.py#102] Progress: 14160 / 15625 [90%], Speed: 2.084 s/iter, ETA 0:00:50 (D:H:M)

[2023-05-05 07:04:29,836-rk0-train.py#348] Epoch: [23][430/625] lr: 0.000191
	batch_time: 2.094648 (2.085657)	data_time: 0.000664 (0.000569)
	loss_fool: 0.201450 (0.198428)	loss_train_adv: 0.000151 (0.001065)
	cen_loss: 0.615052 (0.613496)	cls_loss: 0.054470 (0.048540)
	loc_loss: 0.168481 (0.172427)	total_loss: 1.174964 (1.179319)

[2023-05-05 07:04:29,837-rk0-log_helper.py#102] Progress: 14180 / 15625 [90%], Speed: 2.086 s/iter, ETA 0:00:50 (D:H:M)

[2023-05-05 07:05:11,560-rk0-train.py#348] Epoch: [23][450/625] lr: 0.000191
	batch_time: 2.087500 (2.086412)	data_time: 0.000278 (0.000569)
	loss_fool: 0.195749 (0.198288)	loss_train_adv: 0.001538 (0.001138)
	cen_loss: 0.608840 (0.613137)	cls_loss: 0.046716 (0.048746)
	loc_loss: 0.154248 (0.171439)	total_loss: 1.118299 (1.176200)

[2023-05-05 07:05:11,561-rk0-log_helper.py#102] Progress: 14200 / 15625 [90%], Speed: 2.086 s/iter, ETA 0:00:49 (D:H:M)

[2023-05-05 07:05:53,252-rk0-train.py#348] Epoch: [23][470/625] lr: 0.000191
	batch_time: 2.079178 (2.085741)	data_time: 0.000634 (0.000575)
	loss_fool: 0.200323 (0.198347)	loss_train_adv: 0.001071 (0.001137)
	cen_loss: 0.611066 (0.613158)	cls_loss: 0.059067 (0.049237)
	loc_loss: 0.152606 (0.170511)	total_loss: 1.127950 (1.173929)

[2023-05-05 07:05:53,252-rk0-log_helper.py#102] Progress: 14220 / 15625 [91%], Speed: 2.086 s/iter, ETA 0:00:48 (D:H:M)

[2023-05-05 07:06:34,962-rk0-train.py#348] Epoch: [23][490/625] lr: 0.000191
	batch_time: 2.083776 (2.085136)	data_time: 0.000604 (0.000565)
	loss_fool: 0.199619 (0.198445)	loss_train_adv: 0.000081 (0.001085)
	cen_loss: 0.614224 (0.612855)	cls_loss: 0.042210 (0.049346)
	loc_loss: 0.164706 (0.170922)	total_loss: 1.150554 (1.174966)

[2023-05-05 07:06:34,963-rk0-log_helper.py#102] Progress: 14240 / 15625 [91%], Speed: 2.085 s/iter, ETA 0:00:48 (D:H:M)

[2023-05-05 07:07:16,597-rk0-train.py#348] Epoch: [23][510/625] lr: 0.000191
	batch_time: 2.092263 (2.084585)	data_time: 0.000486 (0.000556)
	loss_fool: 0.196849 (0.198467)	loss_train_adv: 0.002789 (0.001130)
	cen_loss: 0.612834 (0.612716)	cls_loss: 0.041675 (0.049077)
	loc_loss: 0.190293 (0.169800)	total_loss: 1.225389 (1.171193)

[2023-05-05 07:07:16,598-rk0-log_helper.py#102] Progress: 14260 / 15625 [91%], Speed: 2.085 s/iter, ETA 0:00:47 (D:H:M)

[2023-05-05 07:07:59,387-rk0-train.py#348] Epoch: [23][530/625] lr: 0.000191
	batch_time: 2.083899 (2.094312)	data_time: 0.000611 (0.000553)
	loss_fool: 0.195134 (0.198314)	loss_train_adv: 0.005460 (0.001290)
	cen_loss: 0.611377 (0.612240)	cls_loss: 0.039613 (0.047922)
	loc_loss: 0.161803 (0.169203)	total_loss: 1.136400 (1.167771)

[2023-05-05 07:07:59,388-rk0-log_helper.py#102] Progress: 14280 / 15625 [91%], Speed: 2.094 s/iter, ETA 0:00:46 (D:H:M)

[2023-05-05 07:08:41,089-rk0-train.py#348] Epoch: [23][550/625] lr: 0.000191
	batch_time: 2.073272 (2.094106)	data_time: 0.000379 (0.000515)
	loss_fool: 0.199420 (0.198360)	loss_train_adv: 0.000035 (0.001141)
	cen_loss: 0.611619 (0.612455)	cls_loss: 0.052128 (0.047743)
	loc_loss: 0.168218 (0.170814)	total_loss: 1.168401 (1.172642)

[2023-05-05 07:08:41,089-rk0-log_helper.py#102] Progress: 14300 / 15625 [91%], Speed: 2.094 s/iter, ETA 0:00:46 (D:H:M)

[2023-05-05 07:09:22,867-rk0-train.py#348] Epoch: [23][570/625] lr: 0.000191
	batch_time: 2.114458 (2.094905)	data_time: 0.000637 (0.000529)
	loss_fool: 0.199766 (0.198287)	loss_train_adv: 0.000406 (0.001194)
	cen_loss: 0.612458 (0.612163)	cls_loss: 0.041899 (0.048243)
	loc_loss: 0.149513 (0.171391)	total_loss: 1.102894 (1.174578)

[2023-05-05 07:09:22,869-rk0-log_helper.py#102] Progress: 14320 / 15625 [91%], Speed: 2.095 s/iter, ETA 0:00:45 (D:H:M)

[2023-05-05 07:10:04,632-rk0-train.py#348] Epoch: [23][590/625] lr: 0.000191
	batch_time: 2.090323 (2.095457)	data_time: 0.000476 (0.000521)
	loss_fool: 0.199581 (0.198171)	loss_train_adv: 0.010631 (0.001179)
	cen_loss: 0.620950 (0.612329)	cls_loss: 0.082990 (0.048074)
	loc_loss: 0.198113 (0.170942)	total_loss: 1.298279 (1.173230)

[2023-05-05 07:10:04,633-rk0-log_helper.py#102] Progress: 14340 / 15625 [91%], Speed: 2.095 s/iter, ETA 0:00:44 (D:H:M)

[2023-05-05 07:10:46,359-rk0-train.py#348] Epoch: [23][610/625] lr: 0.000191
	batch_time: 2.075289 (2.096382)	data_time: 0.000276 (0.000523)
	loss_fool: 0.194514 (0.198260)	loss_train_adv: 0.000394 (0.001173)
	cen_loss: 0.612496 (0.612051)	cls_loss: 0.044589 (0.046885)
	loc_loss: 0.174933 (0.170145)	total_loss: 1.181885 (1.169371)

[2023-05-05 07:10:46,360-rk0-log_helper.py#102] Progress: 14360 / 15625 [91%], Speed: 2.096 s/iter, ETA 0:00:44 (D:H:M)

[2023-05-05 07:11:18,333-rk0-train.py#235] epoch: 24
[2023-05-05 07:11:18,333-rk0-train.py#240] epoch 24 lr 1.6932568375270345e-05
[2023-05-05 07:11:18,333-rk0-train.py#240] epoch 24 lr 0.00016932568375270342
[2023-05-05 07:11:18,333-rk0-train.py#240] epoch 24 lr 0.0005644189458423447
[2023-05-05 07:11:18,334-rk0-train.py#240] epoch 24 lr 0.00016932568375270342
[2023-05-05 07:11:18,334-rk0-train.py#240] epoch 24 lr 0.00016932568375270342
[2023-05-05 07:11:28,713-rk0-train.py#348] Epoch: [24][5/625] lr: 0.000169
	batch_time: 2.077343 (2.091929)	data_time: 0.000682 (0.007687)
	loss_fool: 0.194331 (0.198274)	loss_train_adv: 0.001794 (0.001119)
	cen_loss: 0.617574 (0.612458)	cls_loss: 0.032895 (0.047621)
	loc_loss: 0.148339 (0.169889)	total_loss: 1.095484 (1.169747)

[2023-05-05 07:11:28,713-rk0-log_helper.py#102] Progress: 14380 / 15625 [92%], Speed: 2.092 s/iter, ETA 0:00:43 (D:H:M)

[2023-05-05 07:12:10,447-rk0-train.py#348] Epoch: [24][25/625] lr: 0.000169
	batch_time: 2.085283 (2.092241)	data_time: 0.000489 (0.007705)
	loss_fool: 0.201553 (0.198320)	loss_train_adv: 0.000101 (0.001095)
	cen_loss: 0.612520 (0.612367)	cls_loss: 0.064138 (0.047970)
	loc_loss: 0.199675 (0.169444)	total_loss: 1.275684 (1.168667)

[2023-05-05 07:12:10,448-rk0-log_helper.py#102] Progress: 14400 / 15625 [92%], Speed: 2.092 s/iter, ETA 0:00:42 (D:H:M)

[2023-05-05 07:12:52,171-rk0-train.py#348] Epoch: [24][45/625] lr: 0.000169
	batch_time: 2.080210 (2.091762)	data_time: 0.000546 (0.007669)
	loss_fool: 0.199462 (0.198292)	loss_train_adv: 0.001807 (0.001103)
	cen_loss: 0.615684 (0.612704)	cls_loss: 0.042871 (0.047315)
	loc_loss: 0.172107 (0.168389)	total_loss: 1.174875 (1.165185)

[2023-05-05 07:12:52,172-rk0-log_helper.py#102] Progress: 14420 / 15625 [92%], Speed: 2.092 s/iter, ETA 0:00:42 (D:H:M)

[2023-05-05 07:13:33,892-rk0-train.py#348] Epoch: [24][65/625] lr: 0.000169
	batch_time: 2.078679 (2.091342)	data_time: 0.000662 (0.007664)
	loss_fool: 0.201982 (0.198076)	loss_train_adv: 0.002901 (0.001150)
	cen_loss: 0.610561 (0.612982)	cls_loss: 0.031798 (0.046771)
	loc_loss: 0.168398 (0.167833)	total_loss: 1.147552 (1.163251)

[2023-05-05 07:13:33,892-rk0-log_helper.py#102] Progress: 14440 / 15625 [92%], Speed: 2.091 s/iter, ETA 0:00:41 (D:H:M)

[2023-05-05 07:14:15,596-rk0-train.py#348] Epoch: [24][85/625] lr: 0.000169
	batch_time: 2.086602 (2.091114)	data_time: 0.000634 (0.007681)
	loss_fool: 0.200273 (0.198040)	loss_train_adv: 0.000022 (0.001219)
	cen_loss: 0.618251 (0.613503)	cls_loss: 0.039670 (0.047635)
	loc_loss: 0.165737 (0.170170)	total_loss: 1.155131 (1.171647)

[2023-05-05 07:14:15,599-rk0-log_helper.py#102] Progress: 14460 / 15625 [92%], Speed: 2.091 s/iter, ETA 0:00:40 (D:H:M)

[2023-05-05 07:14:57,330-rk0-train.py#348] Epoch: [24][105/625] lr: 0.000169
	batch_time: 2.084905 (2.084992)	data_time: 0.000455 (0.000532)
	loss_fool: 0.200098 (0.198225)	loss_train_adv: 0.000189 (0.001081)
	cen_loss: 0.618921 (0.613025)	cls_loss: 0.042907 (0.046276)
	loc_loss: 0.174160 (0.170527)	total_loss: 1.184308 (1.170882)

[2023-05-05 07:14:57,332-rk0-log_helper.py#102] Progress: 14480 / 15625 [92%], Speed: 2.085 s/iter, ETA 0:00:39 (D:H:M)

[2023-05-05 07:15:40,067-rk0-train.py#348] Epoch: [24][125/625] lr: 0.000169
	batch_time: 2.092601 (2.095004)	data_time: 0.000802 (0.000524)
	loss_fool: 0.197631 (0.198241)	loss_train_adv: 0.000191 (0.001165)
	cen_loss: 0.610675 (0.612824)	cls_loss: 0.045685 (0.045280)
	loc_loss: 0.182357 (0.170648)	total_loss: 1.203432 (1.170047)

[2023-05-05 07:15:40,068-rk0-log_helper.py#102] Progress: 14500 / 15625 [92%], Speed: 2.095 s/iter, ETA 0:00:39 (D:H:M)

[2023-05-05 07:16:21,847-rk0-train.py#348] Epoch: [24][145/625] lr: 0.000169
	batch_time: 2.102889 (2.095556)	data_time: 0.000577 (0.000555)
	loss_fool: 0.199253 (0.198008)	loss_train_adv: 0.000795 (0.001206)
	cen_loss: 0.610187 (0.612759)	cls_loss: 0.042355 (0.046673)
	loc_loss: 0.169890 (0.170578)	total_loss: 1.162211 (1.171166)

[2023-05-05 07:16:21,848-rk0-log_helper.py#102] Progress: 14520 / 15625 [92%], Speed: 2.096 s/iter, ETA 0:00:38 (D:H:M)

[2023-05-05 07:17:03,615-rk0-train.py#348] Epoch: [24][165/625] lr: 0.000169
	batch_time: 2.093034 (2.095794)	data_time: 0.000377 (0.000573)
	loss_fool: 0.198536 (0.198493)	loss_train_adv: 0.000045 (0.001030)
	cen_loss: 0.615296 (0.613032)	cls_loss: 0.042664 (0.047862)
	loc_loss: 0.175566 (0.171442)	total_loss: 1.184658 (1.175220)

[2023-05-05 07:17:03,616-rk0-log_helper.py#102] Progress: 14540 / 15625 [93%], Speed: 2.096 s/iter, ETA 0:00:37 (D:H:M)

[2023-05-05 07:17:45,313-rk0-train.py#348] Epoch: [24][185/625] lr: 0.000169
	batch_time: 2.090318 (2.095725)	data_time: 0.000720 (0.000572)
	loss_fool: 0.201367 (0.198487)	loss_train_adv: 0.000042 (0.001001)
	cen_loss: 0.609410 (0.612768)	cls_loss: 0.061062 (0.047649)
	loc_loss: 0.186910 (0.169528)	total_loss: 1.231202 (1.169001)

[2023-05-05 07:17:45,315-rk0-log_helper.py#102] Progress: 14560 / 15625 [93%], Speed: 2.096 s/iter, ETA 0:00:37 (D:H:M)

[2023-05-05 07:18:26,942-rk0-train.py#348] Epoch: [24][205/625] lr: 0.000169
	batch_time: 2.091322 (2.094675)	data_time: 0.000684 (0.000560)
	loss_fool: 0.199098 (0.198537)	loss_train_adv: 0.000775 (0.001023)
	cen_loss: 0.617474 (0.612730)	cls_loss: 0.048006 (0.048184)
	loc_loss: 0.181297 (0.169592)	total_loss: 1.209371 (1.169689)

[2023-05-05 07:18:26,944-rk0-log_helper.py#102] Progress: 14580 / 15625 [93%], Speed: 2.095 s/iter, ETA 0:00:36 (D:H:M)

[2023-05-05 07:19:08,551-rk0-train.py#348] Epoch: [24][225/625] lr: 0.000169
	batch_time: 2.081606 (2.083403)	data_time: 0.000633 (0.000572)
	loss_fool: 0.196056 (0.198589)	loss_train_adv: 0.003953 (0.000992)
	cen_loss: 0.617142 (0.613108)	cls_loss: 0.077737 (0.050410)
	loc_loss: 0.193354 (0.170490)	total_loss: 1.274940 (1.174990)

[2023-05-05 07:19:08,551-rk0-log_helper.py#102] Progress: 14600 / 15625 [93%], Speed: 2.083 s/iter, ETA 0:00:35 (D:H:M)

[2023-05-05 07:19:50,278-rk0-train.py#348] Epoch: [24][245/625] lr: 0.000169
	batch_time: 2.071517 (2.082870)	data_time: 0.000618 (0.000577)
	loss_fool: 0.199977 (0.198872)	loss_train_adv: 0.000095 (0.000844)
	cen_loss: 0.619980 (0.612983)	cls_loss: 0.046295 (0.048919)
	loc_loss: 0.187152 (0.171109)	total_loss: 1.227731 (1.175230)

[2023-05-05 07:19:50,279-rk0-log_helper.py#102] Progress: 14620 / 15625 [93%], Speed: 2.083 s/iter, ETA 0:00:34 (D:H:M)

[2023-05-05 07:20:31,991-rk0-train.py#348] Epoch: [24][265/625] lr: 0.000169
	batch_time: 2.085141 (2.082537)	data_time: 0.000473 (0.000561)
	loss_fool: 0.196804 (0.198687)	loss_train_adv: 0.003217 (0.000965)
	cen_loss: 0.607195 (0.612425)	cls_loss: 0.064875 (0.047234)
	loc_loss: 0.183811 (0.169205)	total_loss: 1.223503 (1.167274)

[2023-05-05 07:20:31,991-rk0-log_helper.py#102] Progress: 14640 / 15625 [93%], Speed: 2.083 s/iter, ETA 0:00:34 (D:H:M)

[2023-05-05 07:21:13,711-rk0-train.py#348] Epoch: [24][285/625] lr: 0.000169
	batch_time: 2.083759 (2.082751)	data_time: 0.000566 (0.000542)
	loss_fool: 0.204437 (0.198635)	loss_train_adv: 0.000799 (0.000954)
	cen_loss: 0.610067 (0.612341)	cls_loss: 0.042257 (0.046765)
	loc_loss: 0.184303 (0.169463)	total_loss: 1.205234 (1.167496)

[2023-05-05 07:21:13,711-rk0-log_helper.py#102] Progress: 14660 / 15625 [93%], Speed: 2.083 s/iter, ETA 0:00:33 (D:H:M)

[2023-05-05 07:21:55,326-rk0-train.py#348] Epoch: [24][305/625] lr: 0.000169
	batch_time: 2.080178 (2.082629)	data_time: 0.000640 (0.000531)
	loss_fool: 0.196800 (0.198743)	loss_train_adv: 0.002323 (0.000885)
	cen_loss: 0.617213 (0.612803)	cls_loss: 0.044379 (0.047036)
	loc_loss: 0.177614 (0.169648)	total_loss: 1.194435 (1.168783)

[2023-05-05 07:21:55,327-rk0-log_helper.py#102] Progress: 14680 / 15625 [93%], Speed: 2.083 s/iter, ETA 0:00:32 (D:H:M)

[2023-05-05 07:22:36,988-rk0-train.py#348] Epoch: [24][325/625] lr: 0.000169
	batch_time: 2.085711 (2.083157)	data_time: 0.000522 (0.000564)
	loss_fool: 0.197574 (0.198654)	loss_train_adv: 0.000375 (0.000918)
	cen_loss: 0.612021 (0.612822)	cls_loss: 0.039593 (0.045618)
	loc_loss: 0.166443 (0.169456)	total_loss: 1.150944 (1.166807)

[2023-05-05 07:22:36,989-rk0-log_helper.py#102] Progress: 14700 / 15625 [94%], Speed: 2.083 s/iter, ETA 0:00:32 (D:H:M)

[2023-05-05 07:23:18,623-rk0-train.py#348] Epoch: [24][345/625] lr: 0.000169
	batch_time: 2.080661 (2.082226)	data_time: 0.000416 (0.000565)
	loss_fool: 0.195916 (0.198567)	loss_train_adv: 0.001392 (0.000990)
	cen_loss: 0.606706 (0.613046)	cls_loss: 0.039474 (0.045889)
	loc_loss: 0.149794 (0.169849)	total_loss: 1.095562 (1.168483)

[2023-05-05 07:23:18,624-rk0-log_helper.py#102] Progress: 14720 / 15625 [94%], Speed: 2.082 s/iter, ETA 0:00:31 (D:H:M)

[2023-05-05 07:24:01,445-rk0-train.py#348] Epoch: [24][365/625] lr: 0.000169
	batch_time: 2.088262 (2.093298)	data_time: 0.000550 (0.000597)
	loss_fool: 0.197140 (0.198629)	loss_train_adv: 0.001317 (0.000925)
	cen_loss: 0.616158 (0.613316)	cls_loss: 0.034232 (0.047248)
	loc_loss: 0.150404 (0.171121)	total_loss: 1.101603 (1.173929)

[2023-05-05 07:24:01,447-rk0-log_helper.py#102] Progress: 14740 / 15625 [94%], Speed: 2.093 s/iter, ETA 0:00:30 (D:H:M)

[2023-05-05 07:24:43,134-rk0-train.py#348] Epoch: [24][385/625] lr: 0.000169
	batch_time: 2.074335 (2.092991)	data_time: 0.000382 (0.000625)
	loss_fool: 0.198187 (0.198881)	loss_train_adv: 0.000034 (0.000805)
	cen_loss: 0.605859 (0.613218)	cls_loss: 0.047196 (0.047053)
	loc_loss: 0.188702 (0.170800)	total_loss: 1.219162 (1.172672)

[2023-05-05 07:24:43,134-rk0-log_helper.py#102] Progress: 14760 / 15625 [94%], Speed: 2.093 s/iter, ETA 0:00:30 (D:H:M)

[2023-05-05 07:25:24,803-rk0-train.py#348] Epoch: [24][405/625] lr: 0.000169
	batch_time: 2.089801 (2.093536)	data_time: 0.000638 (0.000642)
	loss_fool: 0.198396 (0.198699)	loss_train_adv: 0.000439 (0.000907)
	cen_loss: 0.618864 (0.613261)	cls_loss: 0.069021 (0.047712)
	loc_loss: 0.175198 (0.170125)	total_loss: 1.213479 (1.171349)

[2023-05-05 07:25:24,805-rk0-log_helper.py#102] Progress: 14780 / 15625 [94%], Speed: 2.094 s/iter, ETA 0:00:29 (D:H:M)

[2023-05-05 07:26:06,480-rk0-train.py#348] Epoch: [24][425/625] lr: 0.000169
	batch_time: 2.093068 (2.093691)	data_time: 0.000673 (0.000624)
	loss_fool: 0.202206 (0.198527)	loss_train_adv: 0.001051 (0.000982)
	cen_loss: 0.614524 (0.613422)	cls_loss: 0.030178 (0.047094)
	loc_loss: 0.148753 (0.169532)	total_loss: 1.090960 (1.169113)

[2023-05-05 07:26:06,482-rk0-log_helper.py#102] Progress: 14800 / 15625 [94%], Speed: 2.094 s/iter, ETA 0:00:28 (D:H:M)

[2023-05-05 07:26:48,077-rk0-train.py#348] Epoch: [24][445/625] lr: 0.000169
	batch_time: 2.063563 (2.093335)	data_time: 0.000646 (0.000603)
	loss_fool: 0.197650 (0.198623)	loss_train_adv: 0.002980 (0.001057)
	cen_loss: 0.611181 (0.613193)	cls_loss: 0.028691 (0.047375)
	loc_loss: 0.145432 (0.169525)	total_loss: 1.076167 (1.169143)

[2023-05-05 07:26:48,078-rk0-log_helper.py#102] Progress: 14820 / 15625 [94%], Speed: 2.093 s/iter, ETA 0:00:28 (D:H:M)

[2023-05-05 07:27:29,831-rk0-train.py#348] Epoch: [24][465/625] lr: 0.000169
	batch_time: 2.090056 (2.082669)	data_time: 0.000605 (0.000574)
	loss_fool: 0.196776 (0.198558)	loss_train_adv: 0.002177 (0.001091)
	cen_loss: 0.618383 (0.613131)	cls_loss: 0.046093 (0.047498)
	loc_loss: 0.213429 (0.169824)	total_loss: 1.304763 (1.170101)

[2023-05-05 07:27:29,831-rk0-log_helper.py#102] Progress: 14840 / 15625 [94%], Speed: 2.083 s/iter, ETA 0:00:27 (D:H:M)

[2023-05-05 07:28:11,544-rk0-train.py#348] Epoch: [24][485/625] lr: 0.000169
	batch_time: 2.071239 (2.082918)	data_time: 0.000635 (0.000551)
	loss_fool: 0.198064 (0.197883)	loss_train_adv: 0.001019 (0.001422)
	cen_loss: 0.612775 (0.613116)	cls_loss: 0.048229 (0.047363)
	loc_loss: 0.197007 (0.170635)	total_loss: 1.252024 (1.172382)

[2023-05-05 07:28:11,545-rk0-log_helper.py#102] Progress: 14860 / 15625 [95%], Speed: 2.083 s/iter, ETA 0:00:26 (D:H:M)

[2023-05-05 07:28:53,238-rk0-train.py#348] Epoch: [24][505/625] lr: 0.000169
	batch_time: 2.079936 (2.083153)	data_time: 0.000276 (0.000547)
	loss_fool: 0.198939 (0.197917)	loss_train_adv: 0.000106 (0.001410)
	cen_loss: 0.618341 (0.613074)	cls_loss: 0.039998 (0.046975)
	loc_loss: 0.182465 (0.170640)	total_loss: 1.205732 (1.171970)

[2023-05-05 07:28:53,239-rk0-log_helper.py#102] Progress: 14880 / 15625 [95%], Speed: 2.083 s/iter, ETA 0:00:25 (D:H:M)

[2023-05-05 07:29:34,816-rk0-train.py#348] Epoch: [24][525/625] lr: 0.000169
	batch_time: 2.087152 (2.082175)	data_time: 0.000277 (0.000507)
	loss_fool: 0.197932 (0.197848)	loss_train_adv: 0.001285 (0.001441)
	cen_loss: 0.608116 (0.612965)	cls_loss: 0.060463 (0.047362)
	loc_loss: 0.180498 (0.170697)	total_loss: 1.210074 (1.172417)

[2023-05-05 07:29:34,817-rk0-log_helper.py#102] Progress: 14900 / 15625 [95%], Speed: 2.082 s/iter, ETA 0:00:25 (D:H:M)

[2023-05-05 07:30:16,543-rk0-train.py#348] Epoch: [24][545/625] lr: 0.000169
	batch_time: 2.073063 (2.083483)	data_time: 0.000638 (0.000498)
	loss_fool: 0.199561 (0.197914)	loss_train_adv: 0.000083 (0.001282)
	cen_loss: 0.613483 (0.613285)	cls_loss: 0.033782 (0.046683)
	loc_loss: 0.148618 (0.170171)	total_loss: 1.093119 (1.170482)

[2023-05-05 07:30:16,545-rk0-log_helper.py#102] Progress: 14920 / 15625 [95%], Speed: 2.083 s/iter, ETA 0:00:24 (D:H:M)

[2023-05-05 07:30:58,113-rk0-train.py#348] Epoch: [24][565/625] lr: 0.000169
	batch_time: 2.075684 (2.081639)	data_time: 0.001187 (0.000512)
	loss_fool: 0.202198 (0.197845)	loss_train_adv: 0.001470 (0.001280)
	cen_loss: 0.617477 (0.612937)	cls_loss: 0.061743 (0.046542)
	loc_loss: 0.197674 (0.169907)	total_loss: 1.272243 (1.169199)

[2023-05-05 07:30:58,114-rk0-log_helper.py#102] Progress: 14940 / 15625 [95%], Speed: 2.082 s/iter, ETA 0:00:23 (D:H:M)

[2023-05-05 07:31:39,778-rk0-train.py#348] Epoch: [24][585/625] lr: 0.000169
	batch_time: 2.085772 (2.081147)	data_time: 0.000637 (0.000529)
	loss_fool: 0.201781 (0.198535)	loss_train_adv: 0.000116 (0.000963)
	cen_loss: 0.614721 (0.613383)	cls_loss: 0.040880 (0.047705)
	loc_loss: 0.157776 (0.169850)	total_loss: 1.128929 (1.170636)

[2023-05-05 07:31:39,779-rk0-log_helper.py#102] Progress: 14960 / 15625 [95%], Speed: 2.081 s/iter, ETA 0:00:23 (D:H:M)

[2023-05-05 07:32:22,376-rk0-train.py#348] Epoch: [24][605/625] lr: 0.000169
	batch_time: 3.020955 (2.090200)	data_time: 0.000570 (0.000526)
	loss_fool: 0.199867 (0.198564)	loss_train_adv: 0.000868 (0.001031)
	cen_loss: 0.611836 (0.613511)	cls_loss: 0.079464 (0.047545)
	loc_loss: 0.196489 (0.170619)	total_loss: 1.280766 (1.172912)

[2023-05-05 07:32:22,377-rk0-log_helper.py#102] Progress: 14980 / 15625 [95%], Speed: 2.090 s/iter, ETA 0:00:22 (D:H:M)

[2023-05-05 07:33:04,131-rk0-train.py#348] Epoch: [24][0/625] lr: 0.000169
	batch_time: 2.092772 (2.091955)	data_time: 0.000386 (0.000544)
	loss_fool: 0.192479 (0.198684)	loss_train_adv: 0.003028 (0.000992)
	cen_loss: 0.600101 (0.613501)	cls_loss: 0.042079 (0.047485)
	loc_loss: 0.155068 (0.171023)	total_loss: 1.107383 (1.174055)

[2023-05-05 07:33:04,132-rk0-log_helper.py#102] Progress: 15000 / 15625 [96%], Speed: 2.092 s/iter, ETA 0:00:21 (D:H:M)

[2023-05-05 07:33:05,013-rk0-train.py#235] epoch: 25
[2023-05-05 07:33:05,013-rk0-train.py#240] epoch 25 lr 1.5000000000000002e-05
[2023-05-05 07:33:05,013-rk0-train.py#240] epoch 25 lr 0.00015
[2023-05-05 07:33:05,014-rk0-train.py#240] epoch 25 lr 0.0005
[2023-05-05 07:33:05,014-rk0-train.py#240] epoch 25 lr 0.00015
[2023-05-05 07:33:05,014-rk0-train.py#240] epoch 25 lr 0.00015
[2023-05-05 07:33:46,652-rk0-train.py#348] Epoch: [25][20/625] lr: 0.000150
	batch_time: 2.081430 (2.099879)	data_time: 0.000319 (0.009372)
	loss_fool: 0.199938 (0.198643)	loss_train_adv: 0.000035 (0.000995)
	cen_loss: 0.611407 (0.613093)	cls_loss: 0.035331 (0.048078)
	loc_loss: 0.173226 (0.170765)	total_loss: 1.166418 (1.173466)

[2023-05-05 07:33:46,654-rk0-log_helper.py#102] Progress: 15020 / 15625 [96%], Speed: 2.100 s/iter, ETA 0:00:21 (D:H:M)

[2023-05-05 07:34:28,406-rk0-train.py#348] Epoch: [25][40/625] lr: 0.000150
	batch_time: 2.086546 (2.101725)	data_time: 0.000640 (0.009374)
	loss_fool: 0.198841 (0.198639)	loss_train_adv: 0.000024 (0.000968)
	cen_loss: 0.615126 (0.613341)	cls_loss: 0.042863 (0.047974)
	loc_loss: 0.164105 (0.171580)	total_loss: 1.150305 (1.176057)

[2023-05-05 07:34:28,407-rk0-log_helper.py#102] Progress: 15040 / 15625 [96%], Speed: 2.102 s/iter, ETA 0:00:20 (D:H:M)

[2023-05-05 07:35:09,995-rk0-train.py#348] Epoch: [25][60/625] lr: 0.000150
	batch_time: 2.090370 (2.100970)	data_time: 0.000577 (0.009366)
	loss_fool: 0.199454 (0.198552)	loss_train_adv: 0.004181 (0.001019)
	cen_loss: 0.601146 (0.612988)	cls_loss: 0.042835 (0.046831)
	loc_loss: 0.161160 (0.171091)	total_loss: 1.127462 (1.173091)

[2023-05-05 07:35:09,996-rk0-log_helper.py#102] Progress: 15060 / 15625 [96%], Speed: 2.101 s/iter, ETA 0:00:19 (D:H:M)

[2023-05-05 07:35:51,701-rk0-train.py#348] Epoch: [25][80/625] lr: 0.000150
	batch_time: 2.075070 (2.092015)	data_time: 0.000639 (0.009358)
	loss_fool: 0.200561 (0.198385)	loss_train_adv: 0.002983 (0.001045)
	cen_loss: 0.614186 (0.612869)	cls_loss: 0.039098 (0.047273)
	loc_loss: 0.177371 (0.171530)	total_loss: 1.185398 (1.174733)

[2023-05-05 07:35:51,701-rk0-log_helper.py#102] Progress: 15080 / 15625 [96%], Speed: 2.092 s/iter, ETA 0:00:19 (D:H:M)

[2023-05-05 07:36:33,309-rk0-train.py#348] Epoch: [25][100/625] lr: 0.000150
	batch_time: 2.073953 (2.090564)	data_time: 0.000125 (0.009362)
	loss_fool: 0.192790 (0.198337)	loss_train_adv: 0.005969 (0.001006)
	cen_loss: 0.615055 (0.612657)	cls_loss: 0.036513 (0.046790)
	loc_loss: 0.170092 (0.170298)	total_loss: 1.161843 (1.170342)

[2023-05-05 07:36:33,311-rk0-log_helper.py#102] Progress: 15100 / 15625 [96%], Speed: 2.091 s/iter, ETA 0:00:18 (D:H:M)

[2023-05-05 07:37:15,053-rk0-train.py#348] Epoch: [25][120/625] lr: 0.000150
	batch_time: 2.081918 (2.082774)	data_time: 0.000610 (0.000551)
	loss_fool: 0.198193 (0.198202)	loss_train_adv: 0.002071 (0.001151)
	cen_loss: 0.615559 (0.613133)	cls_loss: 0.049992 (0.047773)
	loc_loss: 0.160117 (0.171095)	total_loss: 1.145901 (1.174190)

[2023-05-05 07:37:15,053-rk0-log_helper.py#102] Progress: 15120 / 15625 [96%], Speed: 2.083 s/iter, ETA 0:00:17 (D:H:M)

[2023-05-05 07:37:56,731-rk0-train.py#348] Epoch: [25][140/625] lr: 0.000150
	batch_time: 2.084915 (2.082013)	data_time: 0.000291 (0.000545)
	loss_fool: 0.199812 (0.198212)	loss_train_adv: 0.000049 (0.001179)
	cen_loss: 0.620697 (0.613282)	cls_loss: 0.063072 (0.047707)
	loc_loss: 0.205764 (0.170557)	total_loss: 1.301062 (1.172660)

[2023-05-05 07:37:56,731-rk0-log_helper.py#102] Progress: 15140 / 15625 [96%], Speed: 2.082 s/iter, ETA 0:00:16 (D:H:M)

[2023-05-05 07:38:38,395-rk0-train.py#348] Epoch: [25][160/625] lr: 0.000150
	batch_time: 2.087459 (2.082773)	data_time: 0.000758 (0.000543)
	loss_fool: 0.199734 (0.198151)	loss_train_adv: 0.000041 (0.001156)
	cen_loss: 0.611541 (0.613428)	cls_loss: 0.043446 (0.048648)
	loc_loss: 0.192263 (0.170457)	total_loss: 1.231777 (1.173448)

[2023-05-05 07:38:38,395-rk0-log_helper.py#102] Progress: 15160 / 15625 [97%], Speed: 2.083 s/iter, ETA 0:00:16 (D:H:M)

[2023-05-05 07:39:21,105-rk0-train.py#348] Epoch: [25][180/625] lr: 0.000150
	batch_time: 2.073077 (2.092823)	data_time: 0.000695 (0.000570)
	loss_fool: 0.197181 (0.198286)	loss_train_adv: 0.000062 (0.001068)
	cen_loss: 0.613281 (0.613404)	cls_loss: 0.051229 (0.049012)
	loc_loss: 0.177612 (0.168874)	total_loss: 1.197345 (1.169037)

[2023-05-05 07:39:21,106-rk0-log_helper.py#102] Progress: 15180 / 15625 [97%], Speed: 2.093 s/iter, ETA 0:00:15 (D:H:M)

[2023-05-05 07:40:02,671-rk0-train.py#348] Epoch: [25][200/625] lr: 0.000150
	batch_time: 2.070921 (2.092398)	data_time: 0.000287 (0.000563)
	loss_fool: 0.197162 (0.198531)	loss_train_adv: 0.000096 (0.001012)
	cen_loss: 0.612682 (0.613384)	cls_loss: 0.073206 (0.051823)
	loc_loss: 0.232378 (0.170461)	total_loss: 1.383024 (1.176589)

[2023-05-05 07:40:02,672-rk0-log_helper.py#102] Progress: 15200 / 15625 [97%], Speed: 2.092 s/iter, ETA 0:00:14 (D:H:M)

[2023-05-05 07:40:44,335-rk0-train.py#348] Epoch: [25][220/625] lr: 0.000150
	batch_time: 2.085466 (2.091625)	data_time: 0.000631 (0.000641)
	loss_fool: 0.201294 (0.198708)	loss_train_adv: 0.002801 (0.000888)
	cen_loss: 0.611573 (0.612994)	cls_loss: 0.052882 (0.050864)
	loc_loss: 0.206210 (0.170360)	total_loss: 1.283085 (1.174936)

[2023-05-05 07:40:44,336-rk0-log_helper.py#102] Progress: 15220 / 15625 [97%], Speed: 2.092 s/iter, ETA 0:00:14 (D:H:M)

[2023-05-05 07:41:26,052-rk0-train.py#348] Epoch: [25][240/625] lr: 0.000150
	batch_time: 2.093585 (2.092002)	data_time: 0.000641 (0.000638)
	loss_fool: 0.200884 (0.198867)	loss_train_adv: 0.000219 (0.000807)
	cen_loss: 0.615258 (0.612910)	cls_loss: 0.034031 (0.050665)
	loc_loss: 0.165520 (0.169866)	total_loss: 1.145850 (1.173174)

[2023-05-05 07:41:26,053-rk0-log_helper.py#102] Progress: 15240 / 15625 [97%], Speed: 2.092 s/iter, ETA 0:00:13 (D:H:M)

[2023-05-05 07:42:07,705-rk0-train.py#348] Epoch: [25][260/625] lr: 0.000150
	batch_time: 2.073011 (2.091890)	data_time: 0.000509 (0.000628)
	loss_fool: 0.198070 (0.198946)	loss_train_adv: 0.000031 (0.000750)
	cen_loss: 0.613072 (0.613045)	cls_loss: 0.035745 (0.049864)
	loc_loss: 0.149056 (0.170277)	total_loss: 1.095986 (1.173741)

[2023-05-05 07:42:07,707-rk0-log_helper.py#102] Progress: 15260 / 15625 [97%], Speed: 2.092 s/iter, ETA 0:00:12 (D:H:M)

[2023-05-05 07:42:49,452-rk0-train.py#348] Epoch: [25][280/625] lr: 0.000150
	batch_time: 2.076282 (2.082267)	data_time: 0.000598 (0.000601)
	loss_fool: 0.198024 (0.198928)	loss_train_adv: 0.000030 (0.000780)
	cen_loss: 0.615693 (0.613264)	cls_loss: 0.053146 (0.049004)
	loc_loss: 0.186827 (0.171486)	total_loss: 1.229321 (1.176725)

[2023-05-05 07:42:49,453-rk0-log_helper.py#102] Progress: 15280 / 15625 [97%], Speed: 2.082 s/iter, ETA 0:00:11 (D:H:M)

[2023-05-05 07:43:31,135-rk0-train.py#348] Epoch: [25][300/625] lr: 0.000150
	batch_time: 2.101956 (2.083410)	data_time: 0.000370 (0.000614)
	loss_fool: 0.200081 (0.198886)	loss_train_adv: 0.002487 (0.000893)
	cen_loss: 0.611374 (0.613401)	cls_loss: 0.047203 (0.047251)
	loc_loss: 0.176313 (0.170187)	total_loss: 1.187514 (1.171212)

[2023-05-05 07:43:31,136-rk0-log_helper.py#102] Progress: 15300 / 15625 [97%], Speed: 2.083 s/iter, ETA 0:00:11 (D:H:M)

[2023-05-05 07:44:12,852-rk0-train.py#348] Epoch: [25][320/625] lr: 0.000150
	batch_time: 2.073329 (2.083922)	data_time: 0.000680 (0.000539)
	loss_fool: 0.196676 (0.198584)	loss_train_adv: 0.001763 (0.000882)
	cen_loss: 0.607134 (0.613228)	cls_loss: 0.075728 (0.047267)
	loc_loss: 0.171968 (0.169078)	total_loss: 1.198765 (1.167729)

[2023-05-05 07:44:12,853-rk0-log_helper.py#102] Progress: 15320 / 15625 [98%], Speed: 2.084 s/iter, ETA 0:00:10 (D:H:M)

[2023-05-05 07:44:54,541-rk0-train.py#348] Epoch: [25][340/625] lr: 0.000150
	batch_time: 2.075626 (2.083647)	data_time: 0.000672 (0.000547)
	loss_fool: 0.199273 (0.198608)	loss_train_adv: 0.000286 (0.000918)
	cen_loss: 0.608883 (0.613067)	cls_loss: 0.044964 (0.049440)
	loc_loss: 0.172906 (0.169764)	total_loss: 1.172565 (1.171798)

[2023-05-05 07:44:54,543-rk0-log_helper.py#102] Progress: 15340 / 15625 [98%], Speed: 2.084 s/iter, ETA 0:00:09 (D:H:M)

[2023-05-05 07:45:36,305-rk0-train.py#348] Epoch: [25][360/625] lr: 0.000150
	batch_time: 2.061663 (2.084759)	data_time: 0.000374 (0.000559)
	loss_fool: 0.197417 (0.198606)	loss_train_adv: 0.000035 (0.000983)
	cen_loss: 0.609253 (0.612666)	cls_loss: 0.036992 (0.050145)
	loc_loss: 0.163297 (0.169901)	total_loss: 1.136134 (1.172513)

[2023-05-05 07:45:36,306-rk0-log_helper.py#102] Progress: 15360 / 15625 [98%], Speed: 2.085 s/iter, ETA 0:00:09 (D:H:M)

[2023-05-05 07:46:17,979-rk0-train.py#348] Epoch: [25][380/625] lr: 0.000150
	batch_time: 2.076615 (2.084046)	data_time: 0.000541 (0.000555)
	loss_fool: 0.201295 (0.198501)	loss_train_adv: 0.004311 (0.001043)
	cen_loss: 0.607846 (0.612255)	cls_loss: 0.031120 (0.051181)
	loc_loss: 0.158148 (0.171810)	total_loss: 1.113408 (1.178866)

[2023-05-05 07:46:17,980-rk0-log_helper.py#102] Progress: 15380 / 15625 [98%], Speed: 2.084 s/iter, ETA 0:00:08 (D:H:M)

[2023-05-05 07:46:59,745-rk0-train.py#348] Epoch: [25][400/625] lr: 0.000150
	batch_time: 2.086962 (2.084880)	data_time: 0.000642 (0.000565)
	loss_fool: 0.201092 (0.198493)	loss_train_adv: 0.005984 (0.000971)
	cen_loss: 0.616960 (0.612734)	cls_loss: 0.054694 (0.052350)
	loc_loss: 0.180229 (0.174113)	total_loss: 1.212339 (1.187424)

[2023-05-05 07:46:59,746-rk0-log_helper.py#102] Progress: 15400 / 15625 [98%], Speed: 2.085 s/iter, ETA 0:00:07 (D:H:M)

[2023-05-05 07:47:42,502-rk0-train.py#348] Epoch: [25][420/625] lr: 0.000150
	batch_time: 2.078171 (2.095297)	data_time: 0.000604 (0.000570)
	loss_fool: 0.200508 (0.198335)	loss_train_adv: 0.000098 (0.001129)
	cen_loss: 0.615954 (0.612952)	cls_loss: 0.041657 (0.051702)
	loc_loss: 0.154943 (0.173576)	total_loss: 1.122440 (1.185382)

[2023-05-05 07:47:42,504-rk0-log_helper.py#102] Progress: 15420 / 15625 [98%], Speed: 2.095 s/iter, ETA 0:00:07 (D:H:M)

[2023-05-05 07:48:24,123-rk0-train.py#348] Epoch: [25][440/625] lr: 0.000150
	batch_time: 2.084142 (2.094631)	data_time: 0.000647 (0.000549)
	loss_fool: 0.199784 (0.197739)	loss_train_adv: 0.000033 (0.001332)
	cen_loss: 0.616337 (0.613165)	cls_loss: 0.068540 (0.050207)
	loc_loss: 0.183510 (0.174056)	total_loss: 1.235408 (1.185541)

[2023-05-05 07:48:24,125-rk0-log_helper.py#102] Progress: 15440 / 15625 [98%], Speed: 2.095 s/iter, ETA 0:00:06 (D:H:M)

[2023-05-05 07:49:05,788-rk0-train.py#348] Epoch: [25][460/625] lr: 0.000150
	batch_time: 2.081900 (2.093631)	data_time: 0.000644 (0.000545)
	loss_fool: 0.197367 (0.197811)	loss_train_adv: 0.000036 (0.001312)
	cen_loss: 0.608266 (0.613281)	cls_loss: 0.041651 (0.049306)
	loc_loss: 0.156221 (0.173566)	total_loss: 1.118581 (1.183285)

[2023-05-05 07:49:05,788-rk0-log_helper.py#102] Progress: 15460 / 15625 [98%], Speed: 2.094 s/iter, ETA 0:00:05 (D:H:M)

[2023-05-05 07:49:47,362-rk0-train.py#348] Epoch: [25][480/625] lr: 0.000150
	batch_time: 2.062763 (2.092627)	data_time: 0.000340 (0.000554)
	loss_fool: 0.199450 (0.197933)	loss_train_adv: 0.000040 (0.001282)
	cen_loss: 0.615875 (0.612873)	cls_loss: 0.132778 (0.048647)
	loc_loss: 0.156603 (0.169364)	total_loss: 1.218463 (1.169613)

[2023-05-05 07:49:47,362-rk0-log_helper.py#102] Progress: 15480 / 15625 [99%], Speed: 2.093 s/iter, ETA 0:00:05 (D:H:M)

[2023-05-05 07:50:29,026-rk0-train.py#348] Epoch: [25][500/625] lr: 0.000150
	batch_time: 2.083272 (2.091636)	data_time: 0.000622 (0.000558)
	loss_fool: 0.197134 (0.197871)	loss_train_adv: 0.000937 (0.001311)
	cen_loss: 0.618092 (0.612308)	cls_loss: 0.052746 (0.046201)
	loc_loss: 0.192646 (0.167153)	total_loss: 1.248777 (1.159966)

[2023-05-05 07:50:29,027-rk0-log_helper.py#102] Progress: 15500 / 15625 [99%], Speed: 2.092 s/iter, ETA 0:00:04 (D:H:M)

[2023-05-05 07:51:10,765-rk0-train.py#348] Epoch: [25][520/625] lr: 0.000150
	batch_time: 2.078904 (2.081425)	data_time: 0.000405 (0.000574)
	loss_fool: 0.197208 (0.198217)	loss_train_adv: 0.001443 (0.001174)
	cen_loss: 0.604436 (0.612296)	cls_loss: 0.034434 (0.046664)
	loc_loss: 0.154432 (0.169035)	total_loss: 1.102165 (1.166066)

[2023-05-05 07:51:10,765-rk0-log_helper.py#102] Progress: 15520 / 15625 [99%], Speed: 2.081 s/iter, ETA 0:00:03 (D:H:M)

[2023-05-05 07:51:52,312-rk0-train.py#348] Epoch: [25][540/625] lr: 0.000150
	batch_time: 2.079057 (2.080708)	data_time: 0.000277 (0.000565)
	loss_fool: 0.190689 (0.198644)	loss_train_adv: 0.001445 (0.001017)
	cen_loss: 0.608998 (0.612257)	cls_loss: 0.045836 (0.045664)
	loc_loss: 0.174880 (0.168394)	total_loss: 1.179473 (1.163104)

[2023-05-05 07:51:52,314-rk0-log_helper.py#102] Progress: 15540 / 15625 [99%], Speed: 2.081 s/iter, ETA 0:00:02 (D:H:M)

[2023-05-05 07:52:34,066-rk0-train.py#348] Epoch: [25][560/625] lr: 0.000150
	batch_time: 2.085131 (2.081583)	data_time: 0.000751 (0.000573)
	loss_fool: 0.198977 (0.198112)	loss_train_adv: 0.000649 (0.001216)
	cen_loss: 0.608604 (0.611962)	cls_loss: 0.039210 (0.045987)
	loc_loss: 0.173084 (0.167799)	total_loss: 1.167066 (1.161346)

[2023-05-05 07:52:34,066-rk0-log_helper.py#102] Progress: 15560 / 15625 [99%], Speed: 2.082 s/iter, ETA 0:00:02 (D:H:M)

[2023-05-05 07:53:15,761-rk0-train.py#348] Epoch: [25][580/625] lr: 0.000150
	batch_time: 2.094314 (2.082788)	data_time: 0.000773 (0.000578)
	loss_fool: 0.199210 (0.198329)	loss_train_adv: 0.002444 (0.001136)
	cen_loss: 0.620747 (0.612513)	cls_loss: 0.041461 (0.044727)
	loc_loss: 0.151900 (0.168668)	total_loss: 1.117907 (1.163244)

[2023-05-05 07:53:15,762-rk0-log_helper.py#102] Progress: 15580 / 15625 [99%], Speed: 2.083 s/iter, ETA 0:00:01 (D:H:M)

[2023-05-05 07:53:57,534-rk0-train.py#348] Epoch: [25][600/625] lr: 0.000150
	batch_time: 2.077932 (2.083875)	data_time: 0.000476 (0.000559)
	loss_fool: 0.199702 (0.198366)	loss_train_adv: 0.000213 (0.001062)
	cen_loss: 0.607016 (0.612803)	cls_loss: 0.038507 (0.046171)
	loc_loss: 0.161251 (0.168872)	total_loss: 1.129277 (1.165591)

[2023-05-05 07:53:57,535-rk0-log_helper.py#102] Progress: 15600 / 15625 [99%], Speed: 2.084 s/iter, ETA 0:00:00 (D:H:M)

[2023-05-05 07:54:39,271-rk0-train.py#348] Epoch: [25][620/625] lr: 0.000150
	batch_time: 2.117620 (2.083880)	data_time: 0.000618 (0.000537)
	loss_fool: 0.200388 (0.198560)	loss_train_adv: 0.000766 (0.001024)
	cen_loss: 0.607394 (0.612698)	cls_loss: 0.042645 (0.046988)
	loc_loss: 0.173802 (0.168371)	total_loss: 1.171446 (1.164799)

[2023-05-05 07:54:39,272-rk0-log_helper.py#102] Progress: 15620 / 15625 [99%], Speed: 2.084 s/iter, ETA 0:00:00 (D:H:M)

